{"Event":"SparkListenerLogStart","Spark Version":"3.3.1"}
{"Event":"SparkListenerResourceProfileAdded","Resource Profile Id":0,"Executor Resource Requests":{"cores":{"Resource Name":"cores","Amount":1,"Discovery Script":"","Vendor":""},"memory":{"Resource Name":"memory","Amount":1024,"Discovery Script":"","Vendor":""},"offHeap":{"Resource Name":"offHeap","Amount":0,"Discovery Script":"","Vendor":""}},"Task Resource Requests":{"cpus":{"Resource Name":"cpus","Amount":1.0}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"f9cd076e3ae4","Port":33521},"Maximum Memory":384093388,"Timestamp":1669331819588,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-8-openjdk-amd64/jre","Java Version":"1.8.0_352 (Private Build)","Scala Version":"version 2.12.15"},"Spark Properties":{"spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","spark.app.name":"Testing the Stream with Kafka","spark.app.initial.file.urls":"*********(redacted)","spark.scheduler.mode":"FIFO","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.cassandra.connection.port":"9042","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"},"Hadoop Properties":{"hadoop.service.shutdown.timeout":"30s","yarn.resourcemanager.amlauncher.thread-count":"50","yarn.sharedcache.enabled":"false","fs.s3a.connection.maximum":"96","yarn.nodemanager.numa-awareness.numactl.cmd":"/usr/bin/numactl","fs.viewfs.overload.scheme.target.o3fs.impl":"org.apache.hadoop.fs.ozone.OzoneFileSystem","fs.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms":"1000","yarn.timeline-service.timeline-client.number-of-async-entities-to-merge":"10","hadoop.security.kms.client.timeout":"60","hadoop.http.authentication.kerberos.principal":"HTTP/_HOST@LOCALHOST","mapreduce.jobhistory.loadedjob.tasks.max":"-1","yarn.resourcemanager.application-tag-based-placement.enable":"false","mapreduce.framework.name":"local","yarn.sharedcache.uploader.server.thread-count":"50","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min":"3600","yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern":"^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$","tfile.fs.output.buffer.size":"262144","yarn.app.mapreduce.am.job.task.listener.thread-count":"30","yarn.nodemanager.node-attributes.resync-interval-ms":"120000","yarn.nodemanager.container-log-monitor.interval-ms":"60000","hadoop.security.groups.cache.background.reload.threads":"3","yarn.resourcemanager.webapp.cross-origin.enabled":"false","fs.AbstractFileSystem.ftp.impl":"org.apache.hadoop.fs.ftp.FtpFs","fs.viewfs.overload.scheme.target.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","hadoop.registry.secure":"false","hadoop.shell.safely.delete.limit.num.files":"100","mapreduce.job.acl-view-job":" ","fs.s3a.s3guard.ddb.background.sleep":"25ms","fs.s3a.retry.limit":"7","mapreduce.jobhistory.loadedjobs.cache.size":"5","fs.s3a.s3guard.ddb.table.create":"false","fs.viewfs.overload.scheme.target.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.nodemanager.amrmproxy.enabled":"false","yarn.timeline-service.entity-group-fs-store.with-user-dir":"false","mapreduce.shuffle.pathcache.expire-after-access-minutes":"5","mapreduce.input.fileinputformat.split.minsize":"0","yarn.resourcemanager.container.liveness-monitor.interval-ms":"600000","yarn.resourcemanager.client.thread-count":"50","io.seqfile.compress.blocksize":"1000000","yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes":"runc","fs.viewfs.overload.scheme.target.http.impl":"org.apache.hadoop.fs.http.HttpFileSystem","yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor":"1.0","yarn.sharedcache.checksum.algo.impl":"org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl","yarn.nodemanager.amrmproxy.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor","yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size":"10485760","mapreduce.reduce.shuffle.fetch.retry.interval-ms":"1000","mapreduce.task.profile.maps":"0-2","yarn.scheduler.include-port-in-node-name":"false","yarn.nodemanager.admin-env":"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX","yarn.resourcemanager.node-removal-untracked.timeout-ms":"60000","mapreduce.am.max-attempts":"2","hadoop.security.kms.client.failover.sleep.base.millis":"100","mapreduce.jobhistory.webapp.https.address":"0.0.0.0:19890","yarn.node-labels.fs-store.impl.class":"org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore","yarn.nodemanager.collector-service.address":"${yarn.nodemanager.hostname}:8048","fs.trash.checkpoint.interval":"0","mapreduce.job.map.output.collector.class":"org.apache.hadoop.mapred.MapTask$MapOutputBuffer","yarn.resourcemanager.node-ip-cache.expiry-interval-secs":"-1","hadoop.http.authentication.signature.secret.file":"*********(redacted)","hadoop.jetty.logs.serve.aliases":"true","yarn.resourcemanager.placement-constraints.handler":"disabled","yarn.timeline-service.handler-thread-count":"10","yarn.resourcemanager.max-completed-applications":"1000","yarn.nodemanager.aux-services.manifest.enabled":"false","yarn.resourcemanager.system-metrics-publisher.enabled":"false","yarn.resourcemanager.placement-constraints.algorithm.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm","yarn.sharedcache.webapp.address":"0.0.0.0:8788","fs.s3a.select.input.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.renew-interval":"*********(redacted)","yarn.sharedcache.nm.uploader.replication.factor":"10","hadoop.security.groups.negative-cache.secs":"30","yarn.app.mapreduce.task.container.log.backups":"0","mapreduce.reduce.skip.proc-count.auto-incr":"true","fs.viewfs.overload.scheme.target.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","hadoop.security.group.mapping.ldap.posix.attr.gid.name":"gidNumber","ipc.client.fallback-to-simple-auth-allowed":"false","yarn.nodemanager.resource.memory.enforced":"true","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch":"false","yarn.client.failover-proxy-provider":"org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider","yarn.timeline-service.http-authentication.simple.anonymous.allowed":"true","ha.health-monitor.check-interval.ms":"1000","yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed":"false","hadoop.metrics.jvm.use-thread-mxbean":"false","ipc.[port_number].faircallqueue.multiplexer.weights":"8,4,2,1","yarn.acl.reservation-enable":"false","yarn.resourcemanager.store.class":"org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore","yarn.app.mapreduce.am.hard-kill-timeout-ms":"10000","fs.s3a.etag.checksum.enabled":"false","yarn.nodemanager.container-metrics.enable":"true","ha.health-monitor.rpc.connect.max.retries":"1","yarn.timeline-service.client.fd-clean-interval-secs":"60","yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable":"false","yarn.resourcemanager.nodemanagers.heartbeat-interval-ms":"1000","hadoop.common.configuration.version":"3.0.0","fs.s3a.s3guard.ddb.table.capacity.read":"0","yarn.nodemanager.remote-app-log-dir-suffix":"logs","yarn.nodemanager.container-log-monitor.dir-size-limit-bytes":"1000000000","yarn.nodemanager.windows-container.cpu-limit.enabled":"false","yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed":"false","file.blocksize":"67108864","hadoop.http.idle_timeout.ms":"60000","hadoop.registry.zk.retry.ceiling.ms":"60000","yarn.scheduler.configuration.leveldb-store.path":"${hadoop.tmp.dir}/yarn/system/confstore","yarn.sharedcache.store.in-memory.initial-delay-mins":"10","mapreduce.jobhistory.principal":"jhs/_HOST@REALM.TLD","mapreduce.map.skip.proc-count.auto-incr":"true","fs.s3a.committer.name":"file","mapreduce.task.profile.reduces":"0-2","hadoop.zk.num-retries":"1000","yarn.webapp.xfs-filter.enabled":"true","fs.viewfs.overload.scheme.target.hdfs.impl":"org.apache.hadoop.hdfs.DistributedFileSystem","seq.io.sort.mb":"100","yarn.scheduler.configuration.max.version":"100","yarn.timeline-service.webapp.https.address":"${yarn.timeline-service.hostname}:8190","yarn.resourcemanager.scheduler.address":"${yarn.resourcemanager.hostname}:8030","yarn.node-labels.enabled":"false","yarn.resourcemanager.webapp.ui-actions.enabled":"true","mapreduce.task.timeout":"600000","yarn.sharedcache.client-server.thread-count":"50","hadoop.security.groups.shell.command.timeout":"0s","hadoop.security.crypto.cipher.suite":"AES/CTR/NoPadding","yarn.nodemanager.elastic-memory-control.oom-handler":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler","yarn.resourcemanager.connect.max-wait.ms":"900000","fs.defaultFS":"file:///","yarn.minicluster.use-rpc":"false","ipc.[port_number].decay-scheduler.decay-factor":"0.5","fs.har.impl.disable.cache":"true","yarn.webapp.ui2.enable":"false","io.compression.codec.bzip2.library":"system-native","yarn.webapp.filter-invalid-xml-chars":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs":"600","fs.s3a.select.input.csv.record.delimiter":"\\n","fs.s3a.change.detection.source":"etag","ipc.[port_number].backoff.enable":"false","yarn.nodemanager.distributed-scheduling.enabled":"false","mapreduce.shuffle.connection-keep-alive.timeout":"5","yarn.resourcemanager.webapp.https.address":"${yarn.resourcemanager.hostname}:8090","yarn.webapp.enable-rest-app-submissions":"true","mapreduce.jobhistory.address":"0.0.0.0:10020","yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.is.minicluster":"false","yarn.nodemanager.address":"${yarn.nodemanager.hostname}:0","fs.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","fs.AbstractFileSystem.s3a.impl":"org.apache.hadoop.fs.s3a.S3A","mapreduce.task.combine.progress.records":"10000","yarn.resourcemanager.epoch.range":"0","yarn.resourcemanager.am.max-attempts":"2","yarn.nodemanager.runtime.linux.runc.image-toplevel-dir":"/runc-root","yarn.nodemanager.linux-container-executor.cgroups.hierarchy":"/hadoop-yarn","fs.AbstractFileSystem.wasbs.impl":"org.apache.hadoop.fs.azure.Wasbs","yarn.timeline-service.entity-group-fs-store.cache-store-class":"org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore","yarn.nodemanager.runtime.linux.runc.allowed-container-networks":"host,none,bridge","fs.ftp.transfer.mode":"BLOCK_TRANSFER_MODE","ipc.server.log.slow.rpc":"false","ipc.server.reuseaddr":"true","fs.ftp.timeout":"0","yarn.resourcemanager.node-labels.provider.fetch-interval-ms":"1800000","yarn.router.webapp.https.address":"0.0.0.0:8091","yarn.nodemanager.webapp.cross-origin.enabled":"false","fs.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","yarn.resourcemanager.auto-update.containers":"false","yarn.app.mapreduce.am.job.committer.cancel-timeout":"60000","yarn.scheduler.configuration.zk-store.parent-path":"/confstore","yarn.nodemanager.default-container-executor.log-dirs.permissions":"710","yarn.app.attempt.diagnostics.limit.kc":"64","fs.viewfs.overload.scheme.target.swebhdfs.impl":"org.apache.hadoop.hdfs.web.SWebHdfsFileSystem","yarn.client.failover-no-ha-proxy-provider":"org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider","fs.s3a.change.detection.mode":"server","ftp.bytes-per-checksum":"512","yarn.nodemanager.resource.memory-mb":"-1","fs.AbstractFileSystem.abfs.impl":"org.apache.hadoop.fs.azurebfs.Abfs","yarn.timeline-service.writer.flush-interval-seconds":"60","fs.s3a.fast.upload.active.blocks":"4","yarn.resourcemanager.submission-preprocessor.enabled":"false","hadoop.security.credential.clear-text-fallback":"true","yarn.nodemanager.collector-service.thread-count":"5","ipc.[port_number].scheduler.impl":"org.apache.hadoop.ipc.DefaultRpcScheduler","fs.azure.secure.mode":"false","mapreduce.jobhistory.joblist.cache.size":"20000","fs.ftp.host":"0.0.0.0","yarn.timeline-service.writer.async.queue.capacity":"100","yarn.resourcemanager.fs.state-store.num-retries":"0","yarn.resourcemanager.nodemanager-connect-retries":"10","yarn.nodemanager.log-aggregation.num-log-files-per-app":"30","hadoop.security.kms.client.encrypted.key.cache.low-watermark":"0.3f","fs.s3a.committer.magic.enabled":"true","yarn.timeline-service.client.max-retries":"30","dfs.ha.fencing.ssh.connect-timeout":"30000","yarn.log-aggregation-enable":"false","yarn.system-metrics-publisher.enabled":"false","mapreduce.reduce.markreset.buffer.percent":"0.0","fs.AbstractFileSystem.viewfs.impl":"org.apache.hadoop.fs.viewfs.ViewFs","yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor":"1.0","mapreduce.task.io.sort.factor":"10","yarn.nodemanager.amrmproxy.client.thread-count":"25","ha.failover-controller.new-active.rpc-timeout.ms":"60000","yarn.nodemanager.container-localizer.java.opts":"-Xmx256m","mapreduce.jobhistory.datestring.cache.size":"200000","mapreduce.job.acl-modify-job":" ","yarn.nodemanager.windows-container.memory-limit.enabled":"false","yarn.timeline-service.webapp.address":"${yarn.timeline-service.hostname}:8188","yarn.app.mapreduce.am.job.committer.commit-window":"10000","yarn.nodemanager.container-manager.thread-count":"20","yarn.minicluster.fixed.ports":"false","hadoop.tags.system":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.cluster.max-application-priority":"0","yarn.timeline-service.ttl-enable":"true","mapreduce.jobhistory.recovery.store.fs.uri":"${hadoop.tmp.dir}/mapred/history/recoverystore","hadoop.caller.context.signature.max.size":"40","ipc.[port_number].decay-scheduler.backoff.responsetime.enable":"false","yarn.client.load.resource-types.from-server":"false","ha.zookeeper.session-timeout.ms":"10000","ipc.[port_number].decay-scheduler.metrics.top.user.count":"10","tfile.io.chunk.size":"1048576","fs.s3a.s3guard.ddb.table.capacity.write":"0","yarn.dispatcher.print-events-info.threshold":"5000","mapreduce.job.speculative.slowtaskthreshold":"1.0","io.serializations":"org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization","hadoop.security.kms.client.failover.sleep.max.millis":"2000","hadoop.security.group.mapping.ldap.directory.search.timeout":"10000","yarn.scheduler.configuration.store.max-logs":"1000","yarn.nodemanager.node-attributes.provider.fetch-interval-ms":"600000","fs.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","yarn.nodemanager.local-cache.max-files-per-directory":"8192","hadoop.http.cross-origin.enabled":"false","hadoop.zk.acl":"world:anyone:rwcda","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache":"10","mapreduce.map.sort.spill.percent":"0.80","yarn.timeline-service.entity-group-fs-store.scan-interval-seconds":"60","yarn.node-attribute.fs-store.impl.class":"org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore","fs.s3a.retry.interval":"500ms","yarn.timeline-service.client.best-effort":"false","yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled":"*********(redacted)","hadoop.security.group.mapping.ldap.posix.attr.uid.name":"uidNumber","fs.AbstractFileSystem.swebhdfs.impl":"org.apache.hadoop.fs.SWebHdfs","yarn.nodemanager.elastic-memory-control.timeout-sec":"5","fs.s3a.select.enabled":"true","mapreduce.ifile.readahead":"true","yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms":"300000","yarn.timeline-service.reader.webapp.address":"${yarn.timeline-service.webapp.address}","yarn.resourcemanager.placement-constraints.algorithm.pool-size":"1","yarn.timeline-service.hbase.coprocessor.jar.hdfs.location":"/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar","hadoop.security.kms.client.encrypted.key.cache.num.refill.threads":"2","yarn.resourcemanager.scheduler.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler","yarn.app.mapreduce.am.command-opts":"-Xmx1024m","fs.s3a.metadatastore.fail.on.write.error":"true","hadoop.http.sni.host.check.enabled":"false","mapreduce.cluster.local.dir":"${hadoop.tmp.dir}/mapred/local","io.mapfile.bloom.error.rate":"0.005","fs.client.resolve.topology.enabled":"false","yarn.nodemanager.runtime.linux.allowed-runtimes":"default","yarn.sharedcache.store.class":"org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore","ha.failover-controller.graceful-fence.rpc-timeout.ms":"5000","ftp.replication":"3","fs.getspaceused.jitterMillis":"60000","hadoop.security.uid.cache.secs":"14400","mapreduce.job.maxtaskfailures.per.tracker":"3","fs.s3a.metadatastore.impl":"org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore","io.skip.checksum.errors":"false","yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts":"3","yarn.timeline-service.webapp.xfs-filter.xframe-options":"SAMEORIGIN","fs.s3a.connection.timeout":"200000","yarn.app.mapreduce.am.webapp.https.enabled":"false","mapreduce.job.max.split.locations":"15","yarn.resourcemanager.nm-container-queuing.max-queue-length":"15","yarn.resourcemanager.delegation-token.always-cancel":"*********(redacted)","hadoop.registry.zk.session.timeout.ms":"60000","yarn.federation.cache-ttl.secs":"300","mapreduce.jvm.system-properties-to-log":"os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name","yarn.resourcemanager.opportunistic-container-allocation.nodes-used":"10","yarn.timeline-service.entity-group-fs-store.active-dir":"/tmp/entity-file-history/active","mapreduce.shuffle.transfer.buffer.size":"131072","yarn.timeline-service.client.retry-interval-ms":"1000","yarn.timeline-service.flowname.max-size":"0","yarn.http.policy":"HTTP_ONLY","fs.s3a.socket.send.buffer":"8192","fs.AbstractFileSystem.abfss.impl":"org.apache.hadoop.fs.azurebfs.Abfss","yarn.sharedcache.uploader.server.address":"0.0.0.0:8046","yarn.resourcemanager.delegation-token.max-conf-size-bytes":"*********(redacted)","hadoop.http.authentication.token.validity":"*********(redacted)","mapreduce.shuffle.max.connections":"0","yarn.minicluster.yarn.nodemanager.resource.memory-mb":"4096","mapreduce.job.emit-timeline-data":"false","yarn.nodemanager.resource.system-reserved-memory-mb":"-1","hadoop.kerberos.min.seconds.before.relogin":"60","mapreduce.jobhistory.move.thread-count":"3","yarn.resourcemanager.admin.client.thread-count":"1","yarn.dispatcher.drain-events.timeout":"300000","ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds":"10s,20s,30s,40s","fs.s3a.buffer.dir":"${hadoop.tmp.dir}/s3a","hadoop.ssl.enabled.protocols":"TLSv1.2","mapreduce.jobhistory.admin.address":"0.0.0.0:10033","yarn.log-aggregation-status.time-out.ms":"600000","fs.s3a.accesspoint.required":"false","mapreduce.shuffle.port":"13562","yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory":"10","yarn.nodemanager.health-checker.interval-ms":"600000","yarn.router.clientrm.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor","yarn.resourcemanager.zk-appid-node.split-index":"0","ftp.blocksize":"67108864","yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions":"read","yarn.router.rmadmin.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor","yarn.nodemanager.log-container-debug-info.enabled":"true","yarn.resourcemanager.activities-manager.app-activities.max-queue-length":"100","yarn.resourcemanager.application-https.policy":"NONE","yarn.client.max-cached-nodemanagers-proxies":"0","yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms":"20","yarn.nodemanager.delete.debug-delay-sec":"0","yarn.nodemanager.pmem-check-enabled":"true","yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage":"90.0","mapreduce.app-submission.cross-platform":"false","yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms":"10000","yarn.nodemanager.container-retry-minimum-interval-ms":"1000","hadoop.security.groups.cache.secs":"300","yarn.federation.enabled":"false","yarn.workflow-id.tag-prefix":"workflowid:","fs.azure.local.sas.key.mode":"false","ipc.maximum.data.length":"134217728","fs.s3a.endpoint":"s3.amazonaws.com","mapreduce.shuffle.max.threads":"0","yarn.router.pipeline.cache-max-size":"25","yarn.resourcemanager.nm-container-queuing.load-comparator":"QUEUE_LENGTH","yarn.resourcemanager.resource-tracker.nm.ip-hostname-check":"false","hadoop.security.authorization":"false","mapreduce.job.complete.cancel.delegation.tokens":"*********(redacted)","fs.s3a.paging.maximum":"5000","nfs.exports.allowed.hosts":"* rw","yarn.nodemanager.amrmproxy.ha.enable":"false","fs.AbstractFileSystem.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","mapreduce.jobhistory.http.policy":"HTTP_ONLY","yarn.sharedcache.store.in-memory.check-period-mins":"720","hadoop.security.group.mapping.ldap.ssl":"false","fs.s3a.downgrade.syncable.exceptions":"true","yarn.client.application-client-protocol.poll-interval-ms":"200","yarn.scheduler.configuration.leveldb-store.compaction-interval-secs":"86400","yarn.timeline-service.writer.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl","ha.zookeeper.parent-znode":"/hadoop-ha","yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms":"60000","yarn.nodemanager.log-aggregation.policy.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy","mapreduce.reduce.shuffle.merge.percent":"0.66","hadoop.security.group.mapping.ldap.search.filter.group":"(objectClass=group)","yarn.resourcemanager.placement-constraints.scheduler.pool-size":"1","yarn.resourcemanager.activities-manager.cleanup-interval-ms":"5000","yarn.nodemanager.resourcemanager.minimum.version":"NONE","mapreduce.job.speculative.speculative-cap-running-tasks":"0.1","yarn.admin.acl":"*","ipc.[port_number].identity-provider.impl":"org.apache.hadoop.ipc.UserIdentityProvider","yarn.nodemanager.recovery.supervised":"false","yarn.sharedcache.admin.thread-count":"1","yarn.resourcemanager.ha.automatic-failover.enabled":"true","yarn.nodemanager.container-log-monitor.total-size-limit-bytes":"10000000000","mapreduce.reduce.skip.maxgroups":"0","mapreduce.reduce.shuffle.connect.timeout":"180000","yarn.nodemanager.health-checker.scripts":"script","yarn.resourcemanager.address":"${yarn.resourcemanager.hostname}:8032","ipc.client.ping":"true","mapreduce.task.local-fs.write-limit.bytes":"-1","fs.adl.oauth2.access.token.provider.type":"*********(redacted)","mapreduce.shuffle.ssl.file.buffer.size":"65536","yarn.resourcemanager.ha.automatic-failover.embedded":"true","yarn.nodemanager.resource-plugins.gpu.docker-plugin":"nvidia-docker-v1","fs.s3a.s3guard.consistency.retry.interval":"2s","fs.s3a.multipart.purge":"false","yarn.scheduler.configuration.store.class":"file","yarn.resourcemanager.nm-container-queuing.queue-limit-stdev":"1.0f","mapreduce.job.end-notification.max.attempts":"5","mapreduce.output.fileoutputformat.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled":"false","ipc.client.bind.wildcard.addr":"false","yarn.resourcemanager.webapp.rest-csrf.enabled":"false","ha.health-monitor.connect-retry-interval.ms":"1000","yarn.nodemanager.keytab":"/etc/krb5.keytab","mapreduce.jobhistory.keytab":"/etc/security/keytab/jhs.service.keytab","fs.s3a.threads.max":"64","yarn.nodemanager.runtime.linux.docker.image-update":"false","mapreduce.reduce.shuffle.input.buffer.percent":"0.70","fs.viewfs.overload.scheme.target.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","yarn.dispatcher.cpu-monitor.samples-per-min":"60","hadoop.security.token.service.use_ip":"*********(redacted)","yarn.nodemanager.runtime.linux.docker.allowed-container-networks":"host,none,bridge","yarn.nodemanager.node-labels.resync-interval-ms":"120000","hadoop.tmp.dir":"/tmp/hadoop-${user.name}","mapreduce.job.maps":"2","mapreduce.jobhistory.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.job.end-notification.max.retry.interval":"5000","yarn.log-aggregation.retain-check-interval-seconds":"-1","yarn.resourcemanager.resource-tracker.client.thread-count":"50","yarn.nodemanager.containers-launcher.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher","yarn.rm.system-metrics-publisher.emit-container-events":"false","yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size":"10000","yarn.resourcemanager.ha.automatic-failover.zk-base-path":"/yarn-leader-election","io.seqfile.local.dir":"${hadoop.tmp.dir}/io/local","fs.s3a.s3guard.ddb.throttle.retry.interval":"100ms","fs.AbstractFileSystem.wasb.impl":"org.apache.hadoop.fs.azure.Wasb","mapreduce.client.submit.file.replication":"10","mapreduce.jobhistory.minicluster.fixed.ports":"false","fs.s3a.multipart.threshold":"128M","yarn.resourcemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","mapreduce.jobhistory.done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done","ipc.server.purge.interval":"15","ipc.client.idlethreshold":"4000","yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage":"false","mapreduce.reduce.input.buffer.percent":"0.0","yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold":"1","yarn.nodemanager.webapp.rest-csrf.enabled":"false","fs.ftp.host.port":"21","ipc.ping.interval":"60000","yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size":"10","yarn.resourcemanager.admin.address":"${yarn.resourcemanager.hostname}:8033","file.client-write-packet-size":"65536","ipc.client.kill.max":"10","mapreduce.reduce.speculative":"true","hadoop.security.key.default.bitlength":"128","mapreduce.job.reducer.unconditional-preempt.delay.sec":"300","yarn.nodemanager.disk-health-checker.interval-ms":"120000","yarn.nodemanager.log.deletion-threads-count":"4","fs.s3a.committer.abort.pending.uploads":"true","yarn.webapp.filter-entity-list-by-user":"false","yarn.resourcemanager.activities-manager.app-activities.ttl-ms":"600000","ipc.client.connection.maxidletime":"10000","mapreduce.task.io.sort.mb":"100","yarn.nodemanager.localizer.client.thread-count":"5","io.erasurecode.codec.rs.rawcoders":"rs_native,rs_java","io.erasurecode.codec.rs-legacy.rawcoders":"rs-legacy_java","yarn.sharedcache.admin.address":"0.0.0.0:8047","yarn.resourcemanager.placement-constraints.algorithm.iterator":"SERIAL","yarn.nodemanager.localizer.cache.cleanup.interval-ms":"600000","hadoop.security.crypto.codec.classes.aes.ctr.nopadding":"org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec","mapreduce.job.cache.limit.max-resources-mb":"0","fs.s3a.connection.ssl.enabled":"true","yarn.nodemanager.process-kill-wait.ms":"5000","mapreduce.job.hdfs-servers":"${fs.defaultFS}","yarn.app.mapreduce.am.webapp.https.client.auth":"false","hadoop.workaround.non.threadsafe.getpwuid":"true","fs.df.interval":"60000","ipc.[port_number].decay-scheduler.thresholds":"13,25,50","fs.s3a.multiobjectdelete.enable":"true","yarn.sharedcache.cleaner.resource-sleep-ms":"0","yarn.nodemanager.disk-health-checker.min-healthy-disks":"0.25","hadoop.shell.missing.defaultFs.warning":"false","io.file.buffer.size":"65536","fs.viewfs.overload.scheme.target.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","hadoop.security.group.mapping.ldap.search.attr.member":"member","hadoop.security.random.device.file.path":"/dev/urandom","hadoop.security.sensitive-config-keys":"*********(redacted)","fs.s3a.s3guard.ddb.max.retries":"9","fs.viewfs.overload.scheme.target.file.impl":"org.apache.hadoop.fs.LocalFileSystem","hadoop.rpc.socket.factory.class.default":"org.apache.hadoop.net.StandardSocketFactory","yarn.intermediate-data-encryption.enable":"false","yarn.resourcemanager.connect.retry-interval.ms":"30000","yarn.nodemanager.container.stderr.pattern":"{*stderr*,*STDERR*}","yarn.scheduler.minimum-allocation-mb":"1024","yarn.app.mapreduce.am.staging-dir":"/tmp/hadoop-yarn/staging","mapreduce.reduce.shuffle.read.timeout":"180000","hadoop.http.cross-origin.max-age":"1800","io.erasurecode.codec.xor.rawcoders":"xor_native,xor_java","fs.s3a.s3guard.consistency.retry.limit":"7","fs.s3a.connection.establish.timeout":"5000","mapreduce.job.running.map.limit":"0","yarn.minicluster.control-resource-monitoring":"false","hadoop.ssl.require.client.cert":"false","hadoop.kerberos.kinit.command":"kinit","yarn.federation.state-store.class":"org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore","mapreduce.reduce.log.level":"INFO","hadoop.security.dns.log-slow-lookups.threshold.ms":"1000","mapreduce.job.ubertask.enable":"false","adl.http.timeout":"-1","yarn.resourcemanager.placement-constraints.retry-attempts":"3","hadoop.caller.context.enabled":"false","hadoop.security.group.mapping.ldap.num.attempts":"3","yarn.nodemanager.vmem-pmem-ratio":"2.1","hadoop.rpc.protection":"authentication","ha.health-monitor.rpc-timeout.ms":"45000","yarn.nodemanager.remote-app-log-dir":"/tmp/logs","hadoop.zk.timeout-ms":"10000","fs.s3a.s3guard.cli.prune.age":"86400000","yarn.nodemanager.resource.pcores-vcores-multiplier":"1.0","yarn.nodemanager.runtime.linux.sandbox-mode":"disabled","yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size":"10","fs.viewfs.overload.scheme.target.webhdfs.impl":"org.apache.hadoop.hdfs.web.WebHdfsFileSystem","fs.s3a.committer.threads":"8","hadoop.zk.retry-interval-ms":"1000","hadoop.security.crypto.buffer.size":"8192","yarn.nodemanager.node-labels.provider.fetch-interval-ms":"600000","mapreduce.jobhistory.recovery.store.leveldb.path":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.client.failover-retries-on-socket-timeouts":"0","fs.s3a.ssl.channel.mode":"default_jsse","yarn.nodemanager.resource.memory.enabled":"false","fs.azure.authorization.caching.enable":"true","hadoop.security.instrumentation.requires.admin":"false","yarn.nodemanager.delete.thread-count":"4","mapreduce.job.finish-when-all-reducers-done":"true","hadoop.registry.jaas.context":"Client","yarn.timeline-service.leveldb-timeline-store.path":"${hadoop.tmp.dir}/yarn/timeline","io.map.index.interval":"128","yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms":"100","fs.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","mapreduce.job.counters.max":"120","mapreduce.jobhistory.webapp.rest-csrf.enabled":"false","yarn.timeline-service.store-class":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.jobhistory.move.interval-ms":"180000","fs.s3a.change.detection.version.required":"true","yarn.nodemanager.localizer.fetch.thread-count":"4","yarn.resourcemanager.scheduler.client.thread-count":"50","hadoop.ssl.hostname.verifier":"DEFAULT","yarn.timeline-service.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/timeline","mapreduce.job.classloader":"false","mapreduce.task.profile.map.params":"${mapreduce.task.profile.params}","ipc.client.connect.timeout":"20000","hadoop.security.auth_to_local.mechanism":"hadoop","yarn.timeline-service.app-collector.linger-period.ms":"60000","yarn.nm.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.reservation-system.planfollower.time-step":"1000","yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms":"600000","yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed":"true","yarn.webapp.api-service.enable":"false","yarn.nodemanager.recovery.enabled":"false","mapreduce.job.end-notification.retry.interval":"1000","fs.du.interval":"600000","fs.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","yarn.nodemanager.container.stderr.tail.bytes":"4096","yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled":"true","hadoop.security.group.mapping.ldap.read.timeout.ms":"60000","hadoop.security.groups.cache.warn.after.ms":"5000","file.bytes-per-checksum":"512","mapreduce.outputcommitter.factory.scheme.s3a":"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory","hadoop.security.groups.cache.background.reload":"false","yarn.nodemanager.container-monitor.enabled":"true","yarn.nodemanager.elastic-memory-control.enabled":"false","net.topology.script.number.args":"100","mapreduce.task.merge.progress.records":"10000","yarn.nodemanager.localizer.address":"${yarn.nodemanager.hostname}:8040","yarn.timeline-service.keytab":"/etc/krb5.keytab","mapreduce.reduce.shuffle.fetch.retry.timeout-ms":"30000","yarn.resourcemanager.rm.container-allocation.expiry-interval-ms":"600000","yarn.nodemanager.container-executor.exit-code-file.timeout-ms":"2000","mapreduce.fileoutputcommitter.algorithm.version":"1","yarn.resourcemanager.work-preserving-recovery.enabled":"true","mapreduce.map.skip.maxrecords":"0","yarn.sharedcache.root-dir":"/sharedcache","fs.s3a.retry.throttle.limit":"20","hadoop.http.authentication.type":"simple","fs.viewfs.overload.scheme.target.oss.impl":"org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem","mapreduce.job.cache.limit.max-resources":"0","mapreduce.task.userlog.limit.kb":"0","ipc.[port_number].weighted-cost.handler":"1","yarn.resourcemanager.scheduler.monitor.enable":"false","ipc.client.connect.max.retries":"10","hadoop.registry.zk.retry.times":"5","yarn.nodemanager.resource-monitor.interval-ms":"3000","yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices":"auto","mapreduce.job.sharedcache.mode":"disabled","yarn.nodemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.shuffle.listen.queue.size":"128","yarn.scheduler.configuration.mutation.acl-policy.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy","mapreduce.map.cpu.vcores":"1","yarn.log-aggregation.file-formats":"TFile","yarn.timeline-service.client.fd-retain-secs":"300","fs.s3a.select.output.csv.field.delimiter":",","yarn.nodemanager.health-checker.timeout-ms":"1200000","hadoop.user.group.static.mapping.overrides":"dr.who=;","fs.azure.sas.expiry.period":"90d","fs.s3a.select.output.csv.record.delimiter":"\\n","mapreduce.jobhistory.recovery.store.class":"org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService","fs.viewfs.overload.scheme.target.https.impl":"org.apache.hadoop.fs.http.HttpsFileSystem","fs.s3a.s3guard.ddb.table.sse.enabled":"false","yarn.resourcemanager.fail-fast":"${yarn.fail-fast}","yarn.resourcemanager.proxy-user-privileges.enabled":"false","yarn.router.webapp.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST","yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage":"90.0","mapreduce.job.reducer.preempt.delay.sec":"0","hadoop.util.hash.type":"murmur","yarn.nodemanager.disk-validator":"basic","yarn.app.mapreduce.client.job.max-retries":"3","fs.viewfs.overload.scheme.target.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","mapreduce.reduce.shuffle.retry-delay.max.ms":"60000","hadoop.security.group.mapping.ldap.connection.timeout.ms":"60000","mapreduce.task.profile.params":"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s","yarn.app.mapreduce.shuffle.log.backups":"0","yarn.nodemanager.container-diagnostics-maximum-size":"10000","hadoop.registry.zk.retry.interval.ms":"1000","yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms":"1000","fs.AbstractFileSystem.file.impl":"org.apache.hadoop.fs.local.LocalFs","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds":"-1","mapreduce.jobhistory.cleaner.interval-ms":"86400000","hadoop.registry.zk.quorum":"localhost:2181","yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes":"runc","mapreduce.output.fileoutputformat.compress":"false","yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs":"*********(redacted)","fs.s3a.assumed.role.session.duration":"30m","hadoop.security.group.mapping.ldap.conversion.rule":"none","hadoop.ssl.server.conf":"ssl-server.xml","fs.s3a.retry.throttle.interval":"100ms","seq.io.sort.factor":"100","fs.viewfs.overload.scheme.target.ofs.impl":"org.apache.hadoop.fs.ozone.RootedOzoneFileSystem","yarn.sharedcache.cleaner.initial-delay-mins":"10","mapreduce.client.completion.pollinterval":"5000","hadoop.ssl.keystores.factory.class":"org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory","yarn.app.mapreduce.am.resource.cpu-vcores":"1","yarn.timeline-service.enabled":"false","yarn.nodemanager.runtime.linux.docker.capabilities":"CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE","yarn.acl.enable":"false","yarn.timeline-service.entity-group-fs-store.done-dir":"/tmp/entity-file-history/done/","hadoop.security.group.mapping.ldap.num.attempts.before.failover":"3","mapreduce.task.profile":"false","hadoop.prometheus.endpoint.enabled":"false","yarn.resourcemanager.fs.state-store.uri":"${hadoop.tmp.dir}/yarn/system/rmstore","mapreduce.jobhistory.always-scan-user-dir":"false","fs.s3a.metadatastore.metadata.ttl":"15m","yarn.nodemanager.opportunistic-containers-use-pause-for-preemption":"false","yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user":"nobody","yarn.timeline-service.reader.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl","yarn.resourcemanager.configuration.provider-class":"org.apache.hadoop.yarn.LocalConfigurationProvider","yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold":"1","yarn.resourcemanager.configuration.file-system-based-store":"/yarn/conf","mapreduce.job.cache.limit.max-single-resource-mb":"0","yarn.nodemanager.runtime.linux.docker.stop.grace-period":"10","yarn.resourcemanager.resource-profiles.source-file":"resource-profiles.json","mapreduce.job.dfs.storage.capacity.kill-limit-exceed":"false","yarn.nodemanager.resource.percentage-physical-cpu-limit":"100","mapreduce.jobhistory.client.thread-count":"10","tfile.fs.input.buffer.size":"262144","mapreduce.client.progressmonitor.pollinterval":"1000","yarn.nodemanager.log-dirs":"${yarn.log.dir}/userlogs","yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat":"-1","fs.automatic.close":"true","yarn.resourcemanager.delegation-token-renewer.thread-retry-interval":"*********(redacted)","fs.s3a.select.input.csv.quote.character":"\"","yarn.nodemanager.hostname":"0.0.0.0","ipc.[port_number].cost-provider.impl":"org.apache.hadoop.ipc.DefaultCostProvider","yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin","yarn.nodemanager.remote-app-log-dir-include-older":"true","yarn.nodemanager.resource.memory.cgroups.swappiness":"0","ftp.stream-buffer-size":"4096","yarn.fail-fast":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep":"100","yarn.timeline-service.app-aggregation-interval-secs":"15","hadoop.security.group.mapping.ldap.search.filter.user":"(&(objectClass=user)(sAMAccountName={0}))","ipc.[port_number].weighted-cost.lockshared":"10","yarn.nodemanager.container-localizer.log.level":"INFO","yarn.timeline-service.address":"${yarn.timeline-service.hostname}:10200","mapreduce.job.ubertask.maxmaps":"9","fs.s3a.threads.keepalivetime":"60","mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.task.files.preserve.failedtasks":"false","yarn.app.mapreduce.client.job.retry-interval":"2000","ha.failover-controller.graceful-fence.connection.retries":"1","fs.s3a.select.output.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.max-lifetime":"*********(redacted)","hadoop.kerberos.keytab.login.autorenewal.enabled":"false","yarn.timeline-service.client.drain-entities.timeout.ms":"2000","yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin","yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms":"1000","yarn.timeline-service.entity-group-fs-store.summary-store":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.reduce.cpu.vcores":"1","mapreduce.job.encrypted-intermediate-data.buffer.kb":"128","fs.client.resolve.remote.symlinks":"true","yarn.nodemanager.webapp.https.address":"0.0.0.0:8044","hadoop.http.cross-origin.allowed-origins":"*","mapreduce.job.encrypted-intermediate-data":"false","yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled":"true","fs.s3a.executor.capacity":"16","yarn.timeline-service.entity-group-fs-store.retain-seconds":"604800","yarn.resourcemanager.metrics.runtime.buckets":"60,300,1440","yarn.timeline-service.generic-application-history.max-applications":"10000","yarn.nodemanager.local-dirs":"${hadoop.tmp.dir}/nm-local-dir","mapreduce.shuffle.connection-keep-alive.enable":"false","yarn.node-labels.configuration-type":"centralized","fs.s3a.path.style.access":"false","yarn.nodemanager.aux-services.mapreduce_shuffle.class":"org.apache.hadoop.mapred.ShuffleHandler","yarn.sharedcache.store.in-memory.staleness-period-mins":"10080","fs.adl.impl":"org.apache.hadoop.fs.adl.AdlFileSystem","yarn.resourcemanager.application.max-tags":"10","hadoop.domainname.resolver.impl":"org.apache.hadoop.net.DNSDomainNameResolver","yarn.resourcemanager.nodemanager.minimum.version":"NONE","mapreduce.jobhistory.webapp.xfs-filter.xframe-options":"SAMEORIGIN","yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled":"false","net.topology.impl":"org.apache.hadoop.net.NetworkTopology","io.map.index.skip":"0","yarn.timeline-service.reader.webapp.https.address":"${yarn.timeline-service.webapp.https.address}","fs.ftp.data.connection.mode":"ACTIVE_LOCAL_DATA_CONNECTION_MODE","mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed":"true","fs.azure.buffer.dir":"${hadoop.tmp.dir}/abfs","yarn.scheduler.maximum-allocation-vcores":"4","hadoop.http.cross-origin.allowed-headers":"X-Requested-With,Content-Type,Accept,Origin","yarn.nodemanager.log-aggregation.compression-type":"none","yarn.timeline-service.version":"1.0f","yarn.ipc.rpc.class":"org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC","mapreduce.reduce.maxattempts":"4","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size":"1000","hadoop.security.dns.log-slow-lookups.enabled":"false","mapreduce.job.committer.setup.cleanup.needed":"true","hadoop.security.secure.random.impl":"org.apache.hadoop.crypto.random.OpensslSecureRandom","mapreduce.job.running.reduce.limit":"0","fs.s3a.select.errors.include.sql":"false","fs.s3a.connection.request.timeout":"0","ipc.maximum.response.length":"134217728","yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.job.token.tracking.ids.enabled":"*********(redacted)","hadoop.caller.context.max.size":"128","yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed":"false","yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed":"false","hadoop.registry.system.acls":"sasl:yarn@, sasl:mapred@, sasl:hdfs@","yarn.nodemanager.recovery.dir":"${hadoop.tmp.dir}/yarn-nm-recovery","fs.s3a.fast.upload.buffer":"disk","mapreduce.jobhistory.intermediate-done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate","yarn.app.mapreduce.shuffle.log.separate":"true","yarn.log-aggregation.debug.filesize":"104857600","fs.s3a.max.total.tasks":"32","fs.s3a.readahead.range":"64K","hadoop.http.authentication.simple.anonymous.allowed":"true","fs.s3a.attempts.maximum":"20","hadoop.registry.zk.connection.timeout.ms":"15000","yarn.resourcemanager.delegation-token-renewer.thread-count":"*********(redacted)","yarn.resourcemanager.delegation-token-renewer.thread-timeout":"*********(redacted)","yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size":"10000","yarn.nodemanager.aux-services.manifest.reload-ms":"0","yarn.nodemanager.emit-container-events":"true","yarn.resourcemanager.resource-profiles.enabled":"false","yarn.timeline-service.hbase-schema.prefix":"prod.","fs.azure.authorization":"false","mapreduce.map.log.level":"INFO","ha.failover-controller.active-standby-elector.zk.op.retries":"3","yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs":"20","mapreduce.output.fileoutputformat.compress.type":"RECORD","yarn.resourcemanager.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/system/rmstore","yarn.timeline-service.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.ifile.readahead.bytes":"4194304","yarn.sharedcache.app-checker.class":"org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker","yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users":"true","yarn.nodemanager.resource.detect-hardware-capabilities":"false","mapreduce.cluster.acls.enabled":"false","mapreduce.job.speculative.retry-after-no-speculate":"1000","fs.viewfs.overload.scheme.target.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","hadoop.security.group.mapping.ldap.search.group.hierarchy.levels":"0","yarn.resourcemanager.fs.state-store.retry-interval-ms":"1000","file.stream-buffer-size":"4096","yarn.resourcemanager.application-timeouts.monitor.interval-ms":"3000","mapreduce.map.output.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","mapreduce.map.speculative":"true","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file":"/runc-root/image-tag-to-hash","mapreduce.job.speculative.retry-after-speculate":"15000","yarn.nodemanager.linux-container-executor.cgroups.mount":"false","yarn.app.mapreduce.am.container.log.backups":"0","yarn.app.mapreduce.am.log.level":"INFO","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin","io.bytes.per.checksum":"512","mapreduce.job.reduce.slowstart.completedmaps":"0.05","yarn.timeline-service.http-authentication.type":"simple","hadoop.security.group.mapping.ldap.search.attr.group.name":"cn","yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices":"auto","yarn.timeline-service.client.internal-timers-ttl-secs":"420","fs.s3a.select.output.csv.quote.character":"\"","hadoop.http.logs.enabled":"true","fs.s3a.block.size":"32M","yarn.sharedcache.client-server.address":"0.0.0.0:8045","yarn.nodemanager.logaggregation.threadpool-size-max":"100","yarn.resourcemanager.hostname":"0.0.0.0","yarn.resourcemanager.delegation.key.update-interval":"86400000","mapreduce.reduce.shuffle.fetch.retry.enabled":"${yarn.nodemanager.recovery.enabled}","mapreduce.map.memory.mb":"-1","mapreduce.task.skip.start.attempts":"2","fs.AbstractFileSystem.hdfs.impl":"org.apache.hadoop.fs.Hdfs","yarn.nodemanager.disk-health-checker.enable":"true","fs.s3a.select.output.csv.quote.fields":"always","ipc.client.tcpnodelay":"true","ipc.client.rpc-timeout.ms":"0","yarn.nodemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts":"*********(redacted)","ipc.client.low-latency":"false","mapreduce.input.lineinputformat.linespermap":"1","yarn.router.interceptor.user.threadpool-size":"5","ipc.client.connect.max.retries.on.timeouts":"45","yarn.timeline-service.leveldb-timeline-store.read-cache-size":"104857600","fs.AbstractFileSystem.har.impl":"org.apache.hadoop.fs.HarFs","mapreduce.job.split.metainfo.maxsize":"10000000","yarn.am.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.timeline-service.entity-group-fs-store.app-cache-size":"10","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs":"360","fs.s3a.socket.recv.buffer":"8192","rpc.metrics.timeunit":"MILLISECONDS","yarn.resourcemanager.resource-tracker.address":"${yarn.resourcemanager.hostname}:8031","yarn.nodemanager.node-labels.provider.fetch-timeout-ms":"1200000","mapreduce.job.heap.memory-mb.ratio":"0.8","yarn.resourcemanager.leveldb-state-store.compaction-interval-secs":"3600","yarn.resourcemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","yarn.nodemanager.pluggable-device-framework.enabled":"false","yarn.scheduler.configuration.fs.path":"file://${hadoop.tmp.dir}/yarn/system/schedconf","mapreduce.client.output.filter":"FAILED","hadoop.http.filter.initializers":"org.apache.hadoop.http.lib.StaticUserWebFilter","mapreduce.reduce.memory.mb":"-1","yarn.timeline-service.hostname":"0.0.0.0","file.replication":"1","yarn.nodemanager.container-metrics.unregister-delay-ms":"10000","yarn.nodemanager.container-metrics.period-ms":"-1","mapreduce.fileoutputcommitter.task.cleanup.enabled":"false","yarn.nodemanager.log.retain-seconds":"10800","yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds":"3600","ipc.[port_number].callqueue.impl":"java.util.concurrent.LinkedBlockingQueue","yarn.resourcemanager.keytab":"/etc/krb5.keytab","hadoop.security.group.mapping.providers.combined":"true","mapreduce.reduce.merge.inmem.threshold":"1000","yarn.timeline-service.recovery.enabled":"false","fs.azure.saskey.usecontainersaskeyforallaccess":"true","yarn.sharedcache.nm.uploader.thread-count":"20","yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs":"3600","ipc.[port_number].weighted-cost.lockfree":"1","mapreduce.shuffle.ssl.enabled":"false","yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds":"259200000","yarn.nodemanager.opportunistic-containers-max-queue-length":"0","yarn.resourcemanager.state-store.max-completed-applications":"${yarn.resourcemanager.max-completed-applications}","mapreduce.job.speculative.minimum-allowed-tasks":"10","fs.s3a.aws.credentials.provider":"\n    org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,\n    org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,\n    com.amazonaws.auth.EnvironmentVariableCredentialsProvider,\n    org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider\n  ","yarn.log-aggregation.retain-seconds":"-1","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb":"0","mapreduce.jobhistory.max-age-ms":"604800000","hadoop.http.cross-origin.allowed-methods":"GET,POST,HEAD","yarn.resourcemanager.opportunistic-container-allocation.enabled":"false","mapreduce.jobhistory.webapp.address":"0.0.0.0:19888","hadoop.system.tags":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.log-aggregation.file-controller.TFile.class":"org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController","yarn.client.nodemanager-connect.max-wait-ms":"180000","yarn.resourcemanager.webapp.address":"${yarn.resourcemanager.hostname}:8088","mapreduce.jobhistory.recovery.enable":"false","mapreduce.reduce.shuffle.parallelcopies":"5","fs.AbstractFileSystem.webhdfs.impl":"org.apache.hadoop.fs.WebHdfs","fs.trash.interval":"0","yarn.app.mapreduce.client.max-retries":"3","hadoop.security.authentication":"simple","mapreduce.task.profile.reduce.params":"${mapreduce.task.profile.params}","yarn.app.mapreduce.am.resource.mb":"1536","mapreduce.input.fileinputformat.list-status.num-threads":"1","yarn.nodemanager.container-executor.class":"org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor","io.mapfile.bloom.size":"1048576","yarn.timeline-service.ttl-ms":"604800000","yarn.resourcemanager.nm-container-queuing.min-queue-length":"5","yarn.nodemanager.resource.cpu-vcores":"-1","mapreduce.job.reduces":"1","fs.s3a.multipart.size":"64M","fs.s3a.select.input.csv.comment.marker":"#","yarn.scheduler.minimum-allocation-vcores":"1","mapreduce.job.speculative.speculative-cap-total-tasks":"0.01","hadoop.ssl.client.conf":"ssl-client.xml","mapreduce.job.queuename":"default","mapreduce.job.encrypted-intermediate-data-key-size-bits":"128","fs.s3a.metadatastore.authoritative":"false","ipc.[port_number].weighted-cost.response":"1","yarn.nodemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","ha.health-monitor.sleep-after-disconnect.ms":"1000","yarn.app.mapreduce.shuffle.log.limit.kb":"0","hadoop.security.group.mapping":"org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback","yarn.client.application-client-protocol.poll-timeout-ms":"-1","mapreduce.jobhistory.jhist.format":"binary","mapreduce.task.stuck.timeout-ms":"600000","yarn.resourcemanager.application.max-tag.length":"100","yarn.resourcemanager.ha.enabled":"false","dfs.client.ignore.namenode.default.kms.uri":"false","hadoop.http.staticuser.user":"dr.who","mapreduce.task.exit.timeout.check-interval-ms":"20000","mapreduce.jobhistory.intermediate-user-done-dir.permissions":"770","mapreduce.task.exit.timeout":"60000","yarn.nodemanager.linux-container-executor.resources-handler.class":"org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler","mapreduce.reduce.shuffle.memory.limit.percent":"0.25","yarn.resourcemanager.reservation-system.enable":"false","mapreduce.map.output.compress":"false","ha.zookeeper.acl":"world:anyone:rwcda","ipc.server.max.connections":"0","yarn.nodemanager.runtime.linux.docker.default-container-network":"host","yarn.router.webapp.address":"0.0.0.0:8089","yarn.scheduler.maximum-allocation-mb":"8192","yarn.resourcemanager.scheduler.monitor.policies":"org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy","yarn.sharedcache.cleaner.period-mins":"1440","yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint":"http://localhost:3476/v1.0/docker/cli","yarn.app.mapreduce.am.container.log.limit.kb":"0","ipc.client.connect.retry.interval":"1000","yarn.timeline-service.http-cross-origin.enabled":"false","fs.wasbs.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure","yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms":"1000","yarn.federation.subcluster-resolver.class":"org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl","yarn.resourcemanager.zk-state-store.parent-path":"/rmstore","fs.s3a.select.input.csv.field.delimiter":",","mapreduce.jobhistory.cleaner.enable":"true","yarn.timeline-service.client.fd-flush-interval-secs":"10","hadoop.security.kms.client.encrypted.key.cache.expiry":"43200000","yarn.client.nodemanager-client-async.thread-pool-max-size":"500","mapreduce.map.maxattempts":"4","yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms":"1000","fs.s3a.committer.staging.tmp.path":"tmp/staging","yarn.nodemanager.sleep-delay-before-sigkill.ms":"250","yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms":"10","mapreduce.job.end-notification.retry.attempts":"0","yarn.nodemanager.resource.count-logical-processors-as-cores":"false","hadoop.registry.zk.root":"/registry","adl.feature.ownerandgroup.enableupn":"false","yarn.resourcemanager.zk-max-znode-size.bytes":"1048576","mapreduce.job.reduce.shuffle.consumer.plugin.class":"org.apache.hadoop.mapreduce.task.reduce.Shuffle","yarn.resourcemanager.delayed.delegation-token.removal-interval-ms":"*********(redacted)","yarn.nodemanager.localizer.cache.target-size-mb":"10240","fs.s3a.committer.staging.conflict-mode":"append","mapreduce.client.libjars.wildcard":"true","fs.s3a.committer.staging.unique-filenames":"true","yarn.nodemanager.node-attributes.provider.fetch-timeout-ms":"1200000","fs.s3a.list.version":"2","ftp.client-write-packet-size":"65536","ipc.[port_number].weighted-cost.lockexclusive":"100","fs.AbstractFileSystem.adl.impl":"org.apache.hadoop.fs.adl.Adl","yarn.nodemanager.container-log-monitor.enable":"false","hadoop.security.key.default.cipher":"AES/CTR/NoPadding","yarn.client.failover-retries":"0","fs.s3a.multipart.purge.age":"86400","mapreduce.job.local-fs.single-disk-limit.check.interval-ms":"5000","net.topology.node.switch.mapping.impl":"org.apache.hadoop.net.ScriptBasedMapping","yarn.nodemanager.amrmproxy.address":"0.0.0.0:8049","ipc.server.listen.queue.size":"256","ipc.[port_number].decay-scheduler.period-ms":"5000","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs":"60","map.sort.class":"org.apache.hadoop.util.QuickSort","fs.viewfs.rename.strategy":"SAME_MOUNTPOINT","hadoop.security.kms.client.authentication.retry-count":"1","fs.permissions.umask-mode":"022","fs.s3a.assumed.role.credentials.provider":"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed":"false","yarn.nodemanager.vmem-check-enabled":"true","yarn.nodemanager.numa-awareness.enabled":"false","yarn.nodemanager.recovery.compaction-interval-secs":"3600","yarn.app.mapreduce.client-am.ipc.max-retries":"3","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds":"60","yarn.federation.registry.base-dir":"yarnfederation/","yarn.nodemanager.health-checker.run-before-startup":"false","mapreduce.job.max.map":"-1","mapreduce.job.local-fs.single-disk-limit.bytes":"-1","mapreduce.shuffle.pathcache.concurrency-level":"16","mapreduce.job.ubertask.maxreduces":"1","mapreduce.shuffle.pathcache.max-weight":"10485760","hadoop.security.kms.client.encrypted.key.cache.size":"500","hadoop.security.java.secure.random.algorithm":"SHA1PRNG","ha.failover-controller.cli-check.rpc-timeout.ms":"20000","mapreduce.jobhistory.jobname.limit":"50","fs.s3a.select.input.compression":"none","yarn.client.nodemanager-connect.retry-interval-ms":"10000","ipc.[port_number].scheduler.priority.levels":"4","yarn.timeline-service.state-store-class":"org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore","yarn.nodemanager.env-whitelist":"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ","yarn.sharedcache.nested-level":"3","yarn.timeline-service.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","fs.azure.user.agent.prefix":"unknown","yarn.resourcemanager.zk-delegation-token-node.split-index":"*********(redacted)","yarn.nodemanager.numa-awareness.read-topology":"false","yarn.nodemanager.webapp.address":"${yarn.nodemanager.hostname}:8042","rpc.metrics.quantile.enable":"false","yarn.registry.class":"org.apache.hadoop.registry.client.impl.FSRegistryOperationsService","mapreduce.jobhistory.admin.acl":"*","yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size":"10","yarn.scheduler.queue-placement-rules":"user-group","hadoop.http.authentication.kerberos.keytab":"${user.home}/hadoop.keytab","yarn.resourcemanager.recovery.enabled":"false","fs.s3a.select.input.csv.header":"none","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size":"500","yarn.timeline-service.webapp.rest-csrf.enabled":"false","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb":"0"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.maintenance.version":"4","java.specification.version":"1.8","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Private Build","java.vm.specification.version":"1.8","user.home":"/root","file.encoding.pkg":"sun.io","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64","user.dir":"/scripts","java.library.path":"/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"25.352-b08","jetty.git.hash":"6b67c5719d1f4371b33655ff2d047d24e171e49a","java.endorsed.dirs":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed","java.runtime.version":"1.8.0_352-8u352-ga-1~20.04-b08","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"52.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes","file.encoding":"UTF-8","user.timezone":"Europe/Berlin","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"5.15.0-53-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Private Build","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"root","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"*********(redacted)","java.home":"/usr/lib/jvm/java-8-openjdk-amd64/jre","java.version":"1.8.0_352","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-policy-5.12.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.datastax.oss_native-protocol-1.4.10.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-network-shuffle_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/HikariCP-2.5.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/univocity-parsers-2.9.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/flatbuffers-java-1.12.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-dbcp-1.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/stax-api-1.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-metrics-5.12.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/okhttp-3.12.12.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-core-asl-1.9.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.ws.rs-api-2.1.6.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.spark-project.spark_unused-1.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-platform_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/compress-lzf-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-api-2.17.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.google.code.findbugs_jsr305-3.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-cli-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-scalap_2.12-3.7.0-M11.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-pool-1.5.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/tink-1.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-sketch_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-memory-netty-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-kvstore_2.12-3.3.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.squareup.retrofit2_converter-moshi-2.4.0.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-util_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/slf4j-api-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/chill-java-0.10.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javolution-5.5.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.squareup.moshi_moshi-1.5.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/blas-2.2.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.github.luben_zstd-jni-1.5.2-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/chill_2.12-0.10.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/JLargeArrays-1.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-locator-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-ipc-1.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-encoding-1.12.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar":"Added By User","spark://f9cd076e3ae4:42681/files/org.apache.hadoop_hadoop-client-api-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-jdbc-2.3.9.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.squareup.moshi_moshi-1.5.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/shapeless_2.12-2.3.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-macros_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/algebra_2.12-2.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.lz4_lz4-java-1.8.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-logging-1.1.3.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.squareup.okio_okio-1.14.0.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.squareup.okhttp3_okhttp-3.11.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-reflect-2.12.15.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar":"Added By User","spark://f9cd076e3ae4:42681/files/org.influxdb_influxdb-java-2.14.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-tcnative-classes-2.0.48.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-compiler-3.0.16.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-rdbms-4.1.19.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-batch-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-math3-3.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/snappy-java-1.1.8.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jpam-1.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","spark://f9cd076e3ae4:42681/files/org.reactivestreams_reactive-streams-1.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/paranamer-2.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/aopalliance-repackaged-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/minlog-1.3.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arpack-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/aircompressor-0.21.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.msgpack_msgpack-core-0.8.16.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.thoughtworks.paranamer_paranamer-2.8.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/xbean-asm9-shaded-4.20.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/lz4-java-1.8.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/osgi-resource-locator-1.0.3.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/automaton-1.11-8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jdo-api-3.0.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-2.3.9.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.datastax.oss_java-driver-core-shaded-4.7.2.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.typesafe_config-1.3.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/derby-10.14.2.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-mapreduce-1.7.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/velocity-1.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/stream-2.9.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jaxb-runtime-2.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-sql_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zookeeper-3.6.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-server-2.36.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.squareup.okio_okio-1.14.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-vector-code-gen-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/protobuf-java-2.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-core_2.12-3.7.0-M11.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-memory-core-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-autoscaling-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/guava-14.0.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.apache.commons_commons-lang3-3.9.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/com.typesafe_config-1.3.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-common-2.3.9.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.squareup.retrofit2_retrofit-2.4.0.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mesos_2.12-3.3.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/shims-0.9.25.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-datatype-jsr310-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-network-common_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/RoaringBitmap-0.9.25.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/istack-commons-runtime-3.0.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/httpcore-4.4.14.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-module-scala_2.12-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-handler-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-api-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-exec-2.3.9-core.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/breeze_2.12-1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/httpclient-4.5.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-cli-1.5.0.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/libthrift-0.12.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-yarn_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-unix-common-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jul-to-slf4j-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jta-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-catalyst_2.12-3.3.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/ST4-4.0.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-shaded-guava-1.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-apiextensions-5.12.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.javatuples_javatuples-1.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-collection-compat_2.12-2.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire_2.12-0.17.0.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.datastax.oss_java-driver-core-shaded-4.7.2.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/commons-logging_commons-logging-1.1.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/libfb303-0.9.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-admissionregistration-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-text-1.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/super-csv-2.2.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/leveldbjni-all-1.8.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.thoughtworks.paranamer_paranamer-2.8.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-io-2.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-hk2-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/JTransforms-3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-node-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-service-rpc-3.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-dataformat-yaml-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-framework-2.13.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-kubernetes_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-compress-1.21.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-yarn-server-web-proxy-3.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-mapred-1.11.0.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.slf4j_slf4j-api-1.7.36.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-api-jdo-4.2.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-core_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/janino-3.0.16.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-library-2.12.15.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-metastore-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-1.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/opencsv-2.3.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.3.1.jar":"Added By User","spark://f9cd076e3ae4:42681/files/org.hdrhistogram_HdrHistogram-2.1.11.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/com.squareup.retrofit2_retrofit-2.4.0.jar":"Added By User","spark://f9cd076e3ae4:42681/files/org.msgpack_msgpack-core-0.8.16.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-codec-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-jackson_2.12-3.7.0-M11.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-compiler-2.12.15.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-databind-2.13.4.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/oro-2.0.8.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-all-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/mesos-1.4.3-shaded-protobuf.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-classes-kqueue-4.1.74.Final.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-container-servlet-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jsr305-3.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-coordination-5.12.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.github.luben_zstd-jni-1.5.2-1.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/okio-1.14.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-graphite-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-lang3-3.12.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/xz-1.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/antlr4-runtime-4.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-buffer-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-jmx-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/lapack-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-rbac-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-jvm-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/conf":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-common-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-serde-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-flowcontrol-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/audience-annotations-0.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-repl_2.12-3.3.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.scala-lang_scala-reflect-2.12.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-1.2-api-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-classes-epoll-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-storageclass-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-discovery-5.12.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.influxdb_influxdb-java-2.14.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mllib_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-vector-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-core-2.13.4.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.validation-api-2.0.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.inject-2.6.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.spark-project.spark_unused-1.0.0.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javassist-3.25.0-GA.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-format-structures-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-core-1.7.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jcl-over-slf4j-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-graphx_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-storage-api-2.7.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.apache.commons_commons-lang3-3.9.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.19.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-hive_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-codec-1.15.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-jackson-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-core-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/breeze-macros_2.12-1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mllib-local_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-tags_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-common-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json-1.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-common-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/py4j-0.10.9.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-parser-combinators_2.12-1.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-scheduler-2.3.9.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.datastax.oss_native-protocol-1.4.10.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-shims-1.7.6.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.apache.kafka_kafka-clients-3.2.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-xml_2.12-1.2.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-format-7.0.0.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.hdrhistogram_HdrHistogram-2.1.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-collections-3.2.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.annotation-api-1.3.5.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/io.dropwizard.metrics_metrics-core-4.0.5.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jodd-core-3.5.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/cats-kernel_2.12-2.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zstd-jni-1.5.2-1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/antlr-runtime-3.5.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/joda-time-2.10.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-0.23-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-annotations-2.13.4.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.javatuples_javatuples-1.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-recipes-2.13.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/gson-2.2.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/activation-1.1.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/commons-logging_commons-logging-1.1.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/bonecp-0.8.0.RELEASE.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-client-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/ivy-2.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-core-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-networking-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-unsafe_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zookeeper-jute-3.6.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-utils-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-mapper-asl-1.9.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-crypto-1.1.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javax.jdo-3.2.0-m3.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.lz4_lz4-java-1.8.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-lang-2.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jline-2.14.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-beeline-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-client-2.13.0.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.xerial.snappy_snappy-java-1.1.8.4.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/transaction-api-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.apache.kafka_kafka-clients-3.2.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-ast_2.12-3.7.0-M11.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/io.dropwizard.metrics_metrics-core-4.0.5.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/com.google.code.findbugs_jsr305-3.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/core-1.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/rocksdbjni-6.20.3.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar":"Added By User","spark://f9cd076e3ae4:42681/files/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar":"Added By User","spark://f9cd076e3ae4:42681/jars/org.reactivestreams_reactive-streams-1.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/threeten-extra-1.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-core-4.1.17.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-core-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-common-2.36.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-scheduling-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-llap-common-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.xml.bind-api-2.3.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.datastax.oss_java-driver-query-builder-4.7.2.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.fasterxml.jackson.core_jackson-core-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-common-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-tags_2.12-3.3.1-tests.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-certificates-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/logging-interceptor-3.12.12.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-json-4.2.7.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.datastax.oss_java-driver-query-builder-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/pickle-1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-resolver-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-client-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-events-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-extensions-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.servlet-api-4.0.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-api-3.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-container-servlet-core-2.36.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.squareup.okhttp3_okhttp-3.11.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/objenesis-3.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.slf4j_slf4j-api-1.7.36.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zjsonpatch-0.3.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/annotations-17.0.0.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/com.github.spotbugs_spotbugs-annotations-3.1.12.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-hive-thriftserver_2.12-3.3.1.jar":"System Classpath","spark://f9cd076e3ae4:42681/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/snakeyaml-1.31.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-apps-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-hadoop-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/ch.cern.sparkmeasure_spark-measure_2.12-0.19.jar":"Added By User","spark://f9cd076e3ae4:42681/files/com.squareup.okhttp3_logging-interceptor-3.11.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-streaming_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-column-1.12.2.jar":"System Classpath","spark://f9cd076e3ae4:42681/files/org.scala-lang_scala-reflect-2.12.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-launcher_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-collections4-4.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arpack_combined_all-0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/generex-1.0.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kryo-shaded-4.0.2.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"Testing the Stream with Kafka","App ID":"app-20221125001659-0001","Timestamp":1669331818076,"User":"root"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1669331822664,"Executor ID":"0","Executor Info":{"Host":"172.20.0.13","Total Cores":1,"Log Urls":{"stdout":"http://172.20.0.13:8081/logPage/?appId=app-20221125001659-0001&executorId=0&logType=stdout","stderr":"http://172.20.0.13:8081/logPage/?appId=app-20221125001659-0001&executorId=0&logType=stderr"},"Attributes":{},"Resources":{},"Resource Profile Id":0}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"172.20.0.13","Port":36571},"Maximum Memory":384093388,"Timestamp":1669331822745,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:04.722Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:05.294Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:04.800Z","batchId":1,"batchDuration":807,"durationMs":{"triggerExecution":806,"latestOffset":743},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":0,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:05.625 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:05.625 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":3,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":4,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1,"metricType":"timing"}]},"time":1669331826468,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":1,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#63, value#64, timestamp#65, current_timestamp#66]\nArguments: [topic#63, value#64, timestamp#65, current_timestamp#66], SQLExecutionRDD[3] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#63, value#64, timestamp#65, current_timestamp#66]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@36f30618, org.apache.spark.sql.connector.write.WriteBuilder$1@59f45cdd\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@36f30618, org.apache.spark.sql.connector.write.WriteBuilder$1@59f45cdd","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#63,value#64,timestamp#65,current_timestamp#66]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":6,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":5,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331829175,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1669331829299,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"6\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[0],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"1","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"6\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331829321,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"1","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331829523,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331829523,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331833732,"Failed":false,"Killed":false,"Accumulables":[{"ID":7,"Name":"internal.metrics.executorDeserializeTime","Update":519,"Value":519,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.executorDeserializeCpuTime","Update":458373007,"Value":458373007,"Internal":true,"Count Failed Values":true},{"ID":9,"Name":"internal.metrics.executorRunTime","Update":3612,"Value":3612,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.executorCpuTime","Update":2295639077,"Value":2295639077,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.resultSize","Update":1163,"Value":1163,"Internal":true,"Count Failed Values":true},{"ID":12,"Name":"internal.metrics.jvmGCTime","Update":122,"Value":122,"Internal":true,"Count Failed Values":true},{"ID":13,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":519,"Executor Deserialize CPU Time":458373007,"Executor Run Time":3612,"Executor CPU Time":2295639077,"Peak Execution Memory":0,"Result Size":1163,"JVM GC Time":122,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"6\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331829321,"Completion Time":1669331833744,"Accumulables":[{"ID":7,"Name":"internal.metrics.executorDeserializeTime","Value":519,"Internal":true,"Count Failed Values":true},{"ID":8,"Name":"internal.metrics.executorDeserializeCpuTime","Value":458373007,"Internal":true,"Count Failed Values":true},{"ID":9,"Name":"internal.metrics.executorRunTime","Value":3612,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.executorCpuTime","Value":2295639077,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.resultSize","Value":1163,"Internal":true,"Count Failed Values":true},{"ID":12,"Name":"internal.metrics.jvmGCTime","Value":122,"Internal":true,"Count Failed Values":true},{"ID":13,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1669331833750,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":1,"time":1669331833755}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":0,"time":1669331833760}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:05.299Z","batchId":0,"batchDuration":8512,"durationMs":{"triggerExecution":8512,"queryPlanning":672,"getBatch":7,"latestOffset":324,"addBatch":7406,"walCommit":36},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":null,"endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:15.631Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:23.829Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:25.641Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:33.838Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:35.647Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:43.843Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:45.648Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":2,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:47.726 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:47.726 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":34,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":35,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":36,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":32,"metricType":"timing"}]},"time":1669331867817,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":3,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7ebff9d9, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@7ead5ce4\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@338df78, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5f29c139","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":37,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":38,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":39,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":33,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331867817,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":4,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7ff6b7eb, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@630e96df\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@338df78, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5f29c139","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":37,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":38,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":39,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":33,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331867832,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1669331867889,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"DataSourceRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[1],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"4","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"DataSourceRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331867894,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"4","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331867916,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":5,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#90, value#91, timestamp#92, current_timestamp#93]\nArguments: [topic#90, value#91, timestamp#92, current_timestamp#93], SQLExecutionRDD[9] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#90, value#91, timestamp#92, current_timestamp#93]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@3eca4242, org.apache.spark.sql.connector.write.WriteBuilder$1@54becc06\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@3eca4242, org.apache.spark.sql.connector.write.WriteBuilder$1@54becc06","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#90,value#91,timestamp#92,current_timestamp#93]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":66,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":65,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331867938,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1669331867975,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"DataSourceRDD","Scope":"{\"id\":\"11\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"8\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[2],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"5","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"DataSourceRDD","Scope":"{\"id\":\"11\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"8\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331867976,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"5","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870122,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331867916,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331870126,"Failed":false,"Killed":false,"Accumulables":[{"ID":33,"Name":"duration","Update":"1474","Value":"1474","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":37,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":40,"Name":"internal.metrics.executorDeserializeTime","Update":271,"Value":271,"Internal":true,"Count Failed Values":true},{"ID":41,"Name":"internal.metrics.executorDeserializeCpuTime","Update":231392440,"Value":231392440,"Internal":true,"Count Failed Values":true},{"ID":42,"Name":"internal.metrics.executorRunTime","Update":1918,"Value":1918,"Internal":true,"Count Failed Values":true},{"ID":43,"Name":"internal.metrics.executorCpuTime","Update":1776189219,"Value":1776189219,"Internal":true,"Count Failed Values":true},{"ID":44,"Name":"internal.metrics.resultSize","Update":1801,"Value":1801,"Internal":true,"Count Failed Values":true},{"ID":45,"Name":"internal.metrics.jvmGCTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":62,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":55630288,"JVMOffHeapMemory":102846048,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":15493,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":15493,"OffHeapUnifiedMemory":0,"DirectPoolMemory":19253,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":8,"MinorGCTime":126,"MajorGCCount":3,"MajorGCTime":188,"TotalGCTime":314},"Task Metrics":{"Executor Deserialize Time":271,"Executor Deserialize CPU Time":231392440,"Executor Run Time":1918,"Executor CPU Time":1776189219,"Peak Execution Memory":0,"Result Size":1801,"JVM GC Time":22,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"DataSourceRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"15\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331867894,"Completion Time":1669331870128,"Accumulables":[{"ID":33,"Name":"duration","Value":"1474","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":37,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":40,"Name":"internal.metrics.executorDeserializeTime","Value":271,"Internal":true,"Count Failed Values":true},{"ID":41,"Name":"internal.metrics.executorDeserializeCpuTime","Value":231392440,"Internal":true,"Count Failed Values":true},{"ID":42,"Name":"internal.metrics.executorRunTime","Value":1918,"Internal":true,"Count Failed Values":true},{"ID":43,"Name":"internal.metrics.executorCpuTime","Value":1776189219,"Internal":true,"Count Failed Values":true},{"ID":44,"Name":"internal.metrics.resultSize","Value":1801,"Internal":true,"Count Failed Values":true},{"ID":45,"Name":"internal.metrics.jvmGCTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":62,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1669331870128,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":4,"time":1669331870130}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":3,"time":1669331870130}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:47.725Z","batchId":1,"batchDuration":2434,"durationMs":{"triggerExecution":2434,"queryPlanning":36,"getBatch":0,"latestOffset":1,"addBatch":2328,"walCommit":38},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":1}}","latestOffset":"{\"12003800_test\":{\"0\":1}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":0.4108463434675431,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":6,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7b7d9e72, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@42621ee4\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2c857224, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@436fcbb1","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":93,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":94,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":95,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":92,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331870239,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":7,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5aa07ae4, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@530f9596\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2c857224, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@436fcbb1","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":93,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":94,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":95,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":92,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331870276,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1669331870292,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"DataSourceRDD","Scope":"{\"id\":\"24\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[3],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"7","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"DataSourceRDD","Scope":"{\"id\":\"24\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331870296,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"7","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870425,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870122,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331870429,"Failed":false,"Killed":false,"Accumulables":[{"ID":32,"Name":"duration","Update":"205","Value":"205","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":34,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":65,"Name":"duration","Update":"192","Value":"192","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":66,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":67,"Name":"internal.metrics.executorDeserializeTime","Update":27,"Value":27,"Internal":true,"Count Failed Values":true},{"ID":68,"Name":"internal.metrics.executorDeserializeCpuTime","Update":16867839,"Value":16867839,"Internal":true,"Count Failed Values":true},{"ID":69,"Name":"internal.metrics.executorRunTime","Update":263,"Value":263,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorCpuTime","Update":149202577,"Value":149202577,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":89,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":27,"Executor Deserialize CPU Time":16867839,"Executor Run Time":263,"Executor CPU Time":149202577,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"DataSourceRDD","Scope":"{\"id\":\"11\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"8\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331867976,"Completion Time":1669331870440,"Accumulables":[{"ID":32,"Name":"duration","Value":"205","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":34,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":65,"Name":"duration","Value":"192","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":66,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":67,"Name":"internal.metrics.executorDeserializeTime","Value":27,"Internal":true,"Count Failed Values":true},{"ID":68,"Name":"internal.metrics.executorDeserializeCpuTime","Value":16867839,"Internal":true,"Count Failed Values":true},{"ID":69,"Name":"internal.metrics.executorRunTime","Value":263,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorCpuTime","Value":149202577,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":89,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1669331870440,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":5,"time":1669331870440}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":2,"time":1669331870441}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:47.725Z","batchId":1,"batchDuration":2748,"durationMs":{"triggerExecution":2748,"queryPlanning":26,"getBatch":0,"latestOffset":1,"addBatch":2647,"walCommit":37},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":1}}","latestOffset":"{\"12003800_test\":{\"0\":1}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":0.363901018922853,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870425,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331870540,"Failed":false,"Killed":false,"Accumulables":[{"ID":92,"Name":"duration","Update":"67","Value":"67","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":93,"Name":"number of output rows","Update":"32","Value":"32","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":96,"Name":"internal.metrics.executorDeserializeTime","Update":26,"Value":26,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10109435,"Value":10109435,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorRunTime","Update":76,"Value":76,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.executorCpuTime","Update":41369728,"Value":41369728,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.recordsRead","Update":32,"Value":32,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":26,"Executor Deserialize CPU Time":10109435,"Executor Run Time":76,"Executor CPU Time":41369728,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":32},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"DataSourceRDD","Scope":"{\"id\":\"24\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331870296,"Completion Time":1669331870541,"Accumulables":[{"ID":92,"Name":"duration","Value":"67","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":93,"Name":"number of output rows","Value":"32","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":96,"Name":"internal.metrics.executorDeserializeTime","Value":26,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10109435,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorRunTime","Value":76,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.executorCpuTime","Value":41369728,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.recordsRead","Value":32,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1669331870542,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":7,"time":1669331870542}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":6,"time":1669331870542}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:50.161Z","batchId":2,"batchDuration":407,"durationMs":{"triggerExecution":407,"queryPlanning":23,"getBatch":0,"latestOffset":1,"addBatch":322,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":1}}","endOffset":"{\"12003800_test\":{\"0\":33}}","latestOffset":"{\"12003800_test\":{\"0\":33}}","numInputRows":32,"inputRowsPerSecond":13.136288998357964,"processedRowsPerSecond":78.62407862407863,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":32},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":8,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:50.484 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:50.484 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":122,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":123,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":124,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":121,"metricType":"timing"}]},"time":1669331870579,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":9,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3ed093bc, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@4d46f8ab\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@117975a, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@1cbad490","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":126,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":127,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":128,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":125,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331870657,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":10,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@62bad66e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@1884103d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@117975a, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@1cbad490","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":126,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":127,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":128,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":125,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331870686,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1669331870702,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"37\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"DataSourceRDD","Scope":"{\"id\":\"40\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[4],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"10","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"37\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"DataSourceRDD","Scope":"{\"id\":\"40\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331870704,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"10","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870717,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":11,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#117, value#118, timestamp#119, current_timestamp#120]\nArguments: [topic#117, value#118, timestamp#119, current_timestamp#120], SQLExecutionRDD[20] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#117, value#118, timestamp#119, current_timestamp#120]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@73a5fc97, org.apache.spark.sql.connector.write.WriteBuilder$1@7e2c6033\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@73a5fc97, org.apache.spark.sql.connector.write.WriteBuilder$1@7e2c6033","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#117,value#118,timestamp#119,current_timestamp#120]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":155,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":154,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331870728,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1669331870734,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"DataSourceRDD","Scope":"{\"id\":\"36\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[5],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"11","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"DataSourceRDD","Scope":"{\"id\":\"36\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331870736,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"11","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870980,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870717,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331870981,"Failed":false,"Killed":false,"Accumulables":[{"ID":125,"Name":"duration","Update":"175","Value":"175","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":129,"Name":"internal.metrics.executorDeserializeTime","Update":61,"Value":61,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorDeserializeCpuTime","Update":12317436,"Value":12317436,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorRunTime","Update":193,"Value":193,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.executorCpuTime","Update":25167422,"Value":25167422,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSize","Update":1801,"Value":1801,"Internal":true,"Count Failed Values":true},{"ID":134,"Name":"internal.metrics.jvmGCTime","Update":141,"Value":141,"Internal":true,"Count Failed Values":true},{"ID":151,"Name":"internal.metrics.input.recordsRead","Update":5,"Value":5,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":61,"Executor Deserialize CPU Time":12317436,"Executor Run Time":193,"Executor CPU Time":25167422,"Peak Execution Memory":0,"Result Size":1801,"JVM GC Time":141,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":5},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"37\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"40\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"DataSourceRDD","Scope":"{\"id\":\"40\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331870704,"Completion Time":1669331870983,"Accumulables":[{"ID":125,"Name":"duration","Value":"175","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":129,"Name":"internal.metrics.executorDeserializeTime","Value":61,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12317436,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorRunTime","Value":193,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.executorCpuTime","Value":25167422,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSize","Value":1801,"Internal":true,"Count Failed Values":true},{"ID":134,"Name":"internal.metrics.jvmGCTime","Value":141,"Internal":true,"Count Failed Values":true},{"ID":151,"Name":"internal.metrics.input.recordsRead","Value":5,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1669331870983,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":10,"time":1669331870983}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":9,"time":1669331870983}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:50.568Z","batchId":3,"batchDuration":446,"durationMs":{"triggerExecution":446,"queryPlanning":31,"getBatch":0,"latestOffset":2,"addBatch":341,"walCommit":40},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":33}}","endOffset":"{\"12003800_test\":{\"0\":38}}","latestOffset":"{\"12003800_test\":{\"0\":38}}","numInputRows":5,"inputRowsPerSecond":12.285012285012286,"processedRowsPerSecond":11.210762331838565,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":5},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":12,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@663e79c0, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@154216f3\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@65c097e5, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@27523c6e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":182,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":183,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":184,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":181,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871084,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":13,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6fef0632, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@6641d0a5\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@65c097e5, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@27523c6e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":182,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":183,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":184,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":181,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871099,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1669331871109,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"DataSourceRDD","Scope":"{\"id\":\"49\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[6],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"13","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"DataSourceRDD","Scope":"{\"id\":\"49\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871112,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"13","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871216,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331870980,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331871217,"Failed":false,"Killed":false,"Accumulables":[{"ID":121,"Name":"duration","Update":"153","Value":"153","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":122,"Name":"number of output rows","Update":"36","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":154,"Name":"duration","Update":"152","Value":"152","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":155,"Name":"number of output rows","Update":"36","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":156,"Name":"internal.metrics.executorDeserializeTime","Update":35,"Value":35,"Internal":true,"Count Failed Values":true},{"ID":157,"Name":"internal.metrics.executorDeserializeCpuTime","Update":11460590,"Value":11460590,"Internal":true,"Count Failed Values":true},{"ID":158,"Name":"internal.metrics.executorRunTime","Update":193,"Value":193,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorCpuTime","Update":63069125,"Value":63069125,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.input.recordsRead","Update":36,"Value":36,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":35,"Executor Deserialize CPU Time":11460590,"Executor Run Time":193,"Executor CPU Time":63069125,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":36},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"DataSourceRDD","Scope":"{\"id\":\"36\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331870736,"Completion Time":1669331871218,"Accumulables":[{"ID":121,"Name":"duration","Value":"153","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":122,"Name":"number of output rows","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":154,"Name":"duration","Value":"152","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":155,"Name":"number of output rows","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":156,"Name":"internal.metrics.executorDeserializeTime","Value":35,"Internal":true,"Count Failed Values":true},{"ID":157,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11460590,"Internal":true,"Count Failed Values":true},{"ID":158,"Name":"internal.metrics.executorRunTime","Value":193,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorCpuTime","Value":63069125,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.input.recordsRead","Value":36,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1669331871218,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":11,"time":1669331871221}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":8,"time":1669331871224}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:50.474Z","batchId":2,"batchDuration":780,"durationMs":{"triggerExecution":780,"queryPlanning":25,"getBatch":0,"latestOffset":10,"addBatch":658,"walCommit":54},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":1}}","endOffset":"{\"12003800_test\":{\"0\":37}}","latestOffset":"{\"12003800_test\":{\"0\":37}}","numInputRows":36,"inputRowsPerSecond":13.095671153146599,"processedRowsPerSecond":46.15384615384615,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":14,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:51.258 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:51.258 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":211,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":212,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":213,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":210,"metricType":"timing"}]},"time":1669331871322,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871216,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331871333,"Failed":false,"Killed":false,"Accumulables":[{"ID":181,"Name":"duration","Update":"85","Value":"85","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":182,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":185,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":186,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8580087,"Value":8580087,"Internal":true,"Count Failed Values":true},{"ID":187,"Name":"internal.metrics.executorRunTime","Update":91,"Value":91,"Internal":true,"Count Failed Values":true},{"ID":188,"Name":"internal.metrics.executorCpuTime","Update":25499224,"Value":25499224,"Internal":true,"Count Failed Values":true},{"ID":189,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":207,"Name":"internal.metrics.input.recordsRead","Update":6,"Value":6,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":8580087,"Executor Run Time":91,"Executor CPU Time":25499224,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":6},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"46\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"DataSourceRDD","Scope":"{\"id\":\"49\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871112,"Completion Time":1669331871334,"Accumulables":[{"ID":181,"Name":"duration","Value":"85","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":182,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":185,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":186,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8580087,"Internal":true,"Count Failed Values":true},{"ID":187,"Name":"internal.metrics.executorRunTime","Value":91,"Internal":true,"Count Failed Values":true},{"ID":188,"Name":"internal.metrics.executorCpuTime","Value":25499224,"Internal":true,"Count Failed Values":true},{"ID":189,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":207,"Name":"internal.metrics.input.recordsRead","Value":6,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1669331871334,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":13,"time":1669331871335}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":12,"time":1669331871335}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:51.014Z","batchId":4,"batchDuration":352,"durationMs":{"triggerExecution":352,"queryPlanning":22,"getBatch":0,"latestOffset":2,"addBatch":267,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":38}}","endOffset":"{\"12003800_test\":{\"0\":44}}","latestOffset":"{\"12003800_test\":{\"0\":44}}","numInputRows":6,"inputRowsPerSecond":13.452914798206278,"processedRowsPerSecond":17.045454545454547,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":6},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":15,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#151, value#152, timestamp#153, current_timestamp#154]\nArguments: [topic#151, value#152, timestamp#153, current_timestamp#154], SQLExecutionRDD[31] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#151, value#152, timestamp#153, current_timestamp#154]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@433edaf0, org.apache.spark.sql.connector.write.WriteBuilder$1@39951622\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@433edaf0, org.apache.spark.sql.connector.write.WriteBuilder$1@39951622","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#151,value#152,timestamp#153,current_timestamp#154]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":215,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":214,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871415,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1669331871421,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"DataSourceRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[7],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"15","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"DataSourceRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871424,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"15","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":16,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2da3fddc, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@45791578\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1d552910, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2b94828b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":242,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":243,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":244,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":241,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871433,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871433,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":17,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@68877b08, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5a9ccca3\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1d552910, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2b94828b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":242,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":243,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":244,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":241,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871441,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1669331871452,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"64\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"67\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"DataSourceRDD","Scope":"{\"id\":\"67\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[8],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"17","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"64\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"67\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"DataSourceRDD","Scope":"{\"id\":\"67\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871474,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"17","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871618,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871433,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331871619,"Failed":false,"Killed":false,"Accumulables":[{"ID":210,"Name":"duration","Update":"101","Value":"101","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":211,"Name":"number of output rows","Update":"11","Value":"11","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":214,"Name":"duration","Update":"101","Value":"101","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":215,"Name":"number of output rows","Update":"11","Value":"11","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":216,"Name":"internal.metrics.executorDeserializeTime","Update":39,"Value":39,"Internal":true,"Count Failed Values":true},{"ID":217,"Name":"internal.metrics.executorDeserializeCpuTime","Update":29462241,"Value":29462241,"Internal":true,"Count Failed Values":true},{"ID":218,"Name":"internal.metrics.executorRunTime","Update":136,"Value":136,"Internal":true,"Count Failed Values":true},{"ID":219,"Name":"internal.metrics.executorCpuTime","Update":47685793,"Value":47685793,"Internal":true,"Count Failed Values":true},{"ID":220,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":238,"Name":"internal.metrics.input.recordsRead","Update":11,"Value":11,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":39,"Executor Deserialize CPU Time":29462241,"Executor Run Time":136,"Executor CPU Time":47685793,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":11},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"DataSourceRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871424,"Completion Time":1669331871620,"Accumulables":[{"ID":210,"Name":"duration","Value":"101","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":211,"Name":"number of output rows","Value":"11","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":214,"Name":"duration","Value":"101","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":215,"Name":"number of output rows","Value":"11","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":216,"Name":"internal.metrics.executorDeserializeTime","Value":39,"Internal":true,"Count Failed Values":true},{"ID":217,"Name":"internal.metrics.executorDeserializeCpuTime","Value":29462241,"Internal":true,"Count Failed Values":true},{"ID":218,"Name":"internal.metrics.executorRunTime","Value":136,"Internal":true,"Count Failed Values":true},{"ID":219,"Name":"internal.metrics.executorCpuTime","Value":47685793,"Internal":true,"Count Failed Values":true},{"ID":220,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":238,"Name":"internal.metrics.input.recordsRead","Value":11,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1669331871620,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":15,"time":1669331871620}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":14,"time":1669331871621}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:51.257Z","batchId":3,"batchDuration":399,"durationMs":{"triggerExecution":399,"queryPlanning":18,"getBatch":0,"latestOffset":1,"addBatch":315,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":37}}","endOffset":"{\"12003800_test\":{\"0\":48}}","latestOffset":"{\"12003800_test\":{\"0\":48}}","numInputRows":11,"inputRowsPerSecond":14.0485312899106,"processedRowsPerSecond":27.56892230576441,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871618,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331871667,"Failed":false,"Killed":false,"Accumulables":[{"ID":241,"Name":"duration","Update":"17","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":242,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":245,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":246,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8260908,"Value":8260908,"Internal":true,"Count Failed Values":true},{"ID":247,"Name":"internal.metrics.executorRunTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":248,"Name":"internal.metrics.executorCpuTime","Update":18956856,"Value":18956856,"Internal":true,"Count Failed Values":true},{"ID":249,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":267,"Name":"internal.metrics.input.recordsRead","Update":5,"Value":5,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":8260908,"Executor Run Time":22,"Executor CPU Time":18956856,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":5},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"64\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"67\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"DataSourceRDD","Scope":"{\"id\":\"67\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871474,"Completion Time":1669331871668,"Accumulables":[{"ID":241,"Name":"duration","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":242,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":245,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":246,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8260908,"Internal":true,"Count Failed Values":true},{"ID":247,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":248,"Name":"internal.metrics.executorCpuTime","Value":18956856,"Internal":true,"Count Failed Values":true},{"ID":249,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":267,"Name":"internal.metrics.input.recordsRead","Value":5,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1669331871668,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":17,"time":1669331871668}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":16,"time":1669331871669}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:51.367Z","batchId":5,"batchDuration":332,"durationMs":{"triggerExecution":332,"queryPlanning":11,"getBatch":0,"latestOffset":1,"addBatch":251,"walCommit":38},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":44}}","endOffset":"{\"12003800_test\":{\"0\":49}}","latestOffset":"{\"12003800_test\":{\"0\":49}}","numInputRows":5,"inputRowsPerSecond":14.164305949008499,"processedRowsPerSecond":15.06024096385542,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":5},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":18,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:51.66 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:51.66 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":271,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":272,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":273,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":270,"metricType":"timing"}]},"time":1669331871726,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":19,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@475507d8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@43ecdf26\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@664a5b3b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@22cb90d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":275,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":276,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":277,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":274,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871748,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":20,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3613ed56, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@3995c895\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@664a5b3b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@22cb90d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":275,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":276,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":277,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":274,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871756,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1669331871803,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[9],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"20","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871811,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"20","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871825,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":21,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#182, value#183, timestamp#184, current_timestamp#185]\nArguments: [topic#182, value#183, timestamp#184, current_timestamp#185], SQLExecutionRDD[39] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#182, value#183, timestamp#184, current_timestamp#185]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@5353825a, org.apache.spark.sql.connector.write.WriteBuilder$1@20f2bf7a\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@5353825a, org.apache.spark.sql.connector.write.WriteBuilder$1@20f2bf7a","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#182,value#183,timestamp#184,current_timestamp#185]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":304,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":303,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331871897,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1669331871903,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"DataSourceRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[10],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"21","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"DataSourceRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871904,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"21","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871939,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871825,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331871939,"Failed":false,"Killed":false,"Accumulables":[{"ID":274,"Name":"duration","Update":"79","Value":"79","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":275,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":278,"Name":"internal.metrics.executorDeserializeTime","Update":23,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8300321,"Value":8300321,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.executorRunTime","Update":83,"Value":83,"Internal":true,"Count Failed Values":true},{"ID":281,"Name":"internal.metrics.executorCpuTime","Update":34740788,"Value":34740788,"Internal":true,"Count Failed Values":true},{"ID":282,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":300,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":23,"Executor Deserialize CPU Time":8300321,"Executor Run Time":83,"Executor CPU Time":34740788,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871811,"Completion Time":1669331871941,"Accumulables":[{"ID":274,"Name":"duration","Value":"79","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":275,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":278,"Name":"internal.metrics.executorDeserializeTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8300321,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.executorRunTime","Value":83,"Internal":true,"Count Failed Values":true},{"ID":281,"Name":"internal.metrics.executorCpuTime","Value":34740788,"Internal":true,"Count Failed Values":true},{"ID":282,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":300,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1669331871942,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":20,"time":1669331871942}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":19,"time":1669331871942}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:51.700Z","batchId":6,"batchDuration":269,"durationMs":{"triggerExecution":269,"queryPlanning":11,"getBatch":0,"latestOffset":1,"addBatch":204,"walCommit":25},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":49}}","endOffset":"{\"12003800_test\":{\"0\":53}}","latestOffset":"{\"12003800_test\":{\"0\":53}}","numInputRows":4,"inputRowsPerSecond":12.012012012012011,"processedRowsPerSecond":14.869888475836431,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":4},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331871939,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331872036,"Failed":false,"Killed":false,"Accumulables":[{"ID":270,"Name":"duration","Update":"43","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":271,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":303,"Name":"duration","Update":"43","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":304,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":305,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":306,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10050525,"Value":10050525,"Internal":true,"Count Failed Values":true},{"ID":307,"Name":"internal.metrics.executorRunTime","Update":68,"Value":68,"Internal":true,"Count Failed Values":true},{"ID":308,"Name":"internal.metrics.executorCpuTime","Update":36547491,"Value":36547491,"Internal":true,"Count Failed Values":true},{"ID":309,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":327,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":10050525,"Executor Run Time":68,"Executor CPU Time":36547491,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"84\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"DataSourceRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331871904,"Completion Time":1669331872037,"Accumulables":[{"ID":270,"Name":"duration","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":271,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":303,"Name":"duration","Value":"43","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":304,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":305,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":306,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10050525,"Internal":true,"Count Failed Values":true},{"ID":307,"Name":"internal.metrics.executorRunTime","Value":68,"Internal":true,"Count Failed Values":true},{"ID":308,"Name":"internal.metrics.executorCpuTime","Value":36547491,"Internal":true,"Count Failed Values":true},{"ID":309,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":327,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1669331872037,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":21,"time":1669331872039}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":18,"time":1669331872040}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":22,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@599e83db, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@3672c74a\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4b7ee117, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@6e1c70d6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":331,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":332,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":333,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":330,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872051,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":23,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1c4f1234, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@34375002\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4b7ee117, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@6e1c70d6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":331,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":332,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":333,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":330,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872078,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:51.657Z","batchId":4,"batchDuration":427,"durationMs":{"triggerExecution":427,"queryPlanning":16,"getBatch":0,"latestOffset":3,"addBatch":328,"walCommit":33},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":48}}","endOffset":"{\"12003800_test\":{\"0\":52}}","latestOffset":"{\"12003800_test\":{\"0\":52}}","numInputRows":4,"inputRowsPerSecond":10.0,"processedRowsPerSecond":9.36768149882904,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1669331872088,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[11],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"23","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872091,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"23","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872097,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872097,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331872143,"Failed":false,"Killed":false,"Accumulables":[{"ID":330,"Name":"duration","Update":"18","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":331,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":334,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":335,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8078535,"Value":8078535,"Internal":true,"Count Failed Values":true},{"ID":336,"Name":"internal.metrics.executorRunTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":337,"Name":"internal.metrics.executorCpuTime","Update":16701806,"Value":16701806,"Internal":true,"Count Failed Values":true},{"ID":338,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":356,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":8078535,"Executor Run Time":22,"Executor CPU Time":16701806,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872091,"Completion Time":1669331872144,"Accumulables":[{"ID":330,"Name":"duration","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":331,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":334,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":335,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8078535,"Internal":true,"Count Failed Values":true},{"ID":336,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":337,"Name":"internal.metrics.executorCpuTime","Value":16701806,"Internal":true,"Count Failed Values":true},{"ID":338,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":356,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1669331872144,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":23,"time":1669331872144}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":22,"time":1669331872144}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":24,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:52.087 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:52.087 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":360,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":361,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":362,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":359,"metricType":"timing"}]},"time":1669331872152,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:51.970Z","batchId":7,"batchDuration":206,"durationMs":{"triggerExecution":206,"queryPlanning":19,"getBatch":0,"latestOffset":1,"addBatch":108,"walCommit":44},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":53}}","endOffset":"{\"12003800_test\":{\"0\":57}}","latestOffset":"{\"12003800_test\":{\"0\":57}}","numInputRows":4,"inputRowsPerSecond":14.814814814814813,"processedRowsPerSecond":19.417475728155342,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":4},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":25,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#212, value#213, timestamp#214, current_timestamp#215]\nArguments: [topic#212, value#213, timestamp#214, current_timestamp#215], SQLExecutionRDD[50] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#212, value#213, timestamp#214, current_timestamp#215]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@5afdab60, org.apache.spark.sql.connector.write.WriteBuilder$1@48d68933\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@5afdab60, org.apache.spark.sql.connector.write.WriteBuilder$1@48d68933","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#212,value#213,timestamp#214,current_timestamp#215]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":364,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":363,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872237,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":26,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6eb979d9, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@23d31477\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@708a63bf, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@362dbae6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":366,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":367,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":368,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":365,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872240,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1669331872244,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"105\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"DataSourceRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[12],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"25","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"105\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"DataSourceRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872245,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"25","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":27,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38e459bc, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@357a1183\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@708a63bf, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@362dbae6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":366,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":367,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":368,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":365,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872274,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872274,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1669331872286,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"107\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"DataSourceRDD","Scope":"{\"id\":\"110\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"110\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[13],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"27","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"107\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"DataSourceRDD","Scope":"{\"id\":\"110\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"110\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872289,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"27","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872507,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872274,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331872508,"Failed":false,"Killed":false,"Accumulables":[{"ID":359,"Name":"duration","Update":"126","Value":"126","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":360,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":363,"Name":"duration","Update":"126","Value":"126","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":364,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":369,"Name":"internal.metrics.executorDeserializeTime","Update":41,"Value":41,"Internal":true,"Count Failed Values":true},{"ID":370,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10116939,"Value":10116939,"Internal":true,"Count Failed Values":true},{"ID":371,"Name":"internal.metrics.executorRunTime","Update":183,"Value":183,"Internal":true,"Count Failed Values":true},{"ID":372,"Name":"internal.metrics.executorCpuTime","Update":47335701,"Value":47335701,"Internal":true,"Count Failed Values":true},{"ID":373,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":391,"Name":"internal.metrics.input.recordsRead","Update":6,"Value":6,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":41,"Executor Deserialize CPU Time":10116939,"Executor Run Time":183,"Executor CPU Time":47335701,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":6},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"105\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"DataSourceRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872245,"Completion Time":1669331872509,"Accumulables":[{"ID":359,"Name":"duration","Value":"126","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":360,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":363,"Name":"duration","Value":"126","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":364,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":369,"Name":"internal.metrics.executorDeserializeTime","Value":41,"Internal":true,"Count Failed Values":true},{"ID":370,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10116939,"Internal":true,"Count Failed Values":true},{"ID":371,"Name":"internal.metrics.executorRunTime","Value":183,"Internal":true,"Count Failed Values":true},{"ID":372,"Name":"internal.metrics.executorCpuTime","Value":47335701,"Internal":true,"Count Failed Values":true},{"ID":373,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":391,"Name":"internal.metrics.input.recordsRead","Value":6,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1669331872510,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":25,"time":1669331872510}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":24,"time":1669331872511}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:52.085Z","batchId":5,"batchDuration":458,"durationMs":{"triggerExecution":458,"queryPlanning":14,"getBatch":0,"latestOffset":2,"addBatch":371,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":52}}","endOffset":"{\"12003800_test\":{\"0\":58}}","latestOffset":"{\"12003800_test\":{\"0\":58}}","numInputRows":6,"inputRowsPerSecond":14.018691588785048,"processedRowsPerSecond":13.100436681222707,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":28,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:52.546 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:52.546 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":420,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":421,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":422,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":419,"metricType":"timing"}]},"time":1669331872602,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872507,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331872619,"Failed":false,"Killed":false,"Accumulables":[{"ID":365,"Name":"duration","Update":"76","Value":"76","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":366,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":394,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":395,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8183393,"Value":8183393,"Internal":true,"Count Failed Values":true},{"ID":396,"Name":"internal.metrics.executorRunTime","Update":82,"Value":82,"Internal":true,"Count Failed Values":true},{"ID":397,"Name":"internal.metrics.executorCpuTime","Update":22107317,"Value":22107317,"Internal":true,"Count Failed Values":true},{"ID":398,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":416,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":8183393,"Executor Run Time":82,"Executor CPU Time":22107317,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"107\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"DataSourceRDD","Scope":"{\"id\":\"110\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"110\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872289,"Completion Time":1669331872620,"Accumulables":[{"ID":365,"Name":"duration","Value":"76","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":366,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":394,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":395,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8183393,"Internal":true,"Count Failed Values":true},{"ID":396,"Name":"internal.metrics.executorRunTime","Value":82,"Internal":true,"Count Failed Values":true},{"ID":397,"Name":"internal.metrics.executorCpuTime","Value":22107317,"Internal":true,"Count Failed Values":true},{"ID":398,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":416,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1669331872621,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":27,"time":1669331872621}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":26,"time":1669331872621}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:52.177Z","batchId":8,"batchDuration":483,"durationMs":{"triggerExecution":483,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":388,"walCommit":44},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":57}}","endOffset":"{\"12003800_test\":{\"0\":60}}","latestOffset":"{\"12003800_test\":{\"0\":60}}","numInputRows":3,"inputRowsPerSecond":14.492753623188406,"processedRowsPerSecond":6.211180124223603,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":29,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#239, value#240, timestamp#241, current_timestamp#242]\nArguments: [topic#239, value#240, timestamp#241, current_timestamp#242], SQLExecutionRDD[58] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#239, value#240, timestamp#241, current_timestamp#242]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@15b5a6df, org.apache.spark.sql.connector.write.WriteBuilder$1@e1132fd\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@15b5a6df, org.apache.spark.sql.connector.write.WriteBuilder$1@e1132fd","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#239,value#240,timestamp#241,current_timestamp#242]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":424,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":423,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872682,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1669331872689,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"123\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":55,"Name":"DataSourceRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[14],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"29","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"123\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":55,"Name":"DataSourceRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872690,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"29","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872695,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":30,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5c275188, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5ef25463\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5877d93, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5c8e1e01","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":451,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":452,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":453,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":450,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872728,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":31,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@43c584b0, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@40b3ace3\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5877d93, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5c8e1e01","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":451,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":452,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":453,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":450,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331872740,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1669331872779,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"125\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"128\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"DataSourceRDD","Scope":"{\"id\":\"128\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[15],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"31","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"125\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"128\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"DataSourceRDD","Scope":"{\"id\":\"128\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872780,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"31","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872873,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872695,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331872874,"Failed":false,"Killed":false,"Accumulables":[{"ID":419,"Name":"duration","Update":"118","Value":"118","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":420,"Name":"number of output rows","Update":"7","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":423,"Name":"duration","Update":"118","Value":"118","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":424,"Name":"number of output rows","Update":"7","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":425,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":426,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8360717,"Value":8360717,"Internal":true,"Count Failed Values":true},{"ID":427,"Name":"internal.metrics.executorRunTime","Update":151,"Value":151,"Internal":true,"Count Failed Values":true},{"ID":428,"Name":"internal.metrics.executorCpuTime","Update":36713898,"Value":36713898,"Internal":true,"Count Failed Values":true},{"ID":429,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":447,"Name":"internal.metrics.input.recordsRead","Update":7,"Value":7,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":8360717,"Executor Run Time":151,"Executor CPU Time":36713898,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":7},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"123\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":55,"Name":"DataSourceRDD","Scope":"{\"id\":\"122\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872690,"Completion Time":1669331872875,"Accumulables":[{"ID":419,"Name":"duration","Value":"118","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":420,"Name":"number of output rows","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":423,"Name":"duration","Value":"118","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":424,"Name":"number of output rows","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":425,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":426,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8360717,"Internal":true,"Count Failed Values":true},{"ID":427,"Name":"internal.metrics.executorRunTime","Value":151,"Internal":true,"Count Failed Values":true},{"ID":428,"Name":"internal.metrics.executorCpuTime","Value":36713898,"Internal":true,"Count Failed Values":true},{"ID":429,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":447,"Name":"internal.metrics.input.recordsRead","Value":7,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1669331872875,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":29,"time":1669331872875}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":28,"time":1669331872876}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:52.545Z","batchId":6,"batchDuration":362,"durationMs":{"triggerExecution":362,"queryPlanning":12,"getBatch":0,"latestOffset":1,"addBatch":285,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":58}}","endOffset":"{\"12003800_test\":{\"0\":65}}","latestOffset":"{\"12003800_test\":{\"0\":65}}","numInputRows":7,"inputRowsPerSecond":15.217391304347826,"processedRowsPerSecond":19.337016574585636,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331872873,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331872951,"Failed":false,"Killed":false,"Accumulables":[{"ID":450,"Name":"duration","Update":"46","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":451,"Name":"number of output rows","Update":"7","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":454,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":455,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9821523,"Value":9821523,"Internal":true,"Count Failed Values":true},{"ID":456,"Name":"internal.metrics.executorRunTime","Update":51,"Value":51,"Internal":true,"Count Failed Values":true},{"ID":457,"Name":"internal.metrics.executorCpuTime","Update":25737478,"Value":25737478,"Internal":true,"Count Failed Values":true},{"ID":458,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":476,"Name":"internal.metrics.input.recordsRead","Update":7,"Value":7,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":9821523,"Executor Run Time":51,"Executor CPU Time":25737478,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":7},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"125\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"128\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"DataSourceRDD","Scope":"{\"id\":\"128\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331872780,"Completion Time":1669331872951,"Accumulables":[{"ID":450,"Name":"duration","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":451,"Name":"number of output rows","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":454,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":455,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9821523,"Internal":true,"Count Failed Values":true},{"ID":456,"Name":"internal.metrics.executorRunTime","Value":51,"Internal":true,"Count Failed Values":true},{"ID":457,"Name":"internal.metrics.executorCpuTime","Value":25737478,"Internal":true,"Count Failed Values":true},{"ID":458,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":476,"Name":"internal.metrics.input.recordsRead","Value":7,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1669331872952,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":31,"time":1669331872953}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":30,"time":1669331872953}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":32,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:52.91 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:52.91 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":480,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":481,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":482,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":479,"metricType":"timing"}]},"time":1669331872977,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:52.661Z","batchId":9,"batchDuration":320,"durationMs":{"triggerExecution":320,"queryPlanning":13,"getBatch":0,"latestOffset":1,"addBatch":239,"walCommit":38},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":60}}","endOffset":"{\"12003800_test\":{\"0\":67}}","latestOffset":"{\"12003800_test\":{\"0\":67}}","numInputRows":7,"inputRowsPerSecond":14.462809917355372,"processedRowsPerSecond":21.875,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":7},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":33,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1781e42b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@37e7ada0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3595eeab, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@46a50d4b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":484,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":485,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":486,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":483,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873033,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":34,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@16a562c3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2b2bc6d4\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3595eeab, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@46a50d4b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":484,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":485,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":486,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":483,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873044,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1669331873058,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[16],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"34","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873059,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"34","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":35,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#266, value#267, timestamp#268, current_timestamp#269]\nArguments: [topic#266, value#267, timestamp#268, current_timestamp#269], SQLExecutionRDD[66] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#266, value#267, timestamp#268, current_timestamp#269]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@210d9d93, org.apache.spark.sql.connector.write.WriteBuilder$1@72fdbd0a\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@210d9d93, org.apache.spark.sql.connector.write.WriteBuilder$1@72fdbd0a","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#266,value#267,timestamp#268,current_timestamp#269]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":513,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":512,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873074,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873077,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1669331873079,"Stage Infos":[{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"137\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":63,"Name":"DataSourceRDD","Scope":"{\"id\":\"140\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"140\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[17],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"35","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"137\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":63,"Name":"DataSourceRDD","Scope":"{\"id\":\"140\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"140\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873081,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"35","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873120,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873077,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873121,"Failed":false,"Killed":false,"Accumulables":[{"ID":483,"Name":"duration","Update":"18","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":484,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":487,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":488,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7583807,"Value":7583807,"Internal":true,"Count Failed Values":true},{"ID":489,"Name":"internal.metrics.executorRunTime","Update":23,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":490,"Name":"internal.metrics.executorCpuTime","Update":17184421,"Value":17184421,"Internal":true,"Count Failed Values":true},{"ID":491,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":509,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":7583807,"Executor Run Time":23,"Executor CPU Time":17184421,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873059,"Completion Time":1669331873123,"Accumulables":[{"ID":483,"Name":"duration","Value":"18","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":484,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":487,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":488,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7583807,"Internal":true,"Count Failed Values":true},{"ID":489,"Name":"internal.metrics.executorRunTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":490,"Name":"internal.metrics.executorCpuTime","Value":17184421,"Internal":true,"Count Failed Values":true},{"ID":491,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":509,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1669331873123,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":34,"time":1669331873125}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":33,"time":1669331873126}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:52.982Z","batchId":10,"batchDuration":169,"durationMs":{"triggerExecution":169,"queryPlanning":12,"getBatch":0,"latestOffset":1,"addBatch":101,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":67}}","endOffset":"{\"12003800_test\":{\"0\":71}}","latestOffset":"{\"12003800_test\":{\"0\":71}}","numInputRows":4,"inputRowsPerSecond":12.461059190031152,"processedRowsPerSecond":23.668639053254438,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":4},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":36,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@77188646, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@73a15214\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1ec2b0a8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@6fc89b56","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":540,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":541,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":542,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":539,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873209,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873120,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873214,"Failed":false,"Killed":false,"Accumulables":[{"ID":479,"Name":"duration","Update":"42","Value":"42","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":480,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":512,"Name":"duration","Update":"42","Value":"42","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":513,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":514,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":515,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8099844,"Value":8099844,"Internal":true,"Count Failed Values":true},{"ID":516,"Name":"internal.metrics.executorRunTime","Update":69,"Value":69,"Internal":true,"Count Failed Values":true},{"ID":517,"Name":"internal.metrics.executorCpuTime","Update":34197050,"Value":34197050,"Internal":true,"Count Failed Values":true},{"ID":518,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":536,"Name":"internal.metrics.input.recordsRead","Update":5,"Value":5,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8099844,"Executor Run Time":69,"Executor CPU Time":34197050,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":5},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"137\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":63,"Name":"DataSourceRDD","Scope":"{\"id\":\"140\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"140\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873081,"Completion Time":1669331873215,"Accumulables":[{"ID":479,"Name":"duration","Value":"42","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":480,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":512,"Name":"duration","Value":"42","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":513,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":514,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":515,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8099844,"Internal":true,"Count Failed Values":true},{"ID":516,"Name":"internal.metrics.executorRunTime","Value":69,"Internal":true,"Count Failed Values":true},{"ID":517,"Name":"internal.metrics.executorCpuTime","Value":34197050,"Internal":true,"Count Failed Values":true},{"ID":518,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":536,"Name":"internal.metrics.input.recordsRead","Value":5,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1669331873215,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":35,"time":1669331873215}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":32,"time":1669331873216}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":37,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@513b3c6f, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@3a586431\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1ec2b0a8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@6fc89b56","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":540,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":541,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":542,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":539,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873219,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1669331873228,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"155\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"158\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"DataSourceRDD","Scope":"{\"id\":\"158\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[18],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"37","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"155\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"158\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"DataSourceRDD","Scope":"{\"id\":\"158\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873229,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"37","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873236,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:52.909Z","batchId":7,"batchDuration":339,"durationMs":{"triggerExecution":339,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":247,"walCommit":49},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":65}}","endOffset":"{\"12003800_test\":{\"0\":70}}","latestOffset":"{\"12003800_test\":{\"0\":70}}","numInputRows":5,"inputRowsPerSecond":13.736263736263737,"processedRowsPerSecond":14.749262536873156,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":38,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:53.256 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:53.256 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":569,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":570,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":571,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":568,"metricType":"timing"}]},"time":1669331873322,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873236,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873363,"Failed":false,"Killed":false,"Accumulables":[{"ID":539,"Name":"duration","Update":"79","Value":"79","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":540,"Name":"number of output rows","Update":"2","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":543,"Name":"internal.metrics.executorDeserializeTime","Update":38,"Value":38,"Internal":true,"Count Failed Values":true},{"ID":544,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7964365,"Value":7964365,"Internal":true,"Count Failed Values":true},{"ID":545,"Name":"internal.metrics.executorRunTime","Update":83,"Value":83,"Internal":true,"Count Failed Values":true},{"ID":546,"Name":"internal.metrics.executorCpuTime","Update":19000966,"Value":19000966,"Internal":true,"Count Failed Values":true},{"ID":547,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":565,"Name":"internal.metrics.input.recordsRead","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":38,"Executor Deserialize CPU Time":7964365,"Executor Run Time":83,"Executor CPU Time":19000966,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":2},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"155\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"158\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[71],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":71,"Name":"DataSourceRDD","Scope":"{\"id\":\"158\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873229,"Completion Time":1669331873365,"Accumulables":[{"ID":539,"Name":"duration","Value":"79","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":540,"Name":"number of output rows","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":543,"Name":"internal.metrics.executorDeserializeTime","Value":38,"Internal":true,"Count Failed Values":true},{"ID":544,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7964365,"Internal":true,"Count Failed Values":true},{"ID":545,"Name":"internal.metrics.executorRunTime","Value":83,"Internal":true,"Count Failed Values":true},{"ID":546,"Name":"internal.metrics.executorCpuTime","Value":19000966,"Internal":true,"Count Failed Values":true},{"ID":547,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":565,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1669331873365,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":37,"time":1669331873365}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":36,"time":1669331873366}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":39,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#300, value#301, timestamp#302, current_timestamp#303]\nArguments: [topic#300, value#301, timestamp#302, current_timestamp#303], SQLExecutionRDD[77] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#300, value#301, timestamp#302, current_timestamp#303]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@21cdd5ac, org.apache.spark.sql.connector.write.WriteBuilder$1@77943a91\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@21cdd5ac, org.apache.spark.sql.connector.write.WriteBuilder$1@77943a91","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#300,value#301,timestamp#302,current_timestamp#303]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":573,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":572,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873388,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1669331873394,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"166\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"DataSourceRDD","Scope":"{\"id\":\"162\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"159\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[19],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"39","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"166\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"DataSourceRDD","Scope":"{\"id\":\"162\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"159\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873395,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"39","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:53.152Z","batchId":11,"batchDuration":252,"durationMs":{"triggerExecution":252,"queryPlanning":11,"getBatch":0,"latestOffset":1,"addBatch":167,"walCommit":33},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":71}}","endOffset":"{\"12003800_test\":{\"0\":73}}","latestOffset":"{\"12003800_test\":{\"0\":73}}","numInputRows":2,"inputRowsPerSecond":11.76470588235294,"processedRowsPerSecond":7.936507936507937,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":2},"observedMetrics":{}}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873405,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":40,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@76ffc99a, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@21350945\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3f79c2ba, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@177281ee","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":600,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":601,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":602,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":599,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873456,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":41,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@328fa0b3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5ffdadf8\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3f79c2ba, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@177281ee","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":600,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":601,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":602,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":599,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873482,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1669331873496,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"168\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"171\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"DataSourceRDD","Scope":"{\"id\":\"171\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[20],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"41","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"168\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"171\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"DataSourceRDD","Scope":"{\"id\":\"171\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873497,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"41","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873527,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873405,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873528,"Failed":false,"Killed":false,"Accumulables":[{"ID":568,"Name":"duration","Update":"76","Value":"76","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":569,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":572,"Name":"duration","Update":"75","Value":"75","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":573,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":574,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":575,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8519584,"Value":8519584,"Internal":true,"Count Failed Values":true},{"ID":576,"Name":"internal.metrics.executorRunTime","Update":100,"Value":100,"Internal":true,"Count Failed Values":true},{"ID":577,"Name":"internal.metrics.executorCpuTime","Update":56281838,"Value":56281838,"Internal":true,"Count Failed Values":true},{"ID":578,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":596,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":8519584,"Executor Run Time":100,"Executor CPU Time":56281838,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"166\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"DataSourceRDD","Scope":"{\"id\":\"162\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"159\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873395,"Completion Time":1669331873528,"Accumulables":[{"ID":568,"Name":"duration","Value":"76","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":569,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":572,"Name":"duration","Value":"75","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":573,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":574,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":575,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8519584,"Internal":true,"Count Failed Values":true},{"ID":576,"Name":"internal.metrics.executorRunTime","Value":100,"Internal":true,"Count Failed Values":true},{"ID":577,"Name":"internal.metrics.executorCpuTime","Value":56281838,"Internal":true,"Count Failed Values":true},{"ID":578,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":596,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1669331873529,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":39,"time":1669331873529}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":38,"time":1669331873530}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:53.249Z","batchId":8,"batchDuration":308,"durationMs":{"triggerExecution":308,"queryPlanning":9,"getBatch":0,"latestOffset":7,"addBatch":218,"walCommit":45},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":70}}","endOffset":"{\"12003800_test\":{\"0\":74}}","latestOffset":"{\"12003800_test\":{\"0\":74}}","numInputRows":4,"inputRowsPerSecond":11.76470588235294,"processedRowsPerSecond":12.987012987012987,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873527,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873568,"Failed":false,"Killed":false,"Accumulables":[{"ID":599,"Name":"duration","Update":"15","Value":"15","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":600,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":603,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":604,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9390697,"Value":9390697,"Internal":true,"Count Failed Values":true},{"ID":605,"Name":"internal.metrics.executorRunTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":606,"Name":"internal.metrics.executorCpuTime","Update":15187579,"Value":15187579,"Internal":true,"Count Failed Values":true},{"ID":607,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":625,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":9390697,"Executor Run Time":18,"Executor CPU Time":15187579,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"168\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"171\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[79],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":79,"Name":"DataSourceRDD","Scope":"{\"id\":\"171\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873497,"Completion Time":1669331873571,"Accumulables":[{"ID":599,"Name":"duration","Value":"15","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":600,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":603,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":604,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9390697,"Internal":true,"Count Failed Values":true},{"ID":605,"Name":"internal.metrics.executorRunTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":606,"Name":"internal.metrics.executorCpuTime","Value":15187579,"Internal":true,"Count Failed Values":true},{"ID":607,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":625,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1669331873571,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":41,"time":1669331873571}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":40,"time":1669331873571}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:53.404Z","batchId":12,"batchDuration":207,"durationMs":{"triggerExecution":207,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":123,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":73}}","endOffset":"{\"12003800_test\":{\"0\":76}}","latestOffset":"{\"12003800_test\":{\"0\":76}}","numInputRows":3,"inputRowsPerSecond":11.904761904761905,"processedRowsPerSecond":14.492753623188406,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":42,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:53.559 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:53.559 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":629,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":630,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":631,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":628,"metricType":"timing"}]},"time":1669331873616,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":43,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@446637c7, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@19fe5cf9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6c836636, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@22971459","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":633,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":634,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":635,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":632,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873680,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":44,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@502702ec, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2e135aa9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6c836636, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@22971459","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":633,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":634,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":635,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":632,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873687,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1669331873696,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"DataSourceRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[21],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"44","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"DataSourceRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873697,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"44","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":45,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#327, value#328, timestamp#329, current_timestamp#330]\nArguments: [topic#327, value#328, timestamp#329, current_timestamp#330], SQLExecutionRDD[85] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#327, value#328, timestamp#329, current_timestamp#330]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@79f8c7c8, org.apache.spark.sql.connector.write.WriteBuilder$1@4c7e30a6\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@79f8c7c8, org.apache.spark.sql.connector.write.WriteBuilder$1@4c7e30a6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#327,value#328,timestamp#329,current_timestamp#330]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":662,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":661,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873698,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873701,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerJobStart","Job ID":22,"Submission Time":1669331873711,"Stage Infos":[{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"DataSourceRDD","Scope":"{\"id\":\"183\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"183\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[22],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"45","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"DataSourceRDD","Scope":"{\"id\":\"183\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"183\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873712,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"45","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":22,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873767,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873701,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873768,"Failed":false,"Killed":false,"Accumulables":[{"ID":632,"Name":"duration","Update":"39","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":633,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":636,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":637,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8260058,"Value":8260058,"Internal":true,"Count Failed Values":true},{"ID":638,"Name":"internal.metrics.executorRunTime","Update":44,"Value":44,"Internal":true,"Count Failed Values":true},{"ID":639,"Name":"internal.metrics.executorCpuTime","Update":17793928,"Value":17793928,"Internal":true,"Count Failed Values":true},{"ID":640,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":658,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":8260058,"Executor Run Time":44,"Executor CPU Time":17793928,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"184\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"DataSourceRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873697,"Completion Time":1669331873769,"Accumulables":[{"ID":632,"Name":"duration","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":633,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":636,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":637,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8260058,"Internal":true,"Count Failed Values":true},{"ID":638,"Name":"internal.metrics.executorRunTime","Value":44,"Internal":true,"Count Failed Values":true},{"ID":639,"Name":"internal.metrics.executorCpuTime","Value":17793928,"Internal":true,"Count Failed Values":true},{"ID":640,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":658,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1669331873769,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":44,"time":1669331873769}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":43,"time":1669331873769}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:53.612Z","batchId":13,"batchDuration":188,"durationMs":{"triggerExecution":188,"queryPlanning":12,"getBatch":1,"latestOffset":1,"addBatch":101,"walCommit":42},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":76}}","endOffset":"{\"12003800_test\":{\"0\":79}}","latestOffset":"{\"12003800_test\":{\"0\":79}}","numInputRows":3,"inputRowsPerSecond":14.423076923076923,"processedRowsPerSecond":15.957446808510639,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":46,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@207be143, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2352123\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3a4070fd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@32acca5b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":689,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":690,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":691,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":688,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873842,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":47,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@54b91e25, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@1800e9b0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3a4070fd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@32acca5b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":689,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":690,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":691,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":688,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331873849,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskEnd","Stage ID":22,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873767,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873856,"Failed":false,"Killed":false,"Accumulables":[{"ID":628,"Name":"duration","Update":"39","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":629,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":661,"Name":"duration","Update":"39","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":662,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":663,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":664,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7588989,"Value":7588989,"Internal":true,"Count Failed Values":true},{"ID":665,"Name":"internal.metrics.executorRunTime","Update":63,"Value":63,"Internal":true,"Count Failed Values":true},{"ID":666,"Name":"internal.metrics.executorCpuTime","Update":28102684,"Value":28102684,"Internal":true,"Count Failed Values":true},{"ID":667,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":685,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":7588989,"Executor Run Time":63,"Executor CPU Time":28102684,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"DataSourceRDD","Scope":"{\"id\":\"183\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"183\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873712,"Completion Time":1669331873857,"Accumulables":[{"ID":628,"Name":"duration","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":629,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":661,"Name":"duration","Value":"39","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":662,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":663,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":664,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7588989,"Internal":true,"Count Failed Values":true},{"ID":665,"Name":"internal.metrics.executorRunTime","Value":63,"Internal":true,"Count Failed Values":true},{"ID":666,"Name":"internal.metrics.executorCpuTime","Value":28102684,"Internal":true,"Count Failed Values":true},{"ID":667,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":685,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":22,"Completion Time":1669331873857,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":45,"time":1669331873857}
{"Event":"SparkListenerJobStart","Job ID":23,"Submission Time":1669331873857,"Stage Infos":[{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":92,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"193\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"DataSourceRDD","Scope":"{\"id\":\"196\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"196\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[23],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"47","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":42,"time":1669331873858}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":92,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"193\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"DataSourceRDD","Scope":"{\"id\":\"196\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"196\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873858,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"47","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":23,"Stage Attempt ID":0,"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873876,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:53.558Z","batchId":9,"batchDuration":346,"durationMs":{"triggerExecution":346,"queryPlanning":16,"getBatch":0,"latestOffset":1,"addBatch":251,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":74}}","endOffset":"{\"12003800_test\":{\"0\":78}}","latestOffset":"{\"12003800_test\":{\"0\":78}}","numInputRows":4,"inputRowsPerSecond":12.944983818770227,"processedRowsPerSecond":11.560693641618498,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":23,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331873876,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331873924,"Failed":false,"Killed":false,"Accumulables":[{"ID":688,"Name":"duration","Update":"16","Value":"16","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":689,"Name":"number of output rows","Update":"2","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":692,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":693,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7109158,"Value":7109158,"Internal":true,"Count Failed Values":true},{"ID":694,"Name":"internal.metrics.executorRunTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":695,"Name":"internal.metrics.executorCpuTime","Update":15374851,"Value":15374851,"Internal":true,"Count Failed Values":true},{"ID":696,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":714,"Name":"internal.metrics.input.recordsRead","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7109158,"Executor Run Time":20,"Executor CPU Time":15374851,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":2},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":92,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"193\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"DataSourceRDD","Scope":"{\"id\":\"196\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"196\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331873858,"Completion Time":1669331873926,"Accumulables":[{"ID":688,"Name":"duration","Value":"16","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":689,"Name":"number of output rows","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":692,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":693,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7109158,"Internal":true,"Count Failed Values":true},{"ID":694,"Name":"internal.metrics.executorRunTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":695,"Name":"internal.metrics.executorCpuTime","Value":15374851,"Internal":true,"Count Failed Values":true},{"ID":696,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":714,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":23,"Completion Time":1669331873927,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":47,"time":1669331873928}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":46,"time":1669331873928}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":48,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:53.906 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:53.906 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":718,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":719,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":720,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":717,"metricType":"timing"}]},"time":1669331873959,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:53.801Z","batchId":14,"batchDuration":179,"durationMs":{"triggerExecution":179,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":91,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":79}}","endOffset":"{\"12003800_test\":{\"0\":81}}","latestOffset":"{\"12003800_test\":{\"0\":81}}","numInputRows":2,"inputRowsPerSecond":10.582010582010582,"processedRowsPerSecond":11.1731843575419,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":2},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":49,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#361, value#362, timestamp#363, current_timestamp#364]\nArguments: [topic#361, value#362, timestamp#363, current_timestamp#364], SQLExecutionRDD[96] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#361, value#362, timestamp#363, current_timestamp#364]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@3370b60a, org.apache.spark.sql.connector.write.WriteBuilder$1@6dfffe20\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@3370b60a, org.apache.spark.sql.connector.write.WriteBuilder$1@6dfffe20","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#361,value#362,timestamp#363,current_timestamp#364]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":722,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":721,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874027,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":50,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 15","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@65bfd4ab, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@ce8a6d6\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6c8d7a82, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@7a7e980c","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":724,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":725,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":726,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":723,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874032,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":24,"Submission Time":1669331874032,"Stage Infos":[{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"209\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"208\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[94],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"DataSourceRDD","Scope":"{\"id\":\"208\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[95],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[24],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"49","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"209\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"208\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[94],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"DataSourceRDD","Scope":"{\"id\":\"208\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[95],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874033,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"49","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":24,"Stage Attempt ID":0,"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874038,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":51,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 15","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38ebf119, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5641bf92\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6c8d7a82, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@7a7e980c","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":724,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":725,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":726,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":723,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874040,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":25,"Submission Time":1669331874080,"Stage Infos":[{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":100,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"DataSourceRDD","Scope":"{\"id\":\"214\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"214\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[25],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 15","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"15","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"51","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":100,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"DataSourceRDD","Scope":"{\"id\":\"214\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"214\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874082,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 15","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"15","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"51","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":25,"Stage Attempt ID":0,"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874194,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":24,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874038,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331874195,"Failed":false,"Killed":false,"Accumulables":[{"ID":717,"Name":"duration","Update":"55","Value":"55","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":718,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":721,"Name":"duration","Update":"55","Value":"55","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":722,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":727,"Name":"internal.metrics.executorDeserializeTime","Update":48,"Value":48,"Internal":true,"Count Failed Values":true},{"ID":728,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8977833,"Value":8977833,"Internal":true,"Count Failed Values":true},{"ID":729,"Name":"internal.metrics.executorRunTime","Update":100,"Value":100,"Internal":true,"Count Failed Values":true},{"ID":730,"Name":"internal.metrics.executorCpuTime","Update":31918435,"Value":31918435,"Internal":true,"Count Failed Values":true},{"ID":731,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":749,"Name":"internal.metrics.input.recordsRead","Update":5,"Value":5,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":48,"Executor Deserialize CPU Time":8977833,"Executor Run Time":100,"Executor CPU Time":31918435,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":5},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"209\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"208\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[94],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"DataSourceRDD","Scope":"{\"id\":\"208\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[95],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874033,"Completion Time":1669331874196,"Accumulables":[{"ID":717,"Name":"duration","Value":"55","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":718,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":721,"Name":"duration","Value":"55","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":722,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":727,"Name":"internal.metrics.executorDeserializeTime","Value":48,"Internal":true,"Count Failed Values":true},{"ID":728,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8977833,"Internal":true,"Count Failed Values":true},{"ID":729,"Name":"internal.metrics.executorRunTime","Value":100,"Internal":true,"Count Failed Values":true},{"ID":730,"Name":"internal.metrics.executorCpuTime","Value":31918435,"Internal":true,"Count Failed Values":true},{"ID":731,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":749,"Name":"internal.metrics.input.recordsRead","Value":5,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":24,"Completion Time":1669331874196,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":49,"time":1669331874197}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":48,"time":1669331874197}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:53.905Z","batchId":10,"batchDuration":326,"durationMs":{"triggerExecution":326,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":247,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":78}}","endOffset":"{\"12003800_test\":{\"0\":83}}","latestOffset":"{\"12003800_test\":{\"0\":83}}","numInputRows":5,"inputRowsPerSecond":14.409221902017292,"processedRowsPerSecond":15.337423312883436,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":25,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874194,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331874273,"Failed":false,"Killed":false,"Accumulables":[{"ID":723,"Name":"duration","Update":"52","Value":"52","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":724,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":752,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":753,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7430592,"Value":7430592,"Internal":true,"Count Failed Values":true},{"ID":754,"Name":"internal.metrics.executorRunTime","Update":58,"Value":58,"Internal":true,"Count Failed Values":true},{"ID":755,"Name":"internal.metrics.executorCpuTime","Update":17922257,"Value":17922257,"Internal":true,"Count Failed Values":true},{"ID":756,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":774,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7430592,"Executor Run Time":58,"Executor CPU Time":17922257,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":100,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"211\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"DataSourceRDD","Scope":"{\"id\":\"214\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"214\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874082,"Completion Time":1669331874273,"Accumulables":[{"ID":723,"Name":"duration","Value":"52","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":724,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":752,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":753,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7430592,"Internal":true,"Count Failed Values":true},{"ID":754,"Name":"internal.metrics.executorRunTime","Value":58,"Internal":true,"Count Failed Values":true},{"ID":755,"Name":"internal.metrics.executorCpuTime","Value":17922257,"Internal":true,"Count Failed Values":true},{"ID":756,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":774,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":25,"Completion Time":1669331874274,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":51,"time":1669331874274}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":50,"time":1669331874274}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":52,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:54.232 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:54.232 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":778,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":779,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":780,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":777,"metricType":"timing"}]},"time":1669331874275,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:53.981Z","batchId":15,"batchDuration":315,"durationMs":{"triggerExecution":315,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":249,"walCommit":33},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":81}}","endOffset":"{\"12003800_test\":{\"0\":84}}","latestOffset":"{\"12003800_test\":{\"0\":84}}","numInputRows":3,"inputRowsPerSecond":16.666666666666668,"processedRowsPerSecond":9.523809523809524,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":53,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#388, value#389, timestamp#390, current_timestamp#391]\nArguments: [topic#388, value#389, timestamp#390, current_timestamp#391], SQLExecutionRDD[104] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#388, value#389, timestamp#390, current_timestamp#391]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@126f4bc5, org.apache.spark.sql.connector.write.WriteBuilder$1@3eedfea4\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@126f4bc5, org.apache.spark.sql.connector.write.WriteBuilder$1@3eedfea4","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#388,value#389,timestamp#390,current_timestamp#391]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":782,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":781,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874341,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":26,"Submission Time":1669331874346,"Stage Infos":[{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":105,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"227\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[104],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":104,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[103],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"226\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"DataSourceRDD","Scope":"{\"id\":\"226\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"223\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[102],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[26],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"53","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":105,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"227\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[104],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":104,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[103],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"226\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"DataSourceRDD","Scope":"{\"id\":\"226\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"223\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[102],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874346,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"53","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":54,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 16","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4a9b1a03, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@f51fac4\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@14ce3034, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@9c694b6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":809,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":810,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":811,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":808,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874349,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":26,"Stage Attempt ID":0,"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874351,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":55,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 16","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@26725137, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@7922c889\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@14ce3034, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@9c694b6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":809,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":810,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":811,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":808,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874356,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":27,"Submission Time":1669331874367,"Stage Infos":[{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"229\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"232\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"DataSourceRDD","Scope":"{\"id\":\"232\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[27],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 16","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"16","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"55","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"229\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"232\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"DataSourceRDD","Scope":"{\"id\":\"232\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874370,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 16","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"16","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"55","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":27,"Stage Attempt ID":0,"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874427,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":26,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874351,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331874428,"Failed":false,"Killed":false,"Accumulables":[{"ID":777,"Name":"duration","Update":"24","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":778,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":781,"Name":"duration","Update":"24","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":782,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":783,"Name":"internal.metrics.executorDeserializeTime","Update":21,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":784,"Name":"internal.metrics.executorDeserializeCpuTime","Update":14571371,"Value":14571371,"Internal":true,"Count Failed Values":true},{"ID":785,"Name":"internal.metrics.executorRunTime","Update":48,"Value":48,"Internal":true,"Count Failed Values":true},{"ID":786,"Name":"internal.metrics.executorCpuTime","Update":25148697,"Value":25148697,"Internal":true,"Count Failed Values":true},{"ID":787,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":805,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":21,"Executor Deserialize CPU Time":14571371,"Executor Run Time":48,"Executor CPU Time":25148697,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":105,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"227\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[104],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":104,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[103],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"226\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"DataSourceRDD","Scope":"{\"id\":\"226\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"223\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[102],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874346,"Completion Time":1669331874429,"Accumulables":[{"ID":777,"Name":"duration","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":778,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":781,"Name":"duration","Value":"24","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":782,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":783,"Name":"internal.metrics.executorDeserializeTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":784,"Name":"internal.metrics.executorDeserializeCpuTime","Value":14571371,"Internal":true,"Count Failed Values":true},{"ID":785,"Name":"internal.metrics.executorRunTime","Value":48,"Internal":true,"Count Failed Values":true},{"ID":786,"Name":"internal.metrics.executorCpuTime","Value":25148697,"Internal":true,"Count Failed Values":true},{"ID":787,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":805,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":26,"Completion Time":1669331874429,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":53,"time":1669331874429}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":52,"time":1669331874430}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:54.231Z","batchId":11,"batchDuration":228,"durationMs":{"triggerExecution":228,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":163,"walCommit":22},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":83}}","endOffset":"{\"12003800_test\":{\"0\":86}}","latestOffset":"{\"12003800_test\":{\"0\":86}}","numInputRows":3,"inputRowsPerSecond":9.202453987730062,"processedRowsPerSecond":13.157894736842104,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":27,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874427,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331874464,"Failed":false,"Killed":false,"Accumulables":[{"ID":808,"Name":"duration","Update":"13","Value":"13","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":809,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":812,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":813,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7139523,"Value":7139523,"Internal":true,"Count Failed Values":true},{"ID":814,"Name":"internal.metrics.executorRunTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":815,"Name":"internal.metrics.executorCpuTime","Update":11412940,"Value":11412940,"Internal":true,"Count Failed Values":true},{"ID":816,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":834,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7139523,"Executor Run Time":16,"Executor CPU Time":11412940,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"229\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"232\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"DataSourceRDD","Scope":"{\"id\":\"232\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874370,"Completion Time":1669331874465,"Accumulables":[{"ID":808,"Name":"duration","Value":"13","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":809,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":812,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":813,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7139523,"Internal":true,"Count Failed Values":true},{"ID":814,"Name":"internal.metrics.executorRunTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":815,"Name":"internal.metrics.executorCpuTime","Value":11412940,"Internal":true,"Count Failed Values":true},{"ID":816,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":834,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":27,"Completion Time":1669331874465,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":55,"time":1669331874465}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":54,"time":1669331874466}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:54.297Z","batchId":16,"batchDuration":202,"durationMs":{"triggerExecution":202,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":125,"walCommit":34},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":84}}","endOffset":"{\"12003800_test\":{\"0\":87}}","latestOffset":"{\"12003800_test\":{\"0\":87}}","numInputRows":3,"inputRowsPerSecond":9.493670886075948,"processedRowsPerSecond":14.85148514851485,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":56,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:54.461 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:54.461 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":838,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":839,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":840,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":837,"metricType":"timing"}]},"time":1669331874514,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":57,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 17","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@66c019fc, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@3555ea49\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2ff0f776, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5fa2ae84","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":842,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":843,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":844,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":841,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874539,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":58,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 17","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@221a133b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@36d50596\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2ff0f776, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@5fa2ae84","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":842,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":843,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":844,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":841,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874560,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":28,"Submission Time":1669331874592,"Stage Infos":[{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":115,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"245\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":113,"Name":"DataSourceRDD","Scope":"{\"id\":\"248\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"248\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[113],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[28],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 17","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"17","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"58","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":115,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"245\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":113,"Name":"DataSourceRDD","Scope":"{\"id\":\"248\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"248\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[113],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874593,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 17","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"17","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"58","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":28,"Stage Attempt ID":0,"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874600,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":59,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#417, value#418, timestamp#419, current_timestamp#420]\nArguments: [topic#417, value#418, timestamp#419, current_timestamp#420], SQLExecutionRDD[112] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#417, value#418, timestamp#419, current_timestamp#420]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@665b3f6f, org.apache.spark.sql.connector.write.WriteBuilder$1@24a9a68f\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@665b3f6f, org.apache.spark.sql.connector.write.WriteBuilder$1@24a9a68f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#417,value#418,timestamp#419,current_timestamp#420]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":871,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":870,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874607,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":29,"Submission Time":1669331874617,"Stage Infos":[{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":116,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"249\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":109,"Name":"DataSourceRDD","Scope":"{\"id\":\"244\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"244\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[109],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[111],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[29],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"59","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":116,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"249\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":109,"Name":"DataSourceRDD","Scope":"{\"id\":\"244\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"244\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[109],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[111],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874618,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"59","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":29,"Stage Attempt ID":0,"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874726,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":28,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874600,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331874726,"Failed":false,"Killed":false,"Accumulables":[{"ID":841,"Name":"duration","Update":"93","Value":"93","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":842,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":845,"Name":"internal.metrics.executorDeserializeTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":846,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6578104,"Value":6578104,"Internal":true,"Count Failed Values":true},{"ID":847,"Name":"internal.metrics.executorRunTime","Update":98,"Value":98,"Internal":true,"Count Failed Values":true},{"ID":848,"Name":"internal.metrics.executorCpuTime","Update":17097458,"Value":17097458,"Internal":true,"Count Failed Values":true},{"ID":849,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":867,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":18,"Executor Deserialize CPU Time":6578104,"Executor Run Time":98,"Executor CPU Time":17097458,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":115,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"245\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":113,"Name":"DataSourceRDD","Scope":"{\"id\":\"248\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"248\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[113],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874593,"Completion Time":1669331874727,"Accumulables":[{"ID":841,"Name":"duration","Value":"93","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":842,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":845,"Name":"internal.metrics.executorDeserializeTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":846,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6578104,"Internal":true,"Count Failed Values":true},{"ID":847,"Name":"internal.metrics.executorRunTime","Value":98,"Internal":true,"Count Failed Values":true},{"ID":848,"Name":"internal.metrics.executorCpuTime","Value":17097458,"Internal":true,"Count Failed Values":true},{"ID":849,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":867,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":28,"Completion Time":1669331874727,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":58,"time":1669331874727}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":57,"time":1669331874727}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:54.500Z","batchId":17,"batchDuration":253,"durationMs":{"triggerExecution":253,"queryPlanning":7,"getBatch":1,"latestOffset":1,"addBatch":196,"walCommit":22},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":87}}","endOffset":"{\"12003800_test\":{\"0\":90}}","latestOffset":"{\"12003800_test\":{\"0\":90}}","numInputRows":3,"inputRowsPerSecond":14.778325123152708,"processedRowsPerSecond":11.857707509881422,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":60,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 18","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@675faa71, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@4a182777\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7355555e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@7e812b39","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":898,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":899,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":900,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":897,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874809,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":61,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 18","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1da8c093, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@f5300dc\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7355555e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@7e812b39","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":898,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":899,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":900,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":897,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874815,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":30,"Submission Time":1669331874822,"Stage Infos":[{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":119,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"254\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[118],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"257\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"DataSourceRDD","Scope":"{\"id\":\"257\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[30],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 18","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"18","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"61","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":119,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"254\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[118],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"257\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"DataSourceRDD","Scope":"{\"id\":\"257\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874823,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 18","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"18","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"61","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":30,"Stage Attempt ID":0,"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874847,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":29,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874726,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331874847,"Failed":false,"Killed":false,"Accumulables":[{"ID":837,"Name":"duration","Update":"78","Value":"78","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":838,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":870,"Name":"duration","Update":"78","Value":"78","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":871,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":872,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":873,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7330294,"Value":7330294,"Internal":true,"Count Failed Values":true},{"ID":874,"Name":"internal.metrics.executorRunTime","Update":102,"Value":102,"Internal":true,"Count Failed Values":true},{"ID":875,"Name":"internal.metrics.executorCpuTime","Update":35447507,"Value":35447507,"Internal":true,"Count Failed Values":true},{"ID":876,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":894,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7330294,"Executor Run Time":102,"Executor CPU Time":35447507,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":116,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"249\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":109,"Name":"DataSourceRDD","Scope":"{\"id\":\"244\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"244\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[109],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[111],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874618,"Completion Time":1669331874848,"Accumulables":[{"ID":837,"Name":"duration","Value":"78","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":838,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":870,"Name":"duration","Value":"78","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":871,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":872,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":873,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7330294,"Internal":true,"Count Failed Values":true},{"ID":874,"Name":"internal.metrics.executorRunTime","Value":102,"Internal":true,"Count Failed Values":true},{"ID":875,"Name":"internal.metrics.executorCpuTime","Value":35447507,"Internal":true,"Count Failed Values":true},{"ID":876,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":894,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":29,"Completion Time":1669331874848,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":59,"time":1669331874849}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":56,"time":1669331874850}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:54.460Z","batchId":12,"batchDuration":419,"durationMs":{"triggerExecution":419,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":344,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":86}}","endOffset":"{\"12003800_test\":{\"0\":89}}","latestOffset":"{\"12003800_test\":{\"0\":89}}","numInputRows":3,"inputRowsPerSecond":13.100436681222707,"processedRowsPerSecond":7.159904534606206,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":30,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874847,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331874881,"Failed":false,"Killed":false,"Accumulables":[{"ID":897,"Name":"duration","Update":"13","Value":"13","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":898,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":901,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":902,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6005730,"Value":6005730,"Internal":true,"Count Failed Values":true},{"ID":903,"Name":"internal.metrics.executorRunTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":904,"Name":"internal.metrics.executorCpuTime","Update":12241383,"Value":12241383,"Internal":true,"Count Failed Values":true},{"ID":905,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":923,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":6005730,"Executor Run Time":16,"Executor CPU Time":12241383,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":119,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"254\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[118],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"257\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"DataSourceRDD","Scope":"{\"id\":\"257\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874823,"Completion Time":1669331874883,"Accumulables":[{"ID":897,"Name":"duration","Value":"13","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":898,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":901,"Name":"internal.metrics.executorDeserializeTime","Value":12,"Internal":true,"Count Failed Values":true},{"ID":902,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6005730,"Internal":true,"Count Failed Values":true},{"ID":903,"Name":"internal.metrics.executorRunTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":904,"Name":"internal.metrics.executorCpuTime","Value":12241383,"Internal":true,"Count Failed Values":true},{"ID":905,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":923,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":30,"Completion Time":1669331874883,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":61,"time":1669331874884}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":60,"time":1669331874884}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:54.756Z","batchId":18,"batchDuration":155,"durationMs":{"triggerExecution":155,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":81,"walCommit":37},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":90}}","endOffset":"{\"12003800_test\":{\"0\":93}}","latestOffset":"{\"12003800_test\":{\"0\":93}}","numInputRows":3,"inputRowsPerSecond":11.71875,"processedRowsPerSecond":19.35483870967742,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":62,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:54.881 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:54.881 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":927,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":928,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":929,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":926,"metricType":"timing"}]},"time":1669331874929,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":63,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 19","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@524bbfc7, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@301d8fd\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@33ecef08, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@3c7045d2","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":931,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":932,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":933,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":930,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874956,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":64,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 19","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@340b7a88, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@6bd2861\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@33ecef08, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@3c7045d2","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":931,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":932,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":933,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":930,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874964,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":31,"Submission Time":1669331874972,"Stage Infos":[{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"DataSourceRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[31],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 19","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"19","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"64","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"DataSourceRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874973,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 19","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"19","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"64","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":31,"Stage Attempt ID":0,"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874979,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":65,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#451, value#452, timestamp#453, current_timestamp#454]\nArguments: [topic#451, value#452, timestamp#453, current_timestamp#454], SQLExecutionRDD[123] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#451, value#452, timestamp#453, current_timestamp#454]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@71ba443f, org.apache.spark.sql.connector.write.WriteBuilder$1@34645bae\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@71ba443f, org.apache.spark.sql.connector.write.WriteBuilder$1@34645bae","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#451,value#452,timestamp#453,current_timestamp#454]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":960,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":959,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331874995,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":32,"Submission Time":1669331875000,"Stage Infos":[{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[122],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"266\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"DataSourceRDD","Scope":"{\"id\":\"269\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"269\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[32],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"65","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[122],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"266\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"DataSourceRDD","Scope":"{\"id\":\"269\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"269\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875001,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"65","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":32,"Stage Attempt ID":0,"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331875106,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":31,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331874979,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331875107,"Failed":false,"Killed":false,"Accumulables":[{"ID":930,"Name":"duration","Update":"94","Value":"94","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":931,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":934,"Name":"internal.metrics.executorDeserializeTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":935,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6883277,"Value":6883277,"Internal":true,"Count Failed Values":true},{"ID":936,"Name":"internal.metrics.executorRunTime","Update":98,"Value":98,"Internal":true,"Count Failed Values":true},{"ID":937,"Name":"internal.metrics.executorCpuTime","Update":17468253,"Value":17468253,"Internal":true,"Count Failed Values":true},{"ID":938,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":956,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":20,"Executor Deserialize CPU Time":6883277,"Executor Run Time":98,"Executor CPU Time":17468253,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"DataSourceRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331874973,"Completion Time":1669331875108,"Accumulables":[{"ID":930,"Name":"duration","Value":"94","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":931,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":934,"Name":"internal.metrics.executorDeserializeTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":935,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6883277,"Internal":true,"Count Failed Values":true},{"ID":936,"Name":"internal.metrics.executorRunTime","Value":98,"Internal":true,"Count Failed Values":true},{"ID":937,"Name":"internal.metrics.executorCpuTime","Value":17468253,"Internal":true,"Count Failed Values":true},{"ID":938,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":956,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":31,"Completion Time":1669331875109,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":64,"time":1669331875109}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":63,"time":1669331875110}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:54.911Z","batchId":19,"batchDuration":222,"durationMs":{"triggerExecution":222,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":161,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":93}}","endOffset":"{\"12003800_test\":{\"0\":96}}","latestOffset":"{\"12003800_test\":{\"0\":96}}","numInputRows":3,"inputRowsPerSecond":19.35483870967742,"processedRowsPerSecond":13.513513513513514,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":32,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331875106,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331875177,"Failed":false,"Killed":false,"Accumulables":[{"ID":926,"Name":"duration","Update":"28","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":927,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":959,"Name":"duration","Update":"27","Value":"27","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":960,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":961,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":962,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7313564,"Value":7313564,"Internal":true,"Count Failed Values":true},{"ID":963,"Name":"internal.metrics.executorRunTime","Update":50,"Value":50,"Internal":true,"Count Failed Values":true},{"ID":964,"Name":"internal.metrics.executorCpuTime","Update":27954619,"Value":27954619,"Internal":true,"Count Failed Values":true},{"ID":965,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":983,"Name":"internal.metrics.input.recordsRead","Update":6,"Value":6,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":7313564,"Executor Run Time":50,"Executor CPU Time":27954619,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":6},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[122],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"266\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"DataSourceRDD","Scope":"{\"id\":\"269\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"269\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875001,"Completion Time":1669331875178,"Accumulables":[{"ID":926,"Name":"duration","Value":"28","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":927,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":959,"Name":"duration","Value":"27","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":960,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":961,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":962,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7313564,"Internal":true,"Count Failed Values":true},{"ID":963,"Name":"internal.metrics.executorRunTime","Value":50,"Internal":true,"Count Failed Values":true},{"ID":964,"Name":"internal.metrics.executorCpuTime","Value":27954619,"Internal":true,"Count Failed Values":true},{"ID":965,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":983,"Name":"internal.metrics.input.recordsRead","Value":6,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":32,"Completion Time":1669331875178,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":65,"time":1669331875180}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":62,"time":1669331875180}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:54.880Z","batchId":13,"batchDuration":329,"durationMs":{"triggerExecution":329,"queryPlanning":9,"getBatch":1,"latestOffset":1,"addBatch":260,"walCommit":28},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":89}}","endOffset":"{\"12003800_test\":{\"0\":95}}","latestOffset":"{\"12003800_test\":{\"0\":95}}","numInputRows":6,"inputRowsPerSecond":14.285714285714286,"processedRowsPerSecond":18.2370820668693,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":66,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 20","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1eb916ea, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@6a63bf50\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1e16e498, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2c2bb0f3","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":987,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":988,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":989,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":986,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331875213,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":67,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 20","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@30a3f9e3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@57fec900\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1e16e498, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2c2bb0f3","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":987,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":988,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":989,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":986,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331875221,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":33,"Submission Time":1669331875236,"Stage Infos":[{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"284\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"287\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"DataSourceRDD","Scope":"{\"id\":\"287\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[33],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 20","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"20","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"67","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"284\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"287\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"DataSourceRDD","Scope":"{\"id\":\"287\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875236,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 20","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"20","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"67","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":33,"Stage Attempt ID":0,"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331875242,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":68,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:55.211 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 00:17:55.211 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1016,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1017,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1018,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1015,"metricType":"timing"}]},"time":1669331875266,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskEnd","Stage ID":33,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331875242,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331875288,"Failed":false,"Killed":false,"Accumulables":[{"ID":986,"Name":"duration","Update":"17","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":987,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":990,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":991,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6617327,"Value":6617327,"Internal":true,"Count Failed Values":true},{"ID":992,"Name":"internal.metrics.executorRunTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":993,"Name":"internal.metrics.executorCpuTime","Update":11481669,"Value":11481669,"Internal":true,"Count Failed Values":true},{"ID":994,"Name":"internal.metrics.resultSize","Update":1801,"Value":1801,"Internal":true,"Count Failed Values":true},{"ID":996,"Name":"internal.metrics.resultSerializationTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":1012,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":6617327,"Executor Run Time":22,"Executor CPU Time":11481669,"Peak Execution Memory":0,"Result Size":1801,"JVM GC Time":0,"Result Serialization Time":3,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"284\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"287\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"DataSourceRDD","Scope":"{\"id\":\"287\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875236,"Completion Time":1669331875289,"Accumulables":[{"ID":986,"Name":"duration","Value":"17","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":987,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":990,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":991,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6617327,"Internal":true,"Count Failed Values":true},{"ID":992,"Name":"internal.metrics.executorRunTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":993,"Name":"internal.metrics.executorCpuTime","Value":11481669,"Internal":true,"Count Failed Values":true},{"ID":994,"Name":"internal.metrics.resultSize","Value":1801,"Internal":true,"Count Failed Values":true},{"ID":996,"Name":"internal.metrics.resultSerializationTime","Value":3,"Internal":true,"Count Failed Values":true},{"ID":1012,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":33,"Completion Time":1669331875289,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":67,"time":1669331875289}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":66,"time":1669331875289}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:55.135Z","batchId":20,"batchDuration":188,"durationMs":{"triggerExecution":187,"queryPlanning":22,"getBatch":0,"latestOffset":1,"addBatch":84,"walCommit":45},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":96}}","endOffset":"{\"12003800_test\":{\"0\":99}}","latestOffset":"{\"12003800_test\":{\"0\":99}}","numInputRows":3,"inputRowsPerSecond":13.392857142857142,"processedRowsPerSecond":15.957446808510639,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":69,"description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#483, value#484, timestamp#485, current_timestamp#486]\nArguments: [topic#483, value#484, timestamp#485, current_timestamp#486], SQLExecutionRDD[134] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#483, value#484, timestamp#485, current_timestamp#486]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@69aae086, org.apache.spark.sql.connector.write.WriteBuilder$1@e17bd8a\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3065/947795545@69aae086, org.apache.spark.sql.connector.write.WriteBuilder$1@e17bd8a","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#483,value#484,timestamp#485,current_timestamp#486]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1020,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1019,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331875378,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":34,"Submission Time":1669331875384,"Stage Infos":[{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"295\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[134],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[131],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":134,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":131,"Name":"DataSourceRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"288\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[34],"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"69","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"295\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[134],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[131],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":134,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":131,"Name":"DataSourceRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"288\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875385,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 50b2341f-40fb-4435-a1b5-fb3c3d7bd609\nrunId = ca349726-2967-45d6-b76c-42ab026277a1\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"ca349726-2967-45d6-b76c-42ab026277a1","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"69","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":34,"Stage Attempt ID":0,"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331875390,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":70,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 21","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4a553255, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@21446e50\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@53a5134c, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@a5233b7","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1047,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1048,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1049,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1046,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331875418,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":71,"description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 21","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@51074c7e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@2fee6b46\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@53a5134c, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3683/2100628581@a5233b7","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1047,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1048,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1049,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1046,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669331875427,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":35,"Submission Time":1669331875437,"Stage Infos":[{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"297\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":136,"Name":"DataSourceRDD","Scope":"{\"id\":\"300\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"300\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[136],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[35],"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 21","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"21","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"71","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"297\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":136,"Name":"DataSourceRDD","Scope":"{\"id\":\"300\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"300\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[136],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875438,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"4a9b176d-ceb3-493e-8978-5df2a3b44431","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"f9cd076e3ae4","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"42681","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1669331817839","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 4a9b176d-ceb3-493e-8978-5df2a3b44431\nrunId = 737792af-202e-4f93-af86-fdf64f05fabf\nbatch = 21","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669331818076","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"21","spark.jobGroup.id":"737792af-202e-4f93-af86-fdf64f05fabf","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"71","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125001659-0001","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":35,"Stage Attempt ID":0,"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331876017,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":34,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331875390,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331876018,"Failed":false,"Killed":false,"Accumulables":[{"ID":1015,"Name":"duration","Update":"582","Value":"582","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1016,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1019,"Name":"duration","Update":"582","Value":"582","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1020,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1021,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":1022,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7858987,"Value":7858987,"Internal":true,"Count Failed Values":true},{"ID":1023,"Name":"internal.metrics.executorRunTime","Update":607,"Value":607,"Internal":true,"Count Failed Values":true},{"ID":1024,"Name":"internal.metrics.executorCpuTime","Update":31383987,"Value":31383987,"Internal":true,"Count Failed Values":true},{"ID":1025,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1043,"Name":"internal.metrics.input.recordsRead","Update":5,"Value":5,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7858987,"Executor Run Time":607,"Executor CPU Time":31383987,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":5},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"295\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[134],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[131],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":134,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":131,"Name":"DataSourceRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"288\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875385,"Completion Time":1669331876019,"Accumulables":[{"ID":1015,"Name":"duration","Value":"582","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1016,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1019,"Name":"duration","Value":"582","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1020,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1021,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":1022,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7858987,"Internal":true,"Count Failed Values":true},{"ID":1023,"Name":"internal.metrics.executorRunTime","Value":607,"Internal":true,"Count Failed Values":true},{"ID":1024,"Name":"internal.metrics.executorCpuTime","Value":31383987,"Internal":true,"Count Failed Values":true},{"ID":1025,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1043,"Name":"internal.metrics.input.recordsRead","Value":5,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":34,"Completion Time":1669331876020,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":69,"time":1669331876021}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":68,"time":1669331876022}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:17:55.210Z","batchId":14,"batchDuration":840,"durationMs":{"triggerExecution":840,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":770,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":95}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":5,"inputRowsPerSecond":15.15151515151515,"processedRowsPerSecond":5.9523809523809526,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":35,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669331876017,"Executor ID":"0","Host":"172.20.0.13","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669331876555,"Failed":false,"Killed":false,"Accumulables":[{"ID":1046,"Name":"duration","Update":"513","Value":"513","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1047,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1050,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":1051,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7471129,"Value":7471129,"Internal":true,"Count Failed Values":true},{"ID":1052,"Name":"internal.metrics.executorRunTime","Update":516,"Value":516,"Internal":true,"Count Failed Values":true},{"ID":1053,"Name":"internal.metrics.executorCpuTime","Update":13268339,"Value":13268339,"Internal":true,"Count Failed Values":true},{"ID":1054,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1072,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":7471129,"Executor Run Time":516,"Executor CPU Time":13268339,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"297\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":136,"Name":"DataSourceRDD","Scope":"{\"id\":\"300\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"300\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[136],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669331875438,"Completion Time":1669331876556,"Accumulables":[{"ID":1046,"Name":"duration","Value":"513","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1047,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1050,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":1051,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7471129,"Internal":true,"Count Failed Values":true},{"ID":1052,"Name":"internal.metrics.executorRunTime","Value":516,"Internal":true,"Count Failed Values":true},{"ID":1053,"Name":"internal.metrics.executorCpuTime","Value":13268339,"Internal":true,"Count Failed Values":true},{"ID":1054,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1072,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":35,"Completion Time":1669331876556,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":71,"time":1669331876556}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":70,"time":1669331876556}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:17:55.323Z","batchId":21,"batchDuration":1258,"durationMs":{"triggerExecution":1258,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":1146,"walCommit":77},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":99}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":1,"inputRowsPerSecond":5.319148936170213,"processedRowsPerSecond":0.794912559618442,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:18:06.052Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:18:06.590Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:18:16.059Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:18:16.601Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:18:26.061Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:18:26.601Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:18:36.067Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:18:36.607Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:18:46.073Z","batchId":15,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:18:46.613Z","batchId":22,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:18:56.081Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:18:56.615Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:19:06.091Z","batchId":15,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:19:06.623Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:19:16.096Z","batchId":15,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:19:16.631Z","batchId":22,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:19:26.098Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:19:26.635Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:19:36.105Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:19:36.640Z","batchId":22,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:19:46.109Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:19:46.645Z","batchId":22,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:19:56.113Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:19:56.654Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:20:06.122Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:20:06.658Z","batchId":22,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:20:16.132Z","batchId":15,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:20:16.664Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:20:26.136Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:20:26.672Z","batchId":22,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:20:36.137Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:20:36.679Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:20:46.140Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:20:46.679Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"50b2341f-40fb-4435-a1b5-fb3c3d7bd609","runId":"ca349726-2967-45d6-b76c-42ab026277a1","name":null,"timestamp":"2022-11-24T23:20:56.150Z","batchId":15,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"4a9b176d-ceb3-493e-8978-5df2a3b44431","runId":"737792af-202e-4f93-af86-fdf64f05fabf","name":null,"timestamp":"2022-11-24T23:20:56.679Z","batchId":22,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3eeedc5e","numOutputRows":0},"observedMetrics":{}}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1669332057798}
