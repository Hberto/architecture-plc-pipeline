{"Event":"SparkListenerLogStart","Spark Version":"3.3.1"}
{"Event":"SparkListenerResourceProfileAdded","Resource Profile Id":0,"Executor Resource Requests":{"cores":{"Resource Name":"cores","Amount":1,"Discovery Script":"","Vendor":""},"memory":{"Resource Name":"memory","Amount":1024,"Discovery Script":"","Vendor":""},"offHeap":{"Resource Name":"offHeap","Amount":0,"Discovery Script":"","Vendor":""}},"Task Resource Requests":{"cpus":{"Resource Name":"cpus","Amount":1.0}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"221a64cc1b2e","Port":38991},"Maximum Memory":384093388,"Timestamp":1668520255535,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-8-openjdk-amd64/jre","Java Version":"1.8.0_352 (Private Build)","Scala Version":"version 2.12.15"},"Spark Properties":{"spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","spark.app.name":"Testing the Stream with Kafka","spark.app.initial.file.urls":"*********(redacted)","spark.scheduler.mode":"FIFO","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.cassandra.connection.port":"9042","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"},"Hadoop Properties":{"hadoop.service.shutdown.timeout":"30s","yarn.resourcemanager.amlauncher.thread-count":"50","yarn.sharedcache.enabled":"false","fs.s3a.connection.maximum":"96","yarn.nodemanager.numa-awareness.numactl.cmd":"/usr/bin/numactl","fs.viewfs.overload.scheme.target.o3fs.impl":"org.apache.hadoop.fs.ozone.OzoneFileSystem","fs.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms":"1000","yarn.timeline-service.timeline-client.number-of-async-entities-to-merge":"10","hadoop.security.kms.client.timeout":"60","hadoop.http.authentication.kerberos.principal":"HTTP/_HOST@LOCALHOST","mapreduce.jobhistory.loadedjob.tasks.max":"-1","yarn.resourcemanager.application-tag-based-placement.enable":"false","mapreduce.framework.name":"local","yarn.sharedcache.uploader.server.thread-count":"50","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min":"3600","yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern":"^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$","tfile.fs.output.buffer.size":"262144","yarn.app.mapreduce.am.job.task.listener.thread-count":"30","yarn.nodemanager.node-attributes.resync-interval-ms":"120000","yarn.nodemanager.container-log-monitor.interval-ms":"60000","hadoop.security.groups.cache.background.reload.threads":"3","yarn.resourcemanager.webapp.cross-origin.enabled":"false","fs.AbstractFileSystem.ftp.impl":"org.apache.hadoop.fs.ftp.FtpFs","fs.viewfs.overload.scheme.target.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","hadoop.registry.secure":"false","hadoop.shell.safely.delete.limit.num.files":"100","mapreduce.job.acl-view-job":" ","fs.s3a.s3guard.ddb.background.sleep":"25ms","fs.s3a.retry.limit":"7","mapreduce.jobhistory.loadedjobs.cache.size":"5","fs.s3a.s3guard.ddb.table.create":"false","fs.viewfs.overload.scheme.target.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.nodemanager.amrmproxy.enabled":"false","yarn.timeline-service.entity-group-fs-store.with-user-dir":"false","mapreduce.shuffle.pathcache.expire-after-access-minutes":"5","mapreduce.input.fileinputformat.split.minsize":"0","yarn.resourcemanager.container.liveness-monitor.interval-ms":"600000","yarn.resourcemanager.client.thread-count":"50","io.seqfile.compress.blocksize":"1000000","yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes":"runc","fs.viewfs.overload.scheme.target.http.impl":"org.apache.hadoop.fs.http.HttpFileSystem","yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor":"1.0","yarn.sharedcache.checksum.algo.impl":"org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl","yarn.nodemanager.amrmproxy.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor","yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size":"10485760","mapreduce.reduce.shuffle.fetch.retry.interval-ms":"1000","mapreduce.task.profile.maps":"0-2","yarn.scheduler.include-port-in-node-name":"false","yarn.nodemanager.admin-env":"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX","yarn.resourcemanager.node-removal-untracked.timeout-ms":"60000","mapreduce.am.max-attempts":"2","hadoop.security.kms.client.failover.sleep.base.millis":"100","mapreduce.jobhistory.webapp.https.address":"0.0.0.0:19890","yarn.node-labels.fs-store.impl.class":"org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore","yarn.nodemanager.collector-service.address":"${yarn.nodemanager.hostname}:8048","fs.trash.checkpoint.interval":"0","mapreduce.job.map.output.collector.class":"org.apache.hadoop.mapred.MapTask$MapOutputBuffer","yarn.resourcemanager.node-ip-cache.expiry-interval-secs":"-1","hadoop.http.authentication.signature.secret.file":"*********(redacted)","hadoop.jetty.logs.serve.aliases":"true","yarn.resourcemanager.placement-constraints.handler":"disabled","yarn.timeline-service.handler-thread-count":"10","yarn.resourcemanager.max-completed-applications":"1000","yarn.nodemanager.aux-services.manifest.enabled":"false","yarn.resourcemanager.system-metrics-publisher.enabled":"false","yarn.resourcemanager.placement-constraints.algorithm.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm","yarn.sharedcache.webapp.address":"0.0.0.0:8788","fs.s3a.select.input.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.renew-interval":"*********(redacted)","yarn.sharedcache.nm.uploader.replication.factor":"10","hadoop.security.groups.negative-cache.secs":"30","yarn.app.mapreduce.task.container.log.backups":"0","mapreduce.reduce.skip.proc-count.auto-incr":"true","fs.viewfs.overload.scheme.target.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","hadoop.security.group.mapping.ldap.posix.attr.gid.name":"gidNumber","ipc.client.fallback-to-simple-auth-allowed":"false","yarn.nodemanager.resource.memory.enforced":"true","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch":"false","yarn.client.failover-proxy-provider":"org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider","yarn.timeline-service.http-authentication.simple.anonymous.allowed":"true","ha.health-monitor.check-interval.ms":"1000","yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed":"false","hadoop.metrics.jvm.use-thread-mxbean":"false","ipc.[port_number].faircallqueue.multiplexer.weights":"8,4,2,1","yarn.acl.reservation-enable":"false","yarn.resourcemanager.store.class":"org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore","yarn.app.mapreduce.am.hard-kill-timeout-ms":"10000","fs.s3a.etag.checksum.enabled":"false","yarn.nodemanager.container-metrics.enable":"true","ha.health-monitor.rpc.connect.max.retries":"1","yarn.timeline-service.client.fd-clean-interval-secs":"60","yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable":"false","yarn.resourcemanager.nodemanagers.heartbeat-interval-ms":"1000","hadoop.common.configuration.version":"3.0.0","fs.s3a.s3guard.ddb.table.capacity.read":"0","yarn.nodemanager.remote-app-log-dir-suffix":"logs","yarn.nodemanager.container-log-monitor.dir-size-limit-bytes":"1000000000","yarn.nodemanager.windows-container.cpu-limit.enabled":"false","yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed":"false","file.blocksize":"67108864","hadoop.http.idle_timeout.ms":"60000","hadoop.registry.zk.retry.ceiling.ms":"60000","yarn.scheduler.configuration.leveldb-store.path":"${hadoop.tmp.dir}/yarn/system/confstore","yarn.sharedcache.store.in-memory.initial-delay-mins":"10","mapreduce.jobhistory.principal":"jhs/_HOST@REALM.TLD","mapreduce.map.skip.proc-count.auto-incr":"true","fs.s3a.committer.name":"file","mapreduce.task.profile.reduces":"0-2","hadoop.zk.num-retries":"1000","yarn.webapp.xfs-filter.enabled":"true","fs.viewfs.overload.scheme.target.hdfs.impl":"org.apache.hadoop.hdfs.DistributedFileSystem","seq.io.sort.mb":"100","yarn.scheduler.configuration.max.version":"100","yarn.timeline-service.webapp.https.address":"${yarn.timeline-service.hostname}:8190","yarn.resourcemanager.scheduler.address":"${yarn.resourcemanager.hostname}:8030","yarn.node-labels.enabled":"false","yarn.resourcemanager.webapp.ui-actions.enabled":"true","mapreduce.task.timeout":"600000","yarn.sharedcache.client-server.thread-count":"50","hadoop.security.groups.shell.command.timeout":"0s","hadoop.security.crypto.cipher.suite":"AES/CTR/NoPadding","yarn.nodemanager.elastic-memory-control.oom-handler":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler","yarn.resourcemanager.connect.max-wait.ms":"900000","fs.defaultFS":"file:///","yarn.minicluster.use-rpc":"false","ipc.[port_number].decay-scheduler.decay-factor":"0.5","fs.har.impl.disable.cache":"true","yarn.webapp.ui2.enable":"false","io.compression.codec.bzip2.library":"system-native","yarn.webapp.filter-invalid-xml-chars":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs":"600","fs.s3a.select.input.csv.record.delimiter":"\\n","fs.s3a.change.detection.source":"etag","ipc.[port_number].backoff.enable":"false","yarn.nodemanager.distributed-scheduling.enabled":"false","mapreduce.shuffle.connection-keep-alive.timeout":"5","yarn.resourcemanager.webapp.https.address":"${yarn.resourcemanager.hostname}:8090","yarn.webapp.enable-rest-app-submissions":"true","mapreduce.jobhistory.address":"0.0.0.0:10020","yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.is.minicluster":"false","yarn.nodemanager.address":"${yarn.nodemanager.hostname}:0","fs.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","fs.AbstractFileSystem.s3a.impl":"org.apache.hadoop.fs.s3a.S3A","mapreduce.task.combine.progress.records":"10000","yarn.resourcemanager.epoch.range":"0","yarn.resourcemanager.am.max-attempts":"2","yarn.nodemanager.runtime.linux.runc.image-toplevel-dir":"/runc-root","yarn.nodemanager.linux-container-executor.cgroups.hierarchy":"/hadoop-yarn","fs.AbstractFileSystem.wasbs.impl":"org.apache.hadoop.fs.azure.Wasbs","yarn.timeline-service.entity-group-fs-store.cache-store-class":"org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore","yarn.nodemanager.runtime.linux.runc.allowed-container-networks":"host,none,bridge","fs.ftp.transfer.mode":"BLOCK_TRANSFER_MODE","ipc.server.log.slow.rpc":"false","ipc.server.reuseaddr":"true","fs.ftp.timeout":"0","yarn.resourcemanager.node-labels.provider.fetch-interval-ms":"1800000","yarn.router.webapp.https.address":"0.0.0.0:8091","yarn.nodemanager.webapp.cross-origin.enabled":"false","fs.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","yarn.resourcemanager.auto-update.containers":"false","yarn.app.mapreduce.am.job.committer.cancel-timeout":"60000","yarn.scheduler.configuration.zk-store.parent-path":"/confstore","yarn.nodemanager.default-container-executor.log-dirs.permissions":"710","yarn.app.attempt.diagnostics.limit.kc":"64","fs.viewfs.overload.scheme.target.swebhdfs.impl":"org.apache.hadoop.hdfs.web.SWebHdfsFileSystem","yarn.client.failover-no-ha-proxy-provider":"org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider","fs.s3a.change.detection.mode":"server","ftp.bytes-per-checksum":"512","yarn.nodemanager.resource.memory-mb":"-1","fs.AbstractFileSystem.abfs.impl":"org.apache.hadoop.fs.azurebfs.Abfs","yarn.timeline-service.writer.flush-interval-seconds":"60","fs.s3a.fast.upload.active.blocks":"4","yarn.resourcemanager.submission-preprocessor.enabled":"false","hadoop.security.credential.clear-text-fallback":"true","yarn.nodemanager.collector-service.thread-count":"5","ipc.[port_number].scheduler.impl":"org.apache.hadoop.ipc.DefaultRpcScheduler","fs.azure.secure.mode":"false","mapreduce.jobhistory.joblist.cache.size":"20000","fs.ftp.host":"0.0.0.0","yarn.timeline-service.writer.async.queue.capacity":"100","yarn.resourcemanager.fs.state-store.num-retries":"0","yarn.resourcemanager.nodemanager-connect-retries":"10","yarn.nodemanager.log-aggregation.num-log-files-per-app":"30","hadoop.security.kms.client.encrypted.key.cache.low-watermark":"0.3f","fs.s3a.committer.magic.enabled":"true","yarn.timeline-service.client.max-retries":"30","dfs.ha.fencing.ssh.connect-timeout":"30000","yarn.log-aggregation-enable":"false","yarn.system-metrics-publisher.enabled":"false","mapreduce.reduce.markreset.buffer.percent":"0.0","fs.AbstractFileSystem.viewfs.impl":"org.apache.hadoop.fs.viewfs.ViewFs","yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor":"1.0","mapreduce.task.io.sort.factor":"10","yarn.nodemanager.amrmproxy.client.thread-count":"25","ha.failover-controller.new-active.rpc-timeout.ms":"60000","yarn.nodemanager.container-localizer.java.opts":"-Xmx256m","mapreduce.jobhistory.datestring.cache.size":"200000","mapreduce.job.acl-modify-job":" ","yarn.nodemanager.windows-container.memory-limit.enabled":"false","yarn.timeline-service.webapp.address":"${yarn.timeline-service.hostname}:8188","yarn.app.mapreduce.am.job.committer.commit-window":"10000","yarn.nodemanager.container-manager.thread-count":"20","yarn.minicluster.fixed.ports":"false","hadoop.tags.system":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.cluster.max-application-priority":"0","yarn.timeline-service.ttl-enable":"true","mapreduce.jobhistory.recovery.store.fs.uri":"${hadoop.tmp.dir}/mapred/history/recoverystore","hadoop.caller.context.signature.max.size":"40","ipc.[port_number].decay-scheduler.backoff.responsetime.enable":"false","yarn.client.load.resource-types.from-server":"false","ha.zookeeper.session-timeout.ms":"10000","ipc.[port_number].decay-scheduler.metrics.top.user.count":"10","tfile.io.chunk.size":"1048576","fs.s3a.s3guard.ddb.table.capacity.write":"0","yarn.dispatcher.print-events-info.threshold":"5000","mapreduce.job.speculative.slowtaskthreshold":"1.0","io.serializations":"org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization","hadoop.security.kms.client.failover.sleep.max.millis":"2000","hadoop.security.group.mapping.ldap.directory.search.timeout":"10000","yarn.scheduler.configuration.store.max-logs":"1000","yarn.nodemanager.node-attributes.provider.fetch-interval-ms":"600000","fs.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","yarn.nodemanager.local-cache.max-files-per-directory":"8192","hadoop.http.cross-origin.enabled":"false","hadoop.zk.acl":"world:anyone:rwcda","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache":"10","mapreduce.map.sort.spill.percent":"0.80","yarn.timeline-service.entity-group-fs-store.scan-interval-seconds":"60","yarn.node-attribute.fs-store.impl.class":"org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore","fs.s3a.retry.interval":"500ms","yarn.timeline-service.client.best-effort":"false","yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled":"*********(redacted)","hadoop.security.group.mapping.ldap.posix.attr.uid.name":"uidNumber","fs.AbstractFileSystem.swebhdfs.impl":"org.apache.hadoop.fs.SWebHdfs","yarn.nodemanager.elastic-memory-control.timeout-sec":"5","fs.s3a.select.enabled":"true","mapreduce.ifile.readahead":"true","yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms":"300000","yarn.timeline-service.reader.webapp.address":"${yarn.timeline-service.webapp.address}","yarn.resourcemanager.placement-constraints.algorithm.pool-size":"1","yarn.timeline-service.hbase.coprocessor.jar.hdfs.location":"/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar","hadoop.security.kms.client.encrypted.key.cache.num.refill.threads":"2","yarn.resourcemanager.scheduler.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler","yarn.app.mapreduce.am.command-opts":"-Xmx1024m","fs.s3a.metadatastore.fail.on.write.error":"true","hadoop.http.sni.host.check.enabled":"false","mapreduce.cluster.local.dir":"${hadoop.tmp.dir}/mapred/local","io.mapfile.bloom.error.rate":"0.005","fs.client.resolve.topology.enabled":"false","yarn.nodemanager.runtime.linux.allowed-runtimes":"default","yarn.sharedcache.store.class":"org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore","ha.failover-controller.graceful-fence.rpc-timeout.ms":"5000","ftp.replication":"3","fs.getspaceused.jitterMillis":"60000","hadoop.security.uid.cache.secs":"14400","mapreduce.job.maxtaskfailures.per.tracker":"3","fs.s3a.metadatastore.impl":"org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore","io.skip.checksum.errors":"false","yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts":"3","yarn.timeline-service.webapp.xfs-filter.xframe-options":"SAMEORIGIN","fs.s3a.connection.timeout":"200000","yarn.app.mapreduce.am.webapp.https.enabled":"false","mapreduce.job.max.split.locations":"15","yarn.resourcemanager.nm-container-queuing.max-queue-length":"15","yarn.resourcemanager.delegation-token.always-cancel":"*********(redacted)","hadoop.registry.zk.session.timeout.ms":"60000","yarn.federation.cache-ttl.secs":"300","mapreduce.jvm.system-properties-to-log":"os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name","yarn.resourcemanager.opportunistic-container-allocation.nodes-used":"10","yarn.timeline-service.entity-group-fs-store.active-dir":"/tmp/entity-file-history/active","mapreduce.shuffle.transfer.buffer.size":"131072","yarn.timeline-service.client.retry-interval-ms":"1000","yarn.timeline-service.flowname.max-size":"0","yarn.http.policy":"HTTP_ONLY","fs.s3a.socket.send.buffer":"8192","fs.AbstractFileSystem.abfss.impl":"org.apache.hadoop.fs.azurebfs.Abfss","yarn.sharedcache.uploader.server.address":"0.0.0.0:8046","yarn.resourcemanager.delegation-token.max-conf-size-bytes":"*********(redacted)","hadoop.http.authentication.token.validity":"*********(redacted)","mapreduce.shuffle.max.connections":"0","yarn.minicluster.yarn.nodemanager.resource.memory-mb":"4096","mapreduce.job.emit-timeline-data":"false","yarn.nodemanager.resource.system-reserved-memory-mb":"-1","hadoop.kerberos.min.seconds.before.relogin":"60","mapreduce.jobhistory.move.thread-count":"3","yarn.resourcemanager.admin.client.thread-count":"1","yarn.dispatcher.drain-events.timeout":"300000","ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds":"10s,20s,30s,40s","fs.s3a.buffer.dir":"${hadoop.tmp.dir}/s3a","hadoop.ssl.enabled.protocols":"TLSv1.2","mapreduce.jobhistory.admin.address":"0.0.0.0:10033","yarn.log-aggregation-status.time-out.ms":"600000","fs.s3a.accesspoint.required":"false","mapreduce.shuffle.port":"13562","yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory":"10","yarn.nodemanager.health-checker.interval-ms":"600000","yarn.router.clientrm.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor","yarn.resourcemanager.zk-appid-node.split-index":"0","ftp.blocksize":"67108864","yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions":"read","yarn.router.rmadmin.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor","yarn.nodemanager.log-container-debug-info.enabled":"true","yarn.resourcemanager.activities-manager.app-activities.max-queue-length":"100","yarn.resourcemanager.application-https.policy":"NONE","yarn.client.max-cached-nodemanagers-proxies":"0","yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms":"20","yarn.nodemanager.delete.debug-delay-sec":"0","yarn.nodemanager.pmem-check-enabled":"true","yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage":"90.0","mapreduce.app-submission.cross-platform":"false","yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms":"10000","yarn.nodemanager.container-retry-minimum-interval-ms":"1000","hadoop.security.groups.cache.secs":"300","yarn.federation.enabled":"false","yarn.workflow-id.tag-prefix":"workflowid:","fs.azure.local.sas.key.mode":"false","ipc.maximum.data.length":"134217728","fs.s3a.endpoint":"s3.amazonaws.com","mapreduce.shuffle.max.threads":"0","yarn.router.pipeline.cache-max-size":"25","yarn.resourcemanager.nm-container-queuing.load-comparator":"QUEUE_LENGTH","yarn.resourcemanager.resource-tracker.nm.ip-hostname-check":"false","hadoop.security.authorization":"false","mapreduce.job.complete.cancel.delegation.tokens":"*********(redacted)","fs.s3a.paging.maximum":"5000","nfs.exports.allowed.hosts":"* rw","yarn.nodemanager.amrmproxy.ha.enable":"false","fs.AbstractFileSystem.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","mapreduce.jobhistory.http.policy":"HTTP_ONLY","yarn.sharedcache.store.in-memory.check-period-mins":"720","hadoop.security.group.mapping.ldap.ssl":"false","fs.s3a.downgrade.syncable.exceptions":"true","yarn.client.application-client-protocol.poll-interval-ms":"200","yarn.scheduler.configuration.leveldb-store.compaction-interval-secs":"86400","yarn.timeline-service.writer.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl","ha.zookeeper.parent-znode":"/hadoop-ha","yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms":"60000","yarn.nodemanager.log-aggregation.policy.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy","mapreduce.reduce.shuffle.merge.percent":"0.66","hadoop.security.group.mapping.ldap.search.filter.group":"(objectClass=group)","yarn.resourcemanager.placement-constraints.scheduler.pool-size":"1","yarn.resourcemanager.activities-manager.cleanup-interval-ms":"5000","yarn.nodemanager.resourcemanager.minimum.version":"NONE","mapreduce.job.speculative.speculative-cap-running-tasks":"0.1","yarn.admin.acl":"*","ipc.[port_number].identity-provider.impl":"org.apache.hadoop.ipc.UserIdentityProvider","yarn.nodemanager.recovery.supervised":"false","yarn.sharedcache.admin.thread-count":"1","yarn.resourcemanager.ha.automatic-failover.enabled":"true","yarn.nodemanager.container-log-monitor.total-size-limit-bytes":"10000000000","mapreduce.reduce.skip.maxgroups":"0","mapreduce.reduce.shuffle.connect.timeout":"180000","yarn.nodemanager.health-checker.scripts":"script","yarn.resourcemanager.address":"${yarn.resourcemanager.hostname}:8032","ipc.client.ping":"true","mapreduce.task.local-fs.write-limit.bytes":"-1","fs.adl.oauth2.access.token.provider.type":"*********(redacted)","mapreduce.shuffle.ssl.file.buffer.size":"65536","yarn.resourcemanager.ha.automatic-failover.embedded":"true","yarn.nodemanager.resource-plugins.gpu.docker-plugin":"nvidia-docker-v1","fs.s3a.s3guard.consistency.retry.interval":"2s","fs.s3a.multipart.purge":"false","yarn.scheduler.configuration.store.class":"file","yarn.resourcemanager.nm-container-queuing.queue-limit-stdev":"1.0f","mapreduce.job.end-notification.max.attempts":"5","mapreduce.output.fileoutputformat.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled":"false","ipc.client.bind.wildcard.addr":"false","yarn.resourcemanager.webapp.rest-csrf.enabled":"false","ha.health-monitor.connect-retry-interval.ms":"1000","yarn.nodemanager.keytab":"/etc/krb5.keytab","mapreduce.jobhistory.keytab":"/etc/security/keytab/jhs.service.keytab","fs.s3a.threads.max":"64","yarn.nodemanager.runtime.linux.docker.image-update":"false","mapreduce.reduce.shuffle.input.buffer.percent":"0.70","fs.viewfs.overload.scheme.target.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","yarn.dispatcher.cpu-monitor.samples-per-min":"60","hadoop.security.token.service.use_ip":"*********(redacted)","yarn.nodemanager.runtime.linux.docker.allowed-container-networks":"host,none,bridge","yarn.nodemanager.node-labels.resync-interval-ms":"120000","hadoop.tmp.dir":"/tmp/hadoop-${user.name}","mapreduce.job.maps":"2","mapreduce.jobhistory.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.job.end-notification.max.retry.interval":"5000","yarn.log-aggregation.retain-check-interval-seconds":"-1","yarn.resourcemanager.resource-tracker.client.thread-count":"50","yarn.nodemanager.containers-launcher.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher","yarn.rm.system-metrics-publisher.emit-container-events":"false","yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size":"10000","yarn.resourcemanager.ha.automatic-failover.zk-base-path":"/yarn-leader-election","io.seqfile.local.dir":"${hadoop.tmp.dir}/io/local","fs.s3a.s3guard.ddb.throttle.retry.interval":"100ms","fs.AbstractFileSystem.wasb.impl":"org.apache.hadoop.fs.azure.Wasb","mapreduce.client.submit.file.replication":"10","mapreduce.jobhistory.minicluster.fixed.ports":"false","fs.s3a.multipart.threshold":"128M","yarn.resourcemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","mapreduce.jobhistory.done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done","ipc.server.purge.interval":"15","ipc.client.idlethreshold":"4000","yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage":"false","mapreduce.reduce.input.buffer.percent":"0.0","yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold":"1","yarn.nodemanager.webapp.rest-csrf.enabled":"false","fs.ftp.host.port":"21","ipc.ping.interval":"60000","yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size":"10","yarn.resourcemanager.admin.address":"${yarn.resourcemanager.hostname}:8033","file.client-write-packet-size":"65536","ipc.client.kill.max":"10","mapreduce.reduce.speculative":"true","hadoop.security.key.default.bitlength":"128","mapreduce.job.reducer.unconditional-preempt.delay.sec":"300","yarn.nodemanager.disk-health-checker.interval-ms":"120000","yarn.nodemanager.log.deletion-threads-count":"4","fs.s3a.committer.abort.pending.uploads":"true","yarn.webapp.filter-entity-list-by-user":"false","yarn.resourcemanager.activities-manager.app-activities.ttl-ms":"600000","ipc.client.connection.maxidletime":"10000","mapreduce.task.io.sort.mb":"100","yarn.nodemanager.localizer.client.thread-count":"5","io.erasurecode.codec.rs.rawcoders":"rs_native,rs_java","io.erasurecode.codec.rs-legacy.rawcoders":"rs-legacy_java","yarn.sharedcache.admin.address":"0.0.0.0:8047","yarn.resourcemanager.placement-constraints.algorithm.iterator":"SERIAL","yarn.nodemanager.localizer.cache.cleanup.interval-ms":"600000","hadoop.security.crypto.codec.classes.aes.ctr.nopadding":"org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec","mapreduce.job.cache.limit.max-resources-mb":"0","fs.s3a.connection.ssl.enabled":"true","yarn.nodemanager.process-kill-wait.ms":"5000","mapreduce.job.hdfs-servers":"${fs.defaultFS}","yarn.app.mapreduce.am.webapp.https.client.auth":"false","hadoop.workaround.non.threadsafe.getpwuid":"true","fs.df.interval":"60000","ipc.[port_number].decay-scheduler.thresholds":"13,25,50","fs.s3a.multiobjectdelete.enable":"true","yarn.sharedcache.cleaner.resource-sleep-ms":"0","yarn.nodemanager.disk-health-checker.min-healthy-disks":"0.25","hadoop.shell.missing.defaultFs.warning":"false","io.file.buffer.size":"65536","fs.viewfs.overload.scheme.target.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","hadoop.security.group.mapping.ldap.search.attr.member":"member","hadoop.security.random.device.file.path":"/dev/urandom","hadoop.security.sensitive-config-keys":"*********(redacted)","fs.s3a.s3guard.ddb.max.retries":"9","fs.viewfs.overload.scheme.target.file.impl":"org.apache.hadoop.fs.LocalFileSystem","hadoop.rpc.socket.factory.class.default":"org.apache.hadoop.net.StandardSocketFactory","yarn.intermediate-data-encryption.enable":"false","yarn.resourcemanager.connect.retry-interval.ms":"30000","yarn.nodemanager.container.stderr.pattern":"{*stderr*,*STDERR*}","yarn.scheduler.minimum-allocation-mb":"1024","yarn.app.mapreduce.am.staging-dir":"/tmp/hadoop-yarn/staging","mapreduce.reduce.shuffle.read.timeout":"180000","hadoop.http.cross-origin.max-age":"1800","io.erasurecode.codec.xor.rawcoders":"xor_native,xor_java","fs.s3a.s3guard.consistency.retry.limit":"7","fs.s3a.connection.establish.timeout":"5000","mapreduce.job.running.map.limit":"0","yarn.minicluster.control-resource-monitoring":"false","hadoop.ssl.require.client.cert":"false","hadoop.kerberos.kinit.command":"kinit","yarn.federation.state-store.class":"org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore","mapreduce.reduce.log.level":"INFO","hadoop.security.dns.log-slow-lookups.threshold.ms":"1000","mapreduce.job.ubertask.enable":"false","adl.http.timeout":"-1","yarn.resourcemanager.placement-constraints.retry-attempts":"3","hadoop.caller.context.enabled":"false","hadoop.security.group.mapping.ldap.num.attempts":"3","yarn.nodemanager.vmem-pmem-ratio":"2.1","hadoop.rpc.protection":"authentication","ha.health-monitor.rpc-timeout.ms":"45000","yarn.nodemanager.remote-app-log-dir":"/tmp/logs","hadoop.zk.timeout-ms":"10000","fs.s3a.s3guard.cli.prune.age":"86400000","yarn.nodemanager.resource.pcores-vcores-multiplier":"1.0","yarn.nodemanager.runtime.linux.sandbox-mode":"disabled","yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size":"10","fs.viewfs.overload.scheme.target.webhdfs.impl":"org.apache.hadoop.hdfs.web.WebHdfsFileSystem","fs.s3a.committer.threads":"8","hadoop.zk.retry-interval-ms":"1000","hadoop.security.crypto.buffer.size":"8192","yarn.nodemanager.node-labels.provider.fetch-interval-ms":"600000","mapreduce.jobhistory.recovery.store.leveldb.path":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.client.failover-retries-on-socket-timeouts":"0","fs.s3a.ssl.channel.mode":"default_jsse","yarn.nodemanager.resource.memory.enabled":"false","fs.azure.authorization.caching.enable":"true","hadoop.security.instrumentation.requires.admin":"false","yarn.nodemanager.delete.thread-count":"4","mapreduce.job.finish-when-all-reducers-done":"true","hadoop.registry.jaas.context":"Client","yarn.timeline-service.leveldb-timeline-store.path":"${hadoop.tmp.dir}/yarn/timeline","io.map.index.interval":"128","yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms":"100","fs.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","mapreduce.job.counters.max":"120","mapreduce.jobhistory.webapp.rest-csrf.enabled":"false","yarn.timeline-service.store-class":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.jobhistory.move.interval-ms":"180000","fs.s3a.change.detection.version.required":"true","yarn.nodemanager.localizer.fetch.thread-count":"4","yarn.resourcemanager.scheduler.client.thread-count":"50","hadoop.ssl.hostname.verifier":"DEFAULT","yarn.timeline-service.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/timeline","mapreduce.job.classloader":"false","mapreduce.task.profile.map.params":"${mapreduce.task.profile.params}","ipc.client.connect.timeout":"20000","hadoop.security.auth_to_local.mechanism":"hadoop","yarn.timeline-service.app-collector.linger-period.ms":"60000","yarn.nm.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.reservation-system.planfollower.time-step":"1000","yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms":"600000","yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed":"true","yarn.webapp.api-service.enable":"false","yarn.nodemanager.recovery.enabled":"false","mapreduce.job.end-notification.retry.interval":"1000","fs.du.interval":"600000","fs.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","yarn.nodemanager.container.stderr.tail.bytes":"4096","yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled":"true","hadoop.security.group.mapping.ldap.read.timeout.ms":"60000","hadoop.security.groups.cache.warn.after.ms":"5000","file.bytes-per-checksum":"512","mapreduce.outputcommitter.factory.scheme.s3a":"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory","hadoop.security.groups.cache.background.reload":"false","yarn.nodemanager.container-monitor.enabled":"true","yarn.nodemanager.elastic-memory-control.enabled":"false","net.topology.script.number.args":"100","mapreduce.task.merge.progress.records":"10000","yarn.nodemanager.localizer.address":"${yarn.nodemanager.hostname}:8040","yarn.timeline-service.keytab":"/etc/krb5.keytab","mapreduce.reduce.shuffle.fetch.retry.timeout-ms":"30000","yarn.resourcemanager.rm.container-allocation.expiry-interval-ms":"600000","yarn.nodemanager.container-executor.exit-code-file.timeout-ms":"2000","mapreduce.fileoutputcommitter.algorithm.version":"1","yarn.resourcemanager.work-preserving-recovery.enabled":"true","mapreduce.map.skip.maxrecords":"0","yarn.sharedcache.root-dir":"/sharedcache","fs.s3a.retry.throttle.limit":"20","hadoop.http.authentication.type":"simple","fs.viewfs.overload.scheme.target.oss.impl":"org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem","mapreduce.job.cache.limit.max-resources":"0","mapreduce.task.userlog.limit.kb":"0","ipc.[port_number].weighted-cost.handler":"1","yarn.resourcemanager.scheduler.monitor.enable":"false","ipc.client.connect.max.retries":"10","hadoop.registry.zk.retry.times":"5","yarn.nodemanager.resource-monitor.interval-ms":"3000","yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices":"auto","mapreduce.job.sharedcache.mode":"disabled","yarn.nodemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.shuffle.listen.queue.size":"128","yarn.scheduler.configuration.mutation.acl-policy.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy","mapreduce.map.cpu.vcores":"1","yarn.log-aggregation.file-formats":"TFile","yarn.timeline-service.client.fd-retain-secs":"300","fs.s3a.select.output.csv.field.delimiter":",","yarn.nodemanager.health-checker.timeout-ms":"1200000","hadoop.user.group.static.mapping.overrides":"dr.who=;","fs.azure.sas.expiry.period":"90d","fs.s3a.select.output.csv.record.delimiter":"\\n","mapreduce.jobhistory.recovery.store.class":"org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService","fs.viewfs.overload.scheme.target.https.impl":"org.apache.hadoop.fs.http.HttpsFileSystem","fs.s3a.s3guard.ddb.table.sse.enabled":"false","yarn.resourcemanager.fail-fast":"${yarn.fail-fast}","yarn.resourcemanager.proxy-user-privileges.enabled":"false","yarn.router.webapp.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST","yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage":"90.0","mapreduce.job.reducer.preempt.delay.sec":"0","hadoop.util.hash.type":"murmur","yarn.nodemanager.disk-validator":"basic","yarn.app.mapreduce.client.job.max-retries":"3","fs.viewfs.overload.scheme.target.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","mapreduce.reduce.shuffle.retry-delay.max.ms":"60000","hadoop.security.group.mapping.ldap.connection.timeout.ms":"60000","mapreduce.task.profile.params":"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s","yarn.app.mapreduce.shuffle.log.backups":"0","yarn.nodemanager.container-diagnostics-maximum-size":"10000","hadoop.registry.zk.retry.interval.ms":"1000","yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms":"1000","fs.AbstractFileSystem.file.impl":"org.apache.hadoop.fs.local.LocalFs","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds":"-1","mapreduce.jobhistory.cleaner.interval-ms":"86400000","hadoop.registry.zk.quorum":"localhost:2181","yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes":"runc","mapreduce.output.fileoutputformat.compress":"false","yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs":"*********(redacted)","fs.s3a.assumed.role.session.duration":"30m","hadoop.security.group.mapping.ldap.conversion.rule":"none","hadoop.ssl.server.conf":"ssl-server.xml","fs.s3a.retry.throttle.interval":"100ms","seq.io.sort.factor":"100","fs.viewfs.overload.scheme.target.ofs.impl":"org.apache.hadoop.fs.ozone.RootedOzoneFileSystem","yarn.sharedcache.cleaner.initial-delay-mins":"10","mapreduce.client.completion.pollinterval":"5000","hadoop.ssl.keystores.factory.class":"org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory","yarn.app.mapreduce.am.resource.cpu-vcores":"1","yarn.timeline-service.enabled":"false","yarn.nodemanager.runtime.linux.docker.capabilities":"CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE","yarn.acl.enable":"false","yarn.timeline-service.entity-group-fs-store.done-dir":"/tmp/entity-file-history/done/","hadoop.security.group.mapping.ldap.num.attempts.before.failover":"3","mapreduce.task.profile":"false","hadoop.prometheus.endpoint.enabled":"false","yarn.resourcemanager.fs.state-store.uri":"${hadoop.tmp.dir}/yarn/system/rmstore","mapreduce.jobhistory.always-scan-user-dir":"false","fs.s3a.metadatastore.metadata.ttl":"15m","yarn.nodemanager.opportunistic-containers-use-pause-for-preemption":"false","yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user":"nobody","yarn.timeline-service.reader.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl","yarn.resourcemanager.configuration.provider-class":"org.apache.hadoop.yarn.LocalConfigurationProvider","yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold":"1","yarn.resourcemanager.configuration.file-system-based-store":"/yarn/conf","mapreduce.job.cache.limit.max-single-resource-mb":"0","yarn.nodemanager.runtime.linux.docker.stop.grace-period":"10","yarn.resourcemanager.resource-profiles.source-file":"resource-profiles.json","mapreduce.job.dfs.storage.capacity.kill-limit-exceed":"false","yarn.nodemanager.resource.percentage-physical-cpu-limit":"100","mapreduce.jobhistory.client.thread-count":"10","tfile.fs.input.buffer.size":"262144","mapreduce.client.progressmonitor.pollinterval":"1000","yarn.nodemanager.log-dirs":"${yarn.log.dir}/userlogs","yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat":"-1","fs.automatic.close":"true","yarn.resourcemanager.delegation-token-renewer.thread-retry-interval":"*********(redacted)","fs.s3a.select.input.csv.quote.character":"\"","yarn.nodemanager.hostname":"0.0.0.0","ipc.[port_number].cost-provider.impl":"org.apache.hadoop.ipc.DefaultCostProvider","yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin","yarn.nodemanager.remote-app-log-dir-include-older":"true","yarn.nodemanager.resource.memory.cgroups.swappiness":"0","ftp.stream-buffer-size":"4096","yarn.fail-fast":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep":"100","yarn.timeline-service.app-aggregation-interval-secs":"15","hadoop.security.group.mapping.ldap.search.filter.user":"(&(objectClass=user)(sAMAccountName={0}))","ipc.[port_number].weighted-cost.lockshared":"10","yarn.nodemanager.container-localizer.log.level":"INFO","yarn.timeline-service.address":"${yarn.timeline-service.hostname}:10200","mapreduce.job.ubertask.maxmaps":"9","fs.s3a.threads.keepalivetime":"60","mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.task.files.preserve.failedtasks":"false","yarn.app.mapreduce.client.job.retry-interval":"2000","ha.failover-controller.graceful-fence.connection.retries":"1","fs.s3a.select.output.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.max-lifetime":"*********(redacted)","hadoop.kerberos.keytab.login.autorenewal.enabled":"false","yarn.timeline-service.client.drain-entities.timeout.ms":"2000","yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin","yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms":"1000","yarn.timeline-service.entity-group-fs-store.summary-store":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.reduce.cpu.vcores":"1","mapreduce.job.encrypted-intermediate-data.buffer.kb":"128","fs.client.resolve.remote.symlinks":"true","yarn.nodemanager.webapp.https.address":"0.0.0.0:8044","hadoop.http.cross-origin.allowed-origins":"*","mapreduce.job.encrypted-intermediate-data":"false","yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled":"true","fs.s3a.executor.capacity":"16","yarn.timeline-service.entity-group-fs-store.retain-seconds":"604800","yarn.resourcemanager.metrics.runtime.buckets":"60,300,1440","yarn.timeline-service.generic-application-history.max-applications":"10000","yarn.nodemanager.local-dirs":"${hadoop.tmp.dir}/nm-local-dir","mapreduce.shuffle.connection-keep-alive.enable":"false","yarn.node-labels.configuration-type":"centralized","fs.s3a.path.style.access":"false","yarn.nodemanager.aux-services.mapreduce_shuffle.class":"org.apache.hadoop.mapred.ShuffleHandler","yarn.sharedcache.store.in-memory.staleness-period-mins":"10080","fs.adl.impl":"org.apache.hadoop.fs.adl.AdlFileSystem","yarn.resourcemanager.application.max-tags":"10","hadoop.domainname.resolver.impl":"org.apache.hadoop.net.DNSDomainNameResolver","yarn.resourcemanager.nodemanager.minimum.version":"NONE","mapreduce.jobhistory.webapp.xfs-filter.xframe-options":"SAMEORIGIN","yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled":"false","net.topology.impl":"org.apache.hadoop.net.NetworkTopology","io.map.index.skip":"0","yarn.timeline-service.reader.webapp.https.address":"${yarn.timeline-service.webapp.https.address}","fs.ftp.data.connection.mode":"ACTIVE_LOCAL_DATA_CONNECTION_MODE","mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed":"true","fs.azure.buffer.dir":"${hadoop.tmp.dir}/abfs","yarn.scheduler.maximum-allocation-vcores":"4","hadoop.http.cross-origin.allowed-headers":"X-Requested-With,Content-Type,Accept,Origin","yarn.nodemanager.log-aggregation.compression-type":"none","yarn.timeline-service.version":"1.0f","yarn.ipc.rpc.class":"org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC","mapreduce.reduce.maxattempts":"4","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size":"1000","hadoop.security.dns.log-slow-lookups.enabled":"false","mapreduce.job.committer.setup.cleanup.needed":"true","hadoop.security.secure.random.impl":"org.apache.hadoop.crypto.random.OpensslSecureRandom","mapreduce.job.running.reduce.limit":"0","fs.s3a.select.errors.include.sql":"false","fs.s3a.connection.request.timeout":"0","ipc.maximum.response.length":"134217728","yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.job.token.tracking.ids.enabled":"*********(redacted)","hadoop.caller.context.max.size":"128","yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed":"false","yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed":"false","hadoop.registry.system.acls":"sasl:yarn@, sasl:mapred@, sasl:hdfs@","yarn.nodemanager.recovery.dir":"${hadoop.tmp.dir}/yarn-nm-recovery","fs.s3a.fast.upload.buffer":"disk","mapreduce.jobhistory.intermediate-done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate","yarn.app.mapreduce.shuffle.log.separate":"true","yarn.log-aggregation.debug.filesize":"104857600","fs.s3a.max.total.tasks":"32","fs.s3a.readahead.range":"64K","hadoop.http.authentication.simple.anonymous.allowed":"true","fs.s3a.attempts.maximum":"20","hadoop.registry.zk.connection.timeout.ms":"15000","yarn.resourcemanager.delegation-token-renewer.thread-count":"*********(redacted)","yarn.resourcemanager.delegation-token-renewer.thread-timeout":"*********(redacted)","yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size":"10000","yarn.nodemanager.aux-services.manifest.reload-ms":"0","yarn.nodemanager.emit-container-events":"true","yarn.resourcemanager.resource-profiles.enabled":"false","yarn.timeline-service.hbase-schema.prefix":"prod.","fs.azure.authorization":"false","mapreduce.map.log.level":"INFO","ha.failover-controller.active-standby-elector.zk.op.retries":"3","yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs":"20","mapreduce.output.fileoutputformat.compress.type":"RECORD","yarn.resourcemanager.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/system/rmstore","yarn.timeline-service.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.ifile.readahead.bytes":"4194304","yarn.sharedcache.app-checker.class":"org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker","yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users":"true","yarn.nodemanager.resource.detect-hardware-capabilities":"false","mapreduce.cluster.acls.enabled":"false","mapreduce.job.speculative.retry-after-no-speculate":"1000","fs.viewfs.overload.scheme.target.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","hadoop.security.group.mapping.ldap.search.group.hierarchy.levels":"0","yarn.resourcemanager.fs.state-store.retry-interval-ms":"1000","file.stream-buffer-size":"4096","yarn.resourcemanager.application-timeouts.monitor.interval-ms":"3000","mapreduce.map.output.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","mapreduce.map.speculative":"true","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file":"/runc-root/image-tag-to-hash","mapreduce.job.speculative.retry-after-speculate":"15000","yarn.nodemanager.linux-container-executor.cgroups.mount":"false","yarn.app.mapreduce.am.container.log.backups":"0","yarn.app.mapreduce.am.log.level":"INFO","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin","io.bytes.per.checksum":"512","mapreduce.job.reduce.slowstart.completedmaps":"0.05","yarn.timeline-service.http-authentication.type":"simple","hadoop.security.group.mapping.ldap.search.attr.group.name":"cn","yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices":"auto","yarn.timeline-service.client.internal-timers-ttl-secs":"420","fs.s3a.select.output.csv.quote.character":"\"","hadoop.http.logs.enabled":"true","fs.s3a.block.size":"32M","yarn.sharedcache.client-server.address":"0.0.0.0:8045","yarn.nodemanager.logaggregation.threadpool-size-max":"100","yarn.resourcemanager.hostname":"0.0.0.0","yarn.resourcemanager.delegation.key.update-interval":"86400000","mapreduce.reduce.shuffle.fetch.retry.enabled":"${yarn.nodemanager.recovery.enabled}","mapreduce.map.memory.mb":"-1","mapreduce.task.skip.start.attempts":"2","fs.AbstractFileSystem.hdfs.impl":"org.apache.hadoop.fs.Hdfs","yarn.nodemanager.disk-health-checker.enable":"true","fs.s3a.select.output.csv.quote.fields":"always","ipc.client.tcpnodelay":"true","ipc.client.rpc-timeout.ms":"0","yarn.nodemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts":"*********(redacted)","ipc.client.low-latency":"false","mapreduce.input.lineinputformat.linespermap":"1","yarn.router.interceptor.user.threadpool-size":"5","ipc.client.connect.max.retries.on.timeouts":"45","yarn.timeline-service.leveldb-timeline-store.read-cache-size":"104857600","fs.AbstractFileSystem.har.impl":"org.apache.hadoop.fs.HarFs","mapreduce.job.split.metainfo.maxsize":"10000000","yarn.am.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.timeline-service.entity-group-fs-store.app-cache-size":"10","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs":"360","fs.s3a.socket.recv.buffer":"8192","rpc.metrics.timeunit":"MILLISECONDS","yarn.resourcemanager.resource-tracker.address":"${yarn.resourcemanager.hostname}:8031","yarn.nodemanager.node-labels.provider.fetch-timeout-ms":"1200000","mapreduce.job.heap.memory-mb.ratio":"0.8","yarn.resourcemanager.leveldb-state-store.compaction-interval-secs":"3600","yarn.resourcemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","yarn.nodemanager.pluggable-device-framework.enabled":"false","yarn.scheduler.configuration.fs.path":"file://${hadoop.tmp.dir}/yarn/system/schedconf","mapreduce.client.output.filter":"FAILED","hadoop.http.filter.initializers":"org.apache.hadoop.http.lib.StaticUserWebFilter","mapreduce.reduce.memory.mb":"-1","yarn.timeline-service.hostname":"0.0.0.0","file.replication":"1","yarn.nodemanager.container-metrics.unregister-delay-ms":"10000","yarn.nodemanager.container-metrics.period-ms":"-1","mapreduce.fileoutputcommitter.task.cleanup.enabled":"false","yarn.nodemanager.log.retain-seconds":"10800","yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds":"3600","ipc.[port_number].callqueue.impl":"java.util.concurrent.LinkedBlockingQueue","yarn.resourcemanager.keytab":"/etc/krb5.keytab","hadoop.security.group.mapping.providers.combined":"true","mapreduce.reduce.merge.inmem.threshold":"1000","yarn.timeline-service.recovery.enabled":"false","fs.azure.saskey.usecontainersaskeyforallaccess":"true","yarn.sharedcache.nm.uploader.thread-count":"20","yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs":"3600","ipc.[port_number].weighted-cost.lockfree":"1","mapreduce.shuffle.ssl.enabled":"false","yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds":"259200000","yarn.nodemanager.opportunistic-containers-max-queue-length":"0","yarn.resourcemanager.state-store.max-completed-applications":"${yarn.resourcemanager.max-completed-applications}","mapreduce.job.speculative.minimum-allowed-tasks":"10","fs.s3a.aws.credentials.provider":"\n    org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,\n    org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,\n    com.amazonaws.auth.EnvironmentVariableCredentialsProvider,\n    org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider\n  ","yarn.log-aggregation.retain-seconds":"-1","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb":"0","mapreduce.jobhistory.max-age-ms":"604800000","hadoop.http.cross-origin.allowed-methods":"GET,POST,HEAD","yarn.resourcemanager.opportunistic-container-allocation.enabled":"false","mapreduce.jobhistory.webapp.address":"0.0.0.0:19888","hadoop.system.tags":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.log-aggregation.file-controller.TFile.class":"org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController","yarn.client.nodemanager-connect.max-wait-ms":"180000","yarn.resourcemanager.webapp.address":"${yarn.resourcemanager.hostname}:8088","mapreduce.jobhistory.recovery.enable":"false","mapreduce.reduce.shuffle.parallelcopies":"5","fs.AbstractFileSystem.webhdfs.impl":"org.apache.hadoop.fs.WebHdfs","fs.trash.interval":"0","yarn.app.mapreduce.client.max-retries":"3","hadoop.security.authentication":"simple","mapreduce.task.profile.reduce.params":"${mapreduce.task.profile.params}","yarn.app.mapreduce.am.resource.mb":"1536","mapreduce.input.fileinputformat.list-status.num-threads":"1","yarn.nodemanager.container-executor.class":"org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor","io.mapfile.bloom.size":"1048576","yarn.timeline-service.ttl-ms":"604800000","yarn.resourcemanager.nm-container-queuing.min-queue-length":"5","yarn.nodemanager.resource.cpu-vcores":"-1","mapreduce.job.reduces":"1","fs.s3a.multipart.size":"64M","fs.s3a.select.input.csv.comment.marker":"#","yarn.scheduler.minimum-allocation-vcores":"1","mapreduce.job.speculative.speculative-cap-total-tasks":"0.01","hadoop.ssl.client.conf":"ssl-client.xml","mapreduce.job.queuename":"default","mapreduce.job.encrypted-intermediate-data-key-size-bits":"128","fs.s3a.metadatastore.authoritative":"false","ipc.[port_number].weighted-cost.response":"1","yarn.nodemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","ha.health-monitor.sleep-after-disconnect.ms":"1000","yarn.app.mapreduce.shuffle.log.limit.kb":"0","hadoop.security.group.mapping":"org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback","yarn.client.application-client-protocol.poll-timeout-ms":"-1","mapreduce.jobhistory.jhist.format":"binary","mapreduce.task.stuck.timeout-ms":"600000","yarn.resourcemanager.application.max-tag.length":"100","yarn.resourcemanager.ha.enabled":"false","dfs.client.ignore.namenode.default.kms.uri":"false","hadoop.http.staticuser.user":"dr.who","mapreduce.task.exit.timeout.check-interval-ms":"20000","mapreduce.jobhistory.intermediate-user-done-dir.permissions":"770","mapreduce.task.exit.timeout":"60000","yarn.nodemanager.linux-container-executor.resources-handler.class":"org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler","mapreduce.reduce.shuffle.memory.limit.percent":"0.25","yarn.resourcemanager.reservation-system.enable":"false","mapreduce.map.output.compress":"false","ha.zookeeper.acl":"world:anyone:rwcda","ipc.server.max.connections":"0","yarn.nodemanager.runtime.linux.docker.default-container-network":"host","yarn.router.webapp.address":"0.0.0.0:8089","yarn.scheduler.maximum-allocation-mb":"8192","yarn.resourcemanager.scheduler.monitor.policies":"org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy","yarn.sharedcache.cleaner.period-mins":"1440","yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint":"http://localhost:3476/v1.0/docker/cli","yarn.app.mapreduce.am.container.log.limit.kb":"0","ipc.client.connect.retry.interval":"1000","yarn.timeline-service.http-cross-origin.enabled":"false","fs.wasbs.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure","yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms":"1000","yarn.federation.subcluster-resolver.class":"org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl","yarn.resourcemanager.zk-state-store.parent-path":"/rmstore","fs.s3a.select.input.csv.field.delimiter":",","mapreduce.jobhistory.cleaner.enable":"true","yarn.timeline-service.client.fd-flush-interval-secs":"10","hadoop.security.kms.client.encrypted.key.cache.expiry":"43200000","yarn.client.nodemanager-client-async.thread-pool-max-size":"500","mapreduce.map.maxattempts":"4","yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms":"1000","fs.s3a.committer.staging.tmp.path":"tmp/staging","yarn.nodemanager.sleep-delay-before-sigkill.ms":"250","yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms":"10","mapreduce.job.end-notification.retry.attempts":"0","yarn.nodemanager.resource.count-logical-processors-as-cores":"false","hadoop.registry.zk.root":"/registry","adl.feature.ownerandgroup.enableupn":"false","yarn.resourcemanager.zk-max-znode-size.bytes":"1048576","mapreduce.job.reduce.shuffle.consumer.plugin.class":"org.apache.hadoop.mapreduce.task.reduce.Shuffle","yarn.resourcemanager.delayed.delegation-token.removal-interval-ms":"*********(redacted)","yarn.nodemanager.localizer.cache.target-size-mb":"10240","fs.s3a.committer.staging.conflict-mode":"append","mapreduce.client.libjars.wildcard":"true","fs.s3a.committer.staging.unique-filenames":"true","yarn.nodemanager.node-attributes.provider.fetch-timeout-ms":"1200000","fs.s3a.list.version":"2","ftp.client-write-packet-size":"65536","ipc.[port_number].weighted-cost.lockexclusive":"100","fs.AbstractFileSystem.adl.impl":"org.apache.hadoop.fs.adl.Adl","yarn.nodemanager.container-log-monitor.enable":"false","hadoop.security.key.default.cipher":"AES/CTR/NoPadding","yarn.client.failover-retries":"0","fs.s3a.multipart.purge.age":"86400","mapreduce.job.local-fs.single-disk-limit.check.interval-ms":"5000","net.topology.node.switch.mapping.impl":"org.apache.hadoop.net.ScriptBasedMapping","yarn.nodemanager.amrmproxy.address":"0.0.0.0:8049","ipc.server.listen.queue.size":"256","ipc.[port_number].decay-scheduler.period-ms":"5000","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs":"60","map.sort.class":"org.apache.hadoop.util.QuickSort","fs.viewfs.rename.strategy":"SAME_MOUNTPOINT","hadoop.security.kms.client.authentication.retry-count":"1","fs.permissions.umask-mode":"022","fs.s3a.assumed.role.credentials.provider":"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed":"false","yarn.nodemanager.vmem-check-enabled":"true","yarn.nodemanager.numa-awareness.enabled":"false","yarn.nodemanager.recovery.compaction-interval-secs":"3600","yarn.app.mapreduce.client-am.ipc.max-retries":"3","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds":"60","yarn.federation.registry.base-dir":"yarnfederation/","yarn.nodemanager.health-checker.run-before-startup":"false","mapreduce.job.max.map":"-1","mapreduce.job.local-fs.single-disk-limit.bytes":"-1","mapreduce.shuffle.pathcache.concurrency-level":"16","mapreduce.job.ubertask.maxreduces":"1","mapreduce.shuffle.pathcache.max-weight":"10485760","hadoop.security.kms.client.encrypted.key.cache.size":"500","hadoop.security.java.secure.random.algorithm":"SHA1PRNG","ha.failover-controller.cli-check.rpc-timeout.ms":"20000","mapreduce.jobhistory.jobname.limit":"50","fs.s3a.select.input.compression":"none","yarn.client.nodemanager-connect.retry-interval-ms":"10000","ipc.[port_number].scheduler.priority.levels":"4","yarn.timeline-service.state-store-class":"org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore","yarn.nodemanager.env-whitelist":"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ","yarn.sharedcache.nested-level":"3","yarn.timeline-service.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","fs.azure.user.agent.prefix":"unknown","yarn.resourcemanager.zk-delegation-token-node.split-index":"*********(redacted)","yarn.nodemanager.numa-awareness.read-topology":"false","yarn.nodemanager.webapp.address":"${yarn.nodemanager.hostname}:8042","rpc.metrics.quantile.enable":"false","yarn.registry.class":"org.apache.hadoop.registry.client.impl.FSRegistryOperationsService","mapreduce.jobhistory.admin.acl":"*","yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size":"10","yarn.scheduler.queue-placement-rules":"user-group","hadoop.http.authentication.kerberos.keytab":"${user.home}/hadoop.keytab","yarn.resourcemanager.recovery.enabled":"false","fs.s3a.select.input.csv.header":"none","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size":"500","yarn.timeline-service.webapp.rest-csrf.enabled":"false","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb":"0"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.maintenance.version":"4","java.specification.version":"1.8","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Private Build","java.vm.specification.version":"1.8","user.home":"/root","file.encoding.pkg":"sun.io","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64","user.dir":"/scripts","java.library.path":"/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"25.352-b08","jetty.git.hash":"6b67c5719d1f4371b33655ff2d047d24e171e49a","java.endorsed.dirs":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed","java.runtime.version":"1.8.0_352-8u352-ga-1~20.04-b08","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"52.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes","file.encoding":"UTF-8","user.timezone":"Europe/Berlin","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"5.15.0-52-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Private Build","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"root","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"*********(redacted)","java.home":"/usr/lib/jvm/java-8-openjdk-amd64/jre","java.version":"1.8.0_352","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"spark://221a64cc1b2e:43125/jars/io.dropwizard.metrics_metrics-core-4.0.5.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-policy-5.12.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.spark-project.spark_unused-1.0.0.jar":"Added By User","spark://221a64cc1b2e:43125/files/com.datastax.oss_java-driver-core-shaded-4.7.2.jar":"Added By User","spark://221a64cc1b2e:43125/jars/com.squareup.moshi_moshi-1.5.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-network-shuffle_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/HikariCP-2.5.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/univocity-parsers-2.9.1.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.reactivestreams_reactive-streams-1.0.2.jar":"Added By User","spark://221a64cc1b2e:43125/jars/org.apache.kafka_kafka-clients-3.2.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/flatbuffers-java-1.12.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-dbcp-1.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/stax-api-1.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-metrics-5.12.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.github.spotbugs_spotbugs-annotations-3.1.12.jar":"Added By User","spark://221a64cc1b2e:43125/files/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar":"Added By User","spark://221a64cc1b2e:43125/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/okhttp-3.12.12.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-core-asl-1.9.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.ws.rs-api-2.1.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-platform_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/compress-lzf-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-api-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-cli-2.3.9.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.squareup.retrofit2_converter-moshi-2.4.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-scalap_2.12-3.7.0-M11.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.squareup.okio_okio-1.14.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-pool-1.5.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/tink-1.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-sketch_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-memory-netty-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-kvstore_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-util_2.12-0.17.0.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.google.code.findbugs_jsr305-3.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/slf4j-api-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/chill-java-0.10.0.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.apache.hadoop_hadoop-client-api-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javolution-5.5.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/blas-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/chill_2.12-0.10.0.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/JLargeArrays-1.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-locator-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-ipc-1.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-encoding-1.12.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.apache.kafka_kafka-clients-3.2.1.jar":"Added By User","spark://221a64cc1b2e:43125/jars/org.msgpack_msgpack-core-0.8.16.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.javatuples_javatuples-1.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-jdbc-2.3.9.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/shapeless_2.12-2.3.7.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-macros_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/algebra_2.12-2.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-logging-1.1.3.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-reflect-2.12.15.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-tcnative-classes-2.0.48.Final.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/commons-logging_commons-logging-1.1.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-compiler-3.0.16.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-rdbms-4.1.19.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-batch-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-math3-3.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/snappy-java-1.1.8.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jpam-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/paranamer-2.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/aopalliance-repackaged-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/minlog-1.3.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arpack-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/aircompressor-0.21.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar":"Added By User","spark://221a64cc1b2e:43125/files/com.datastax.oss_java-driver-query-builder-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/xbean-asm9-shaded-4.20.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/lz4-java-1.8.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/osgi-resource-locator-1.0.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/automaton-1.11-8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jdo-api-3.0.1.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.spark-project.spark_unused-1.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-2.3.9.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.squareup.moshi_moshi-1.5.0.jar":"Added By User","spark://221a64cc1b2e:43125/jars/com.thoughtworks.paranamer_paranamer-2.8.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/derby-10.14.2.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-mapreduce-1.7.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/velocity-1.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/stream-2.9.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jaxb-runtime-2.3.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/io.dropwizard.metrics_metrics-core-4.0.5.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-sql_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zookeeper-3.6.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-server-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-vector-code-gen-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/protobuf-java-2.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-core_2.12-3.7.0-M11.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-memory-core-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-autoscaling-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/guava-14.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-common-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mesos_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/shims-0.9.25.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-datatype-jsr310-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-network-common_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/RoaringBitmap-0.9.25.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/istack-commons-runtime-3.0.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/httpcore-4.4.14.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-module-scala_2.12-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-handler-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-api-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-exec-2.3.9-core.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/breeze_2.12-1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/httpclient-4.5.13.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-cli-1.5.0.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/libthrift-0.12.0.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-yarn_2.12-3.3.1.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.squareup.okio_okio-1.14.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-unix-common-4.1.74.Final.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.typesafe_config-1.3.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jul-to-slf4j-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jta-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-catalyst_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/ST4-4.0.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-shaded-guava-1.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-apiextensions-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-collection-compat_2.12-2.1.1.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire_2.12-0.17.0.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","spark://221a64cc1b2e:43125/files/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/libfb303-0.9.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-admissionregistration-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-text-1.9.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.squareup.okhttp3_okhttp-3.11.0.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.hdrhistogram_HdrHistogram-2.1.11.jar":"Added By User","spark://221a64cc1b2e:43125/files/ch.cern.sparkmeasure_spark-measure_2.12-0.19.jar":"Added By User","spark://221a64cc1b2e:43125/files/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/super-csv-2.2.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/leveldbjni-all-1.8.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.slf4j_slf4j-api-1.7.36.jar":"Added By User","spark://221a64cc1b2e:43125/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-io-2.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-hk2-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/JTransforms-3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-node-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-service-rpc-3.1.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.squareup.okhttp3_okhttp-3.11.0.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.xerial.snappy_snappy-java-1.1.8.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-dataformat-yaml-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-framework-2.13.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-kubernetes_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-compress-1.21.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-yarn-server-web-proxy-3.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-mapred-1.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-api-jdo-4.2.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-core_2.12-3.3.1.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/janino-3.0.16.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-library-2.12.15.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-metastore-2.3.9.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-1.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/opencsv-2.3.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.datastax.oss_java-driver-query-builder-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-codec-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-jackson_2.12-3.7.0-M11.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-compiler-2.12.15.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-databind-2.13.4.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/oro-2.0.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-all-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/mesos-1.4.3-shaded-protobuf.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-classes-kqueue-4.1.74.Final.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-container-servlet-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jsr305-3.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-coordination-5.12.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.squareup.okhttp3_logging-interceptor-3.11.0.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.lz4_lz4-java-1.8.0.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.scala-lang_scala-reflect-2.12.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/okio-1.14.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-graphite-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-lang3-3.12.0.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.slf4j_slf4j-api-1.7.36.jar":"Added By User","spark://221a64cc1b2e:43125/files/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/xz-1.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/antlr4-runtime-4.8.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.fasterxml.jackson.core_jackson-core-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-buffer-4.1.74.Final.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.msgpack_msgpack-core-0.8.16.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-jmx-4.2.7.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.scala-lang_scala-reflect-2.12.11.jar":"Added By User","spark://221a64cc1b2e:43125/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar":"Added By User","spark://221a64cc1b2e:43125/jars/com.datastax.oss_native-protocol-1.4.10.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/lapack-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-rbac-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-jvm-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/conf":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-common-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-serde-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-flowcontrol-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/audience-annotations-0.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-repl_2.12-3.3.1.jar":"System Classpath","spark://221a64cc1b2e:43125/files/commons-logging_commons-logging-1.1.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-1.2-api-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-classes-epoll-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-storageclass-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-discovery-5.12.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.influxdb_influxdb-java-2.14.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mllib_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-vector-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-core-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.validation-api-2.0.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.inject-2.6.1.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javassist-3.25.0-GA.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-format-structures-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-core-1.7.6.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.apache.commons_commons-lang3-3.9.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jcl-over-slf4j-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-graphx_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-storage-api-2.7.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-hive_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-codec-1.15.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.thoughtworks.paranamer_paranamer-2.8.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-jackson-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-core-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/breeze-macros_2.12-1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mllib-local_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-tags_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-common-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json-1.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-common-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/py4j-0.10.9.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-parser-combinators_2.12-1.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-scheduler-2.3.9.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.influxdb_influxdb-java-2.14.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-shims-1.7.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-xml_2.12-1.2.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-format-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-collections-3.2.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.annotation-api-1.3.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jodd-core-3.5.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/cats-kernel_2.12-2.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zstd-jni-1.5.2-1.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar":"Added By User","spark://221a64cc1b2e:43125/files/org.reactivestreams_reactive-streams-1.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/antlr-runtime-3.5.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.google.code.findbugs_jsr305-3.0.2.jar":"Added By User","spark://221a64cc1b2e:43125/jars/org.hdrhistogram_HdrHistogram-2.1.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/joda-time-2.10.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-0.23-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-annotations-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-recipes-2.13.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/gson-2.2.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/activation-1.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/bonecp-0.8.0.RELEASE.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-client-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/ivy-2.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-core-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-networking-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-unsafe_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zookeeper-jute-3.6.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.github.luben_zstd-jni-1.5.2-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-utils-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-mapper-asl-1.9.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-crypto-1.1.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javax.jdo-3.2.0-m3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-lang-2.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jline-2.14.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-beeline-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-client-2.13.0.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.squareup.retrofit2_retrofit-2.4.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/transaction-api-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar":"System Classpath","spark://221a64cc1b2e:43125/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-ast_2.12-3.7.0-M11.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.lz4_lz4-java-1.8.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/core-1.1.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.typesafe_config-1.3.4.jar":"Added By User","spark://221a64cc1b2e:43125/jars/com.squareup.retrofit2_retrofit-2.4.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/rocksdbjni-6.20.3.jar":"System Classpath","spark://221a64cc1b2e:43125/files/com.datastax.oss_native-protocol-1.4.10.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/threeten-extra-1.5.0.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-core-4.1.17.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-core-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-common-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-scheduling-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-llap-common-2.3.9.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.apache.commons_commons-lang3-3.9.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.xml.bind-api-2.3.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/org.javatuples_javatuples-1.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-common-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-tags_2.12-3.3.1-tests.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-certificates-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/logging-interceptor-3.12.12.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-json-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/pickle-1.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.datastax.oss_java-driver-core-shaded-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-resolver-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-client-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-events-5.12.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.github.luben_zstd-jni-1.5.2-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-extensions-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.servlet-api-4.0.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-api-3.3.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-container-servlet-core-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/objenesis-3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zjsonpatch-0.3.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/annotations-17.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-hive-thriftserver_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/snakeyaml-1.31.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-apps-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-hadoop-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-streaming_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-column-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-launcher_2.12-3.3.1.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-collections4-4.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arpack_combined_all-0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/generex-1.0.2.jar":"System Classpath","spark://221a64cc1b2e:43125/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.19.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kryo-shaded-4.0.2.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"Testing the Stream with Kafka","App ID":"app-20221115145055-0003","Timestamp":1668520253910,"User":"root"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1668520258471,"Executor ID":"0","Executor Info":{"Host":"172.19.0.11","Total Cores":2,"Log Urls":{"stdout":"http://172.19.0.11:8081/logPage/?appId=app-20221115145055-0003&executorId=0&logType=stdout","stderr":"http://172.19.0.11:8081/logPage/?appId=app-20221115145055-0003&executorId=0&logType=stderr"},"Attributes":{},"Resources":{},"Resource Profile Id":0}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"172.19.0.11","Port":37617},"Maximum Memory":384093388,"Timestamp":1668520258555,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:00.381Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:00.962Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":0,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 33","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@15c8e6d0, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6742c91c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2445e338, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@293d27ac","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":7,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":8,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520262151,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":1,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":4,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":5,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":6,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":2,"metricType":"timing"}]},"time":1668520262152,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":2,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 33","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1ec2b0a8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6fc89b56\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2445e338, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@293d27ac","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":3,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":7,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":8,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520262187,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1668520262793,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"7\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"DataSourceRDD","Scope":"{\"id\":\"7\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[0],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 33","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"33","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"2","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"7\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"DataSourceRDD","Scope":"{\"id\":\"7\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520262829,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 33","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"33","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"2","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520263026,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":3,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#61, value#62, timestamp#63]\nArguments: [topic#61, value#62, timestamp#63], SQLExecutionRDD[6] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#61, value#62, timestamp#63]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@323e7ad7, org.apache.spark.sql.connector.write.WriteBuilder$1@22eafc10\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@323e7ad7, org.apache.spark.sql.connector.write.WriteBuilder$1@22eafc10","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#61,value#62,timestamp#63]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":35,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":34,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520264841,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1668520264933,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"8\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"6\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"DataSourceRDD","Scope":"{\"id\":\"6\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[1],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"3","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"8\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"6\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"DataSourceRDD","Scope":"{\"id\":\"6\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520264938,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"3","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520264957,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520263026,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520266880,"Failed":false,"Killed":false,"Accumulables":[{"ID":1,"Name":"duration","Update":"2400","Value":"2400","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":9,"Name":"internal.metrics.executorDeserializeTime","Update":678,"Value":678,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.executorDeserializeCpuTime","Update":584236793,"Value":584236793,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.executorRunTime","Update":3032,"Value":3032,"Internal":true,"Count Failed Values":true},{"ID":12,"Name":"internal.metrics.executorCpuTime","Update":2153609028,"Value":2153609028,"Internal":true,"Count Failed Values":true},{"ID":13,"Name":"internal.metrics.resultSize","Update":1801,"Value":1801,"Internal":true,"Count Failed Values":true},{"ID":14,"Name":"internal.metrics.jvmGCTime","Update":184,"Value":184,"Internal":true,"Count Failed Values":true},{"ID":31,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":678,"Executor Deserialize CPU Time":584236793,"Executor Run Time":3032,"Executor CPU Time":2153609028,"Peak Execution Memory":0,"Result Size":1801,"JVM GC Time":184,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"7\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"DataSourceRDD","Scope":"{\"id\":\"7\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520262829,"Completion Time":1668520266892,"Accumulables":[{"ID":1,"Name":"duration","Value":"2400","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":3,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":9,"Name":"internal.metrics.executorDeserializeTime","Value":678,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.executorDeserializeCpuTime","Value":584236793,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.executorRunTime","Value":3032,"Internal":true,"Count Failed Values":true},{"ID":12,"Name":"internal.metrics.executorCpuTime","Value":2153609028,"Internal":true,"Count Failed Values":true},{"ID":13,"Name":"internal.metrics.resultSize","Value":1801,"Internal":true,"Count Failed Values":true},{"ID":14,"Name":"internal.metrics.jvmGCTime","Value":184,"Internal":true,"Count Failed Values":true},{"ID":31,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1668520266904,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":2,"time":1668520266937}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":0,"time":1668520266940}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:00.496Z","batchId":33,"batchDuration":6502,"durationMs":{"triggerExecution":6501,"queryPlanning":560,"getBatch":5,"latestOffset":851,"addBatch":4864,"walCommit":46},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":32}}","endOffset":"{\"12003800_test\":{\"0\":36}}","latestOffset":"{\"12003800_test\":{\"0\":36}}","numInputRows":4,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.6151953245155337,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":4},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520264957,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520268959,"Failed":false,"Killed":false,"Accumulables":[{"ID":2,"Name":"duration","Update":"3570","Value":"3570","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4,"Name":"number of output rows","Update":"36","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":34,"Name":"duration","Update":"3557","Value":"3557","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":35,"Name":"number of output rows","Update":"36","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":36,"Name":"internal.metrics.executorDeserializeTime","Update":332,"Value":332,"Internal":true,"Count Failed Values":true},{"ID":37,"Name":"internal.metrics.executorDeserializeCpuTime","Update":141988212,"Value":141988212,"Internal":true,"Count Failed Values":true},{"ID":38,"Name":"internal.metrics.executorRunTime","Update":3648,"Value":3648,"Internal":true,"Count Failed Values":true},{"ID":39,"Name":"internal.metrics.executorCpuTime","Update":2325412343,"Value":2325412343,"Internal":true,"Count Failed Values":true},{"ID":40,"Name":"internal.metrics.resultSize","Update":1916,"Value":1916,"Internal":true,"Count Failed Values":true},{"ID":41,"Name":"internal.metrics.jvmGCTime","Update":170,"Value":170,"Internal":true,"Count Failed Values":true},{"ID":58,"Name":"internal.metrics.input.recordsRead","Update":36,"Value":36,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":332,"Executor Deserialize CPU Time":141988212,"Executor Run Time":3648,"Executor CPU Time":2325412343,"Peak Execution Memory":0,"Result Size":1916,"JVM GC Time":170,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":36},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"8\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":6,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[5],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"6\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"DataSourceRDD","Scope":"{\"id\":\"6\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520264938,"Completion Time":1668520268961,"Accumulables":[{"ID":2,"Name":"duration","Value":"3570","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":4,"Name":"number of output rows","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":34,"Name":"duration","Value":"3557","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":35,"Name":"number of output rows","Value":"36","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":36,"Name":"internal.metrics.executorDeserializeTime","Value":332,"Internal":true,"Count Failed Values":true},{"ID":37,"Name":"internal.metrics.executorDeserializeCpuTime","Value":141988212,"Internal":true,"Count Failed Values":true},{"ID":38,"Name":"internal.metrics.executorRunTime","Value":3648,"Internal":true,"Count Failed Values":true},{"ID":39,"Name":"internal.metrics.executorCpuTime","Value":2325412343,"Internal":true,"Count Failed Values":true},{"ID":40,"Name":"internal.metrics.resultSize","Value":1916,"Internal":true,"Count Failed Values":true},{"ID":41,"Name":"internal.metrics.jvmGCTime","Value":170,"Internal":true,"Count Failed Values":true},{"ID":58,"Name":"internal.metrics.input.recordsRead","Value":36,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1668520268962,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":3,"time":1668520268965}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":1,"time":1668520268966}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:00.971Z","batchId":0,"batchDuration":8029,"durationMs":{"triggerExecution":8029,"queryPlanning":560,"getBatch":4,"latestOffset":489,"addBatch":6889,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":null,"endOffset":"{\"12003800_test\":{\"0\":36}}","latestOffset":"{\"12003800_test\":{\"0\":36}}","numInputRows":36,"inputRowsPerSecond":0.0,"processedRowsPerSecond":4.4837464192302905,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":4,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 34","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@392dcd42, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@34319d6\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@a5a59fa, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@51850d1d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":62,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":63,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":64,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":61,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520269881,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":5,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":66,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":67,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":68,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":65,"metricType":"timing"}]},"time":1668520269890,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":6,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 34","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1688c4a9, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@1643dc26\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@a5a59fa, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@51850d1d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":62,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":63,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":64,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":61,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520269893,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1668520269907,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"DataSourceRDD","Scope":"{\"id\":\"25\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[2],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 34","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"34","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"6","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"DataSourceRDD","Scope":"{\"id\":\"25\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520269909,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 34","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"34","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"6","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520269921,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":7,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#83, value#84, timestamp#85]\nArguments: [topic#83, value#84, timestamp#85], SQLExecutionRDD[11] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#83, value#84, timestamp#85]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@6d926167, org.apache.spark.sql.connector.write.WriteBuilder$1@5f37e212\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@6d926167, org.apache.spark.sql.connector.write.WriteBuilder$1@5f37e212","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#83,value#84,timestamp#85]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":95,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":94,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520269976,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1668520269986,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"18\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"DataSourceRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[3],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"7","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"18\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"DataSourceRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520269990,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"7","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520270006,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520269921,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520270518,"Failed":false,"Killed":false,"Accumulables":[{"ID":61,"Name":"duration","Update":"541","Value":"541","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":62,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":69,"Name":"internal.metrics.executorDeserializeTime","Update":36,"Value":36,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorDeserializeCpuTime","Update":12736881,"Value":12736881,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.executorRunTime","Update":547,"Value":547,"Internal":true,"Count Failed Values":true},{"ID":72,"Name":"internal.metrics.executorCpuTime","Update":34274823,"Value":34274823,"Internal":true,"Count Failed Values":true},{"ID":73,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":36,"Executor Deserialize CPU Time":12736881,"Executor Run Time":547,"Executor CPU Time":34274823,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"25\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"DataSourceRDD","Scope":"{\"id\":\"25\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520269909,"Completion Time":1668520270521,"Accumulables":[{"ID":61,"Name":"duration","Value":"541","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":62,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":69,"Name":"internal.metrics.executorDeserializeTime","Value":36,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12736881,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.executorRunTime","Value":547,"Internal":true,"Count Failed Values":true},{"ID":72,"Name":"internal.metrics.executorCpuTime","Value":34274823,"Internal":true,"Count Failed Values":true},{"ID":73,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1668520270522,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":6,"time":1668520270523}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":4,"time":1668520270523}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:09.812Z","batchId":34,"batchDuration":735,"durationMs":{"triggerExecution":735,"queryPlanning":17,"getBatch":0,"latestOffset":1,"addBatch":660,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":36}}","endOffset":"{\"12003800_test\":{\"0\":37}}","latestOffset":"{\"12003800_test\":{\"0\":37}}","numInputRows":1,"inputRowsPerSecond":83.33333333333333,"processedRowsPerSecond":1.3605442176870748,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520270006,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520270610,"Failed":false,"Killed":false,"Accumulables":[{"ID":65,"Name":"duration","Update":"560","Value":"560","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":66,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":94,"Name":"duration","Update":"560","Value":"560","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":95,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":96,"Name":"internal.metrics.executorDeserializeTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeCpuTime","Update":11061150,"Value":11061150,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorRunTime","Update":570,"Value":570,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.executorCpuTime","Update":40545398,"Value":40545398,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":25,"Executor Deserialize CPU Time":11061150,"Executor Run Time":570,"Executor CPU Time":40545398,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"18\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"DataSourceRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520269990,"Completion Time":1668520270612,"Accumulables":[{"ID":65,"Name":"duration","Value":"560","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":66,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":94,"Name":"duration","Value":"560","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":95,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":96,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11061150,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorRunTime","Value":570,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.executorCpuTime","Value":40545398,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1668520270613,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":7,"time":1668520270613}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":5,"time":1668520270614}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:09.822Z","batchId":1,"batchDuration":818,"durationMs":{"triggerExecution":818,"queryPlanning":17,"getBatch":0,"latestOffset":2,"addBatch":741,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":36}}","endOffset":"{\"12003800_test\":{\"0\":37}}","latestOffset":"{\"12003800_test\":{\"0\":37}}","numInputRows":1,"inputRowsPerSecond":83.33333333333333,"processedRowsPerSecond":1.2224938875305624,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":8,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 35","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@a44c7fb, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@450113ea\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6ecd7eee, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6adfff65","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":122,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":123,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":124,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":121,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520279914,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":10,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 35","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@19697fb1, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@487e696d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6ecd7eee, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6adfff65","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":122,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":123,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":124,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":121,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520279925,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":9,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":126,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":127,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":128,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":125,"metricType":"timing"}]},"time":1668520279926,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1668520279937,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"DataSourceRDD","Scope":"{\"id\":\"42\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"42\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[4],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 35","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"35","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"10","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"DataSourceRDD","Scope":"{\"id\":\"42\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"42\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520279939,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 35","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"35","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"10","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520279949,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":11,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#105, value#106, timestamp#107]\nArguments: [topic#105, value#106, timestamp#107], SQLExecutionRDD[22] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#105, value#106, timestamp#107]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@75f975a7, org.apache.spark.sql.connector.write.WriteBuilder$1@bc1327b\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@75f975a7, org.apache.spark.sql.connector.write.WriteBuilder$1@bc1327b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#105,value#106,timestamp#107]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":155,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":154,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520280027,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1668520280034,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"DataSourceRDD","Scope":"{\"id\":\"43\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"43\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[5],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"11","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"DataSourceRDD","Scope":"{\"id\":\"43\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"43\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520280035,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"11","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520280045,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520279949,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520280531,"Failed":false,"Killed":false,"Accumulables":[{"ID":121,"Name":"duration","Update":"529","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":122,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":129,"Name":"internal.metrics.executorDeserializeTime","Update":34,"Value":34,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10111307,"Value":10111307,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorRunTime","Update":539,"Value":539,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.executorCpuTime","Update":26749069,"Value":26749069,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSize","Update":1801,"Value":1801,"Internal":true,"Count Failed Values":true},{"ID":134,"Name":"internal.metrics.jvmGCTime","Update":102,"Value":102,"Internal":true,"Count Failed Values":true},{"ID":151,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":34,"Executor Deserialize CPU Time":10111307,"Executor Run Time":539,"Executor CPU Time":26749069,"Peak Execution Memory":0,"Result Size":1801,"JVM GC Time":102,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"DataSourceRDD","Scope":"{\"id\":\"42\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"42\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520279939,"Completion Time":1668520280533,"Accumulables":[{"ID":121,"Name":"duration","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":122,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":129,"Name":"internal.metrics.executorDeserializeTime","Value":34,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10111307,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.executorRunTime","Value":539,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.executorCpuTime","Value":26749069,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSize","Value":1801,"Internal":true,"Count Failed Values":true},{"ID":134,"Name":"internal.metrics.jvmGCTime","Value":102,"Internal":true,"Count Failed Values":true},{"ID":151,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1668520280534,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":10,"time":1668520280535}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":8,"time":1668520280535}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:19.826Z","batchId":35,"batchDuration":740,"durationMs":{"triggerExecution":740,"queryPlanning":34,"getBatch":1,"latestOffset":1,"addBatch":633,"walCommit":28},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":37}}","endOffset":"{\"12003800_test\":{\"0\":38}}","latestOffset":"{\"12003800_test\":{\"0\":38}}","numInputRows":1,"inputRowsPerSecond":71.42857142857143,"processedRowsPerSecond":1.3513513513513513,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520280045,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520280787,"Failed":false,"Killed":false,"Accumulables":[{"ID":125,"Name":"duration","Update":"672","Value":"672","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":154,"Name":"duration","Update":"672","Value":"672","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":155,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":156,"Name":"internal.metrics.executorDeserializeTime","Update":30,"Value":30,"Internal":true,"Count Failed Values":true},{"ID":157,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9501386,"Value":9501386,"Internal":true,"Count Failed Values":true},{"ID":158,"Name":"internal.metrics.executorRunTime","Update":702,"Value":702,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorCpuTime","Update":36864593,"Value":36864593,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.resultSize","Update":1916,"Value":1916,"Internal":true,"Count Failed Values":true},{"ID":161,"Name":"internal.metrics.jvmGCTime","Update":102,"Value":102,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":30,"Executor Deserialize CPU Time":9501386,"Executor Run Time":702,"Executor CPU Time":36864593,"Peak Execution Memory":0,"Result Size":1916,"JVM GC Time":102,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"DataSourceRDD","Scope":"{\"id\":\"43\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"43\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520280035,"Completion Time":1668520280788,"Accumulables":[{"ID":125,"Name":"duration","Value":"672","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":154,"Name":"duration","Value":"672","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":155,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":156,"Name":"internal.metrics.executorDeserializeTime","Value":30,"Internal":true,"Count Failed Values":true},{"ID":157,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9501386,"Internal":true,"Count Failed Values":true},{"ID":158,"Name":"internal.metrics.executorRunTime","Value":702,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorCpuTime","Value":36864593,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.resultSize","Value":1916,"Internal":true,"Count Failed Values":true},{"ID":161,"Name":"internal.metrics.jvmGCTime","Value":102,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1668520280788,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":11,"time":1668520280789}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":9,"time":1668520280789}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:19.824Z","batchId":2,"batchDuration":996,"durationMs":{"triggerExecution":996,"queryPlanning":16,"getBatch":0,"latestOffset":1,"addBatch":880,"walCommit":66},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":37}}","endOffset":"{\"12003800_test\":{\"0\":38}}","latestOffset":"{\"12003800_test\":{\"0\":38}}","numInputRows":1,"inputRowsPerSecond":83.33333333333333,"processedRowsPerSecond":1.0040160642570282,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":12,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":182,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":183,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":184,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":181,"metricType":"timing"}]},"time":1668520289878,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":13,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 36","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6ed4311f, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6d8decbe\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7447dc75, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6a333b82","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":186,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":187,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":188,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":185,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520289880,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":14,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 36","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3e204607, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@4b0770a4\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7447dc75, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6a333b82","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":186,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":187,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":188,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":185,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520289892,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1668520289911,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"58\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"DataSourceRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[6],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 36","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"36","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"14","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"58\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"DataSourceRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520289913,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 36","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"36","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"14","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520289922,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":15,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#126, value#127, timestamp#128]\nArguments: [topic#126, value#127, timestamp#128], SQLExecutionRDD[27] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#126, value#127, timestamp#128]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@6f913c53, org.apache.spark.sql.connector.write.WriteBuilder$1@24439c43\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@6f913c53, org.apache.spark.sql.connector.write.WriteBuilder$1@24439c43","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#126,value#127,timestamp#128]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":215,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":214,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520289960,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1668520289983,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"DataSourceRDD","Scope":"{\"id\":\"57\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"57\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[7],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"15","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"DataSourceRDD","Scope":"{\"id\":\"57\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"57\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520289987,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"15","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520289996,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520289922,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520290504,"Failed":false,"Killed":false,"Accumulables":[{"ID":185,"Name":"duration","Update":"544","Value":"544","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":186,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":189,"Name":"internal.metrics.executorDeserializeTime","Update":23,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":190,"Name":"internal.metrics.executorDeserializeCpuTime","Update":11044139,"Value":11044139,"Internal":true,"Count Failed Values":true},{"ID":191,"Name":"internal.metrics.executorRunTime","Update":548,"Value":548,"Internal":true,"Count Failed Values":true},{"ID":192,"Name":"internal.metrics.executorCpuTime","Update":41885055,"Value":41885055,"Internal":true,"Count Failed Values":true},{"ID":193,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":211,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":23,"Executor Deserialize CPU Time":11044139,"Executor Run Time":548,"Executor CPU Time":41885055,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"58\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"DataSourceRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"61\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520289913,"Completion Time":1668520290504,"Accumulables":[{"ID":185,"Name":"duration","Value":"544","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":186,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":189,"Name":"internal.metrics.executorDeserializeTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":190,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11044139,"Internal":true,"Count Failed Values":true},{"ID":191,"Name":"internal.metrics.executorRunTime","Value":548,"Internal":true,"Count Failed Values":true},{"ID":192,"Name":"internal.metrics.executorCpuTime","Value":41885055,"Internal":true,"Count Failed Values":true},{"ID":193,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":211,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1668520290505,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":14,"time":1668520290505}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":13,"time":1668520290505}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:29.823Z","batchId":36,"batchDuration":711,"durationMs":{"triggerExecution":711,"queryPlanning":14,"getBatch":0,"latestOffset":1,"addBatch":636,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":38}}","endOffset":"{\"12003800_test\":{\"0\":39}}","latestOffset":"{\"12003800_test\":{\"0\":39}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.4064697609001406,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520289996,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520290578,"Failed":false,"Killed":false,"Accumulables":[{"ID":181,"Name":"duration","Update":"544","Value":"544","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":182,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":214,"Name":"duration","Update":"544","Value":"544","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":215,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":216,"Name":"internal.metrics.executorDeserializeTime","Update":19,"Value":19,"Internal":true,"Count Failed Values":true},{"ID":217,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10661320,"Value":10661320,"Internal":true,"Count Failed Values":true},{"ID":218,"Name":"internal.metrics.executorRunTime","Update":552,"Value":552,"Internal":true,"Count Failed Values":true},{"ID":219,"Name":"internal.metrics.executorCpuTime","Update":27472723,"Value":27472723,"Internal":true,"Count Failed Values":true},{"ID":220,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":238,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":19,"Executor Deserialize CPU Time":10661320,"Executor Run Time":552,"Executor CPU Time":27472723,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"DataSourceRDD","Scope":"{\"id\":\"57\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"57\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520289987,"Completion Time":1668520290579,"Accumulables":[{"ID":181,"Name":"duration","Value":"544","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":182,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":214,"Name":"duration","Value":"544","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":215,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":216,"Name":"internal.metrics.executorDeserializeTime","Value":19,"Internal":true,"Count Failed Values":true},{"ID":217,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10661320,"Internal":true,"Count Failed Values":true},{"ID":218,"Name":"internal.metrics.executorRunTime","Value":552,"Internal":true,"Count Failed Values":true},{"ID":219,"Name":"internal.metrics.executorCpuTime","Value":27472723,"Internal":true,"Count Failed Values":true},{"ID":220,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":238,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1668520290581,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":15,"time":1668520290581}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":12,"time":1668520290582}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:29.821Z","batchId":3,"batchDuration":790,"durationMs":{"triggerExecution":790,"queryPlanning":12,"getBatch":0,"latestOffset":1,"addBatch":714,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":38}}","endOffset":"{\"12003800_test\":{\"0\":39}}","latestOffset":"{\"12003800_test\":{\"0\":39}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.2658227848101264,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":16,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 37","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6f5d31b3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@7fdf20dd\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@58f83213, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@28a05bf4","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":242,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":243,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":244,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":241,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520299887,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":17,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":246,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":247,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":248,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":245,"metricType":"timing"}]},"time":1668520299895,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":18,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 37","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@45b5bc5, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@658a4054\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@58f83213, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@28a05bf4","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":242,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":243,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":244,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":241,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520299897,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1668520299906,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"DataSourceRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[8],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 37","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"37","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"18","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"DataSourceRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520299907,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 37","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"37","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"18","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520299917,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":19,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#149, value#150, timestamp#151]\nArguments: [topic#149, value#150, timestamp#151], SQLExecutionRDD[36] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#149, value#150, timestamp#151]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@36244035, org.apache.spark.sql.connector.write.WriteBuilder$1@3c8e06b9\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@36244035, org.apache.spark.sql.connector.write.WriteBuilder$1@3c8e06b9","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#149,value#150,timestamp#151]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":275,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":274,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520299977,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1668520299983,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"DataSourceRDD","Scope":"{\"id\":\"75\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"72\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"75\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[32],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[9],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"19","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"DataSourceRDD","Scope":"{\"id\":\"75\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"72\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"75\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[32],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520299984,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"19","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520299992,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520299917,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520300493,"Failed":false,"Killed":false,"Accumulables":[{"ID":241,"Name":"duration","Update":"542","Value":"542","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":242,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":249,"Name":"internal.metrics.executorDeserializeTime","Update":21,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":250,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9333561,"Value":9333561,"Internal":true,"Count Failed Values":true},{"ID":251,"Name":"internal.metrics.executorRunTime","Update":547,"Value":547,"Internal":true,"Count Failed Values":true},{"ID":252,"Name":"internal.metrics.executorCpuTime","Update":40959167,"Value":40959167,"Internal":true,"Count Failed Values":true},{"ID":253,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":271,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":21,"Executor Deserialize CPU Time":9333561,"Executor Run Time":547,"Executor CPU Time":40959167,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"DataSourceRDD","Scope":"{\"id\":\"79\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520299907,"Completion Time":1668520300495,"Accumulables":[{"ID":241,"Name":"duration","Value":"542","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":242,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":249,"Name":"internal.metrics.executorDeserializeTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":250,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9333561,"Internal":true,"Count Failed Values":true},{"ID":251,"Name":"internal.metrics.executorRunTime","Value":547,"Internal":true,"Count Failed Values":true},{"ID":252,"Name":"internal.metrics.executorCpuTime","Value":40959167,"Internal":true,"Count Failed Values":true},{"ID":253,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":271,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1668520300495,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":18,"time":1668520300496}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":16,"time":1668520300496}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:39.828Z","batchId":37,"batchDuration":694,"durationMs":{"triggerExecution":694,"queryPlanning":16,"getBatch":0,"latestOffset":1,"addBatch":620,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":39}}","endOffset":"{\"12003800_test\":{\"0\":40}}","latestOffset":"{\"12003800_test\":{\"0\":40}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.4409221902017293,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520299992,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520300576,"Failed":false,"Killed":false,"Accumulables":[{"ID":245,"Name":"duration","Update":"539","Value":"539","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":246,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":274,"Name":"duration","Update":"539","Value":"539","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":275,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":276,"Name":"internal.metrics.executorDeserializeTime","Update":19,"Value":19,"Internal":true,"Count Failed Values":true},{"ID":277,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10248938,"Value":10248938,"Internal":true,"Count Failed Values":true},{"ID":278,"Name":"internal.metrics.executorRunTime","Update":556,"Value":556,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"internal.metrics.executorCpuTime","Update":23032808,"Value":23032808,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":298,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":19,"Executor Deserialize CPU Time":10248938,"Executor Run Time":556,"Executor CPU Time":23032808,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"DataSourceRDD","Scope":"{\"id\":\"75\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"72\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"75\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[32],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520299984,"Completion Time":1668520300577,"Accumulables":[{"ID":245,"Name":"duration","Value":"539","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":246,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":274,"Name":"duration","Value":"539","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":275,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":276,"Name":"internal.metrics.executorDeserializeTime","Value":19,"Internal":true,"Count Failed Values":true},{"ID":277,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10248938,"Internal":true,"Count Failed Values":true},{"ID":278,"Name":"internal.metrics.executorRunTime","Value":556,"Internal":true,"Count Failed Values":true},{"ID":279,"Name":"internal.metrics.executorCpuTime","Value":23032808,"Internal":true,"Count Failed Values":true},{"ID":280,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":298,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1668520300577,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":19,"time":1668520300577}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":17,"time":1668520300578}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:39.833Z","batchId":4,"batchDuration":769,"durationMs":{"triggerExecution":769,"queryPlanning":15,"getBatch":0,"latestOffset":2,"addBatch":696,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":39}}","endOffset":"{\"12003800_test\":{\"0\":40}}","latestOffset":"{\"12003800_test\":{\"0\":40}}","numInputRows":1,"inputRowsPerSecond":83.33333333333333,"processedRowsPerSecond":1.3003901170351104,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":20,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":302,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":304,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":305,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":301,"metricType":"timing"}]},"time":1668520309904,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":21,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 38","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@aa2c93d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@61279fe0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@450ddf89, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@37ce9d26","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":306,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":307,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":308,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":303,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520309904,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":22,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 38","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7fd4976f, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@69e07105\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@450ddf89, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@37ce9d26","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":306,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":307,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":308,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":303,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520309915,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1668520309934,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[10],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 38","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"38","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"22","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520309941,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 38","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"38","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"22","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520309954,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":23,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#170, value#171, timestamp#172]\nArguments: [topic#170, value#171, timestamp#172], SQLExecutionRDD[43] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#170, value#171, timestamp#172]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@2c422010, org.apache.spark.sql.connector.write.WriteBuilder$1@2f47dbf5\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@2c422010, org.apache.spark.sql.connector.write.WriteBuilder$1@2f47dbf5","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#170,value#171,timestamp#172]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":335,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":334,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520309989,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1668520309998,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"98\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"93\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[11],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"23","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"98\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"93\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520310002,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"23","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520310013,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520309954,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520310520,"Failed":false,"Killed":false,"Accumulables":[{"ID":303,"Name":"duration","Update":"529","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":306,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":309,"Name":"internal.metrics.executorDeserializeTime","Update":21,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":310,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9715958,"Value":9715958,"Internal":true,"Count Failed Values":true},{"ID":311,"Name":"internal.metrics.executorRunTime","Update":533,"Value":533,"Internal":true,"Count Failed Values":true},{"ID":312,"Name":"internal.metrics.executorCpuTime","Update":24190851,"Value":24190851,"Internal":true,"Count Failed Values":true},{"ID":313,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":331,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":21,"Executor Deserialize CPU Time":9715958,"Executor Run Time":533,"Executor CPU Time":24190851,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520309941,"Completion Time":1668520310522,"Accumulables":[{"ID":303,"Name":"duration","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":306,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":309,"Name":"internal.metrics.executorDeserializeTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":310,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9715958,"Internal":true,"Count Failed Values":true},{"ID":311,"Name":"internal.metrics.executorRunTime","Value":533,"Internal":true,"Count Failed Values":true},{"ID":312,"Name":"internal.metrics.executorCpuTime","Value":24190851,"Internal":true,"Count Failed Values":true},{"ID":313,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":331,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1668520310522,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":22,"time":1668520310523}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":21,"time":1668520310523}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:49.829Z","batchId":38,"batchDuration":720,"durationMs":{"triggerExecution":720,"queryPlanning":14,"getBatch":0,"latestOffset":1,"addBatch":647,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":40}}","endOffset":"{\"12003800_test\":{\"0\":41}}","latestOffset":"{\"12003800_test\":{\"0\":41}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.3888888888888888,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520310013,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520310618,"Failed":false,"Killed":false,"Accumulables":[{"ID":301,"Name":"duration","Update":"569","Value":"569","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":302,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":334,"Name":"duration","Update":"569","Value":"569","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":335,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":336,"Name":"internal.metrics.executorDeserializeTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":337,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9925219,"Value":9925219,"Internal":true,"Count Failed Values":true},{"ID":338,"Name":"internal.metrics.executorRunTime","Update":577,"Value":577,"Internal":true,"Count Failed Values":true},{"ID":339,"Name":"internal.metrics.executorCpuTime","Update":25555825,"Value":25555825,"Internal":true,"Count Failed Values":true},{"ID":340,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":358,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":18,"Executor Deserialize CPU Time":9925219,"Executor Run Time":577,"Executor CPU Time":25555825,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"98\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"DataSourceRDD","Scope":"{\"id\":\"93\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"93\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520310002,"Completion Time":1668520310618,"Accumulables":[{"ID":301,"Name":"duration","Value":"569","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":302,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":334,"Name":"duration","Value":"569","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":335,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":336,"Name":"internal.metrics.executorDeserializeTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":337,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9925219,"Internal":true,"Count Failed Values":true},{"ID":338,"Name":"internal.metrics.executorRunTime","Value":577,"Internal":true,"Count Failed Values":true},{"ID":339,"Name":"internal.metrics.executorCpuTime","Value":25555825,"Internal":true,"Count Failed Values":true},{"ID":340,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":358,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1668520310619,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":23,"time":1668520310619}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":20,"time":1668520310620}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:49.829Z","batchId":5,"batchDuration":819,"durationMs":{"triggerExecution":819,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":748,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":40}}","endOffset":"{\"12003800_test\":{\"0\":41}}","latestOffset":"{\"12003800_test\":{\"0\":41}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.221001221001221,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":24,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 39","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@59af7dd4, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@601a9481\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3dd52510, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@1623ad83","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":362,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":363,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":364,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":361,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520319885,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":25,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":366,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":367,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":368,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":365,"metricType":"timing"}]},"time":1668520319888,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":26,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 39","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2a082d34, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@7a2c83e1\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3dd52510, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@1623ad83","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":362,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":363,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":364,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":361,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520319894,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1668520319904,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"112\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"115\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"DataSourceRDD","Scope":"{\"id\":\"115\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[12],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 39","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"39","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"26","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"112\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"115\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"DataSourceRDD","Scope":"{\"id\":\"115\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520319906,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 39","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"39","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"26","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520319916,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":27,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#192, value#193, timestamp#194]\nArguments: [topic#192, value#193, timestamp#194], SQLExecutionRDD[51] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#192, value#193, timestamp#194]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@29689eb0, org.apache.spark.sql.connector.write.WriteBuilder$1@f9b3c8a\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@29689eb0, org.apache.spark.sql.connector.write.WriteBuilder$1@f9b3c8a","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#192,value#193,timestamp#194]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":395,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":394,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520319947,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1668520319954,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"108\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"DataSourceRDD","Scope":"{\"id\":\"111\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"111\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[13],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"27","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"108\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"DataSourceRDD","Scope":"{\"id\":\"111\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"111\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520319956,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"27","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520319983,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520319916,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520320466,"Failed":false,"Killed":false,"Accumulables":[{"ID":361,"Name":"duration","Update":"519","Value":"519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":362,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":369,"Name":"internal.metrics.executorDeserializeTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":370,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9450398,"Value":9450398,"Internal":true,"Count Failed Values":true},{"ID":371,"Name":"internal.metrics.executorRunTime","Update":523,"Value":523,"Internal":true,"Count Failed Values":true},{"ID":372,"Name":"internal.metrics.executorCpuTime","Update":18838421,"Value":18838421,"Internal":true,"Count Failed Values":true},{"ID":373,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":391,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":18,"Executor Deserialize CPU Time":9450398,"Executor Run Time":523,"Executor CPU Time":18838421,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"112\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"115\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"DataSourceRDD","Scope":"{\"id\":\"115\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520319906,"Completion Time":1668520320466,"Accumulables":[{"ID":361,"Name":"duration","Value":"519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":362,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":369,"Name":"internal.metrics.executorDeserializeTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":370,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9450398,"Internal":true,"Count Failed Values":true},{"ID":371,"Name":"internal.metrics.executorRunTime","Value":523,"Internal":true,"Count Failed Values":true},{"ID":372,"Name":"internal.metrics.executorCpuTime","Value":18838421,"Internal":true,"Count Failed Values":true},{"ID":373,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":391,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1668520320467,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":26,"time":1668520320467}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":24,"time":1668520320467}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:51:59.835Z","batchId":39,"batchDuration":656,"durationMs":{"triggerExecution":656,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":594,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":41}}","endOffset":"{\"12003800_test\":{\"0\":42}}","latestOffset":"{\"12003800_test\":{\"0\":42}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.524390243902439,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520319983,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520320546,"Failed":false,"Killed":false,"Accumulables":[{"ID":365,"Name":"duration","Update":"534","Value":"534","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":366,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":394,"Name":"duration","Update":"534","Value":"534","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":395,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":396,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":397,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8304604,"Value":8304604,"Internal":true,"Count Failed Values":true},{"ID":398,"Name":"internal.metrics.executorRunTime","Update":541,"Value":541,"Internal":true,"Count Failed Values":true},{"ID":399,"Name":"internal.metrics.executorCpuTime","Update":22873418,"Value":22873418,"Internal":true,"Count Failed Values":true},{"ID":400,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":418,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":8304604,"Executor Run Time":541,"Executor CPU Time":22873418,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"108\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"DataSourceRDD","Scope":"{\"id\":\"111\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"111\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520319956,"Completion Time":1668520320547,"Accumulables":[{"ID":365,"Name":"duration","Value":"534","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":366,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":394,"Name":"duration","Value":"534","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":395,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":396,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":397,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8304604,"Internal":true,"Count Failed Values":true},{"ID":398,"Name":"internal.metrics.executorRunTime","Value":541,"Internal":true,"Count Failed Values":true},{"ID":399,"Name":"internal.metrics.executorCpuTime","Value":22873418,"Internal":true,"Count Failed Values":true},{"ID":400,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":418,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1668520320547,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":27,"time":1668520320547}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":25,"time":1668520320549}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:51:59.835Z","batchId":6,"batchDuration":741,"durationMs":{"triggerExecution":741,"queryPlanning":10,"getBatch":1,"latestOffset":1,"addBatch":671,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":41}}","endOffset":"{\"12003800_test\":{\"0\":42}}","latestOffset":"{\"12003800_test\":{\"0\":42}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.349527665317139,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":28,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 40","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@23289bd6, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@34f3cc59\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@648cb67a, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5fe73e63","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":422,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":423,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":424,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":421,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520329897,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":29,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":426,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":427,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":428,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":425,"metricType":"timing"}]},"time":1668520329902,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":30,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 40","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7a3bd275, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@35e2371\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@648cb67a, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5fe73e63","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":422,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":423,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":424,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":421,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520329909,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1668520329922,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"DataSourceRDD","Scope":"{\"id\":\"133\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[14],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 40","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"40","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"30","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"DataSourceRDD","Scope":"{\"id\":\"133\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520329924,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 40","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"40","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"30","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520329935,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":31,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#215, value#216, timestamp#217]\nArguments: [topic#215, value#216, timestamp#217], SQLExecutionRDD[59] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#215, value#216, timestamp#217]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@78bf41b0, org.apache.spark.sql.connector.write.WriteBuilder$1@25a536af\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@78bf41b0, org.apache.spark.sql.connector.write.WriteBuilder$1@25a536af","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#215,value#216,timestamp#217]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":455,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":454,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520329986,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1668520329992,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[59],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":59,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"DataSourceRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[15],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"31","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[59],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":59,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"DataSourceRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520329993,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"31","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520330002,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520329935,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520330496,"Failed":false,"Killed":false,"Accumulables":[{"ID":421,"Name":"duration","Update":"522","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":422,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":429,"Name":"internal.metrics.executorDeserializeTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":430,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9211884,"Value":9211884,"Internal":true,"Count Failed Values":true},{"ID":431,"Name":"internal.metrics.executorRunTime","Update":527,"Value":527,"Internal":true,"Count Failed Values":true},{"ID":432,"Name":"internal.metrics.executorCpuTime","Update":21654470,"Value":21654470,"Internal":true,"Count Failed Values":true},{"ID":433,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":451,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":25,"Executor Deserialize CPU Time":9211884,"Executor Run Time":527,"Executor CPU Time":21654470,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"130\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"133\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"DataSourceRDD","Scope":"{\"id\":\"133\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520329924,"Completion Time":1668520330497,"Accumulables":[{"ID":421,"Name":"duration","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":422,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":429,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":430,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9211884,"Internal":true,"Count Failed Values":true},{"ID":431,"Name":"internal.metrics.executorRunTime","Value":527,"Internal":true,"Count Failed Values":true},{"ID":432,"Name":"internal.metrics.executorCpuTime","Value":21654470,"Internal":true,"Count Failed Values":true},{"ID":433,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":451,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1668520330498,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":30,"time":1668520330498}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":28,"time":1668520330499}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:52:09.835Z","batchId":40,"batchDuration":694,"durationMs":{"triggerExecution":694,"queryPlanning":15,"getBatch":0,"latestOffset":0,"addBatch":615,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":42}}","endOffset":"{\"12003800_test\":{\"0\":43}}","latestOffset":"{\"12003800_test\":{\"0\":43}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.4409221902017293,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520330002,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520330576,"Failed":false,"Killed":false,"Accumulables":[{"ID":425,"Name":"duration","Update":"535","Value":"535","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":426,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":454,"Name":"duration","Update":"535","Value":"535","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":455,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":456,"Name":"internal.metrics.executorDeserializeTime","Update":23,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":457,"Name":"internal.metrics.executorDeserializeCpuTime","Update":13057922,"Value":13057922,"Internal":true,"Count Failed Values":true},{"ID":458,"Name":"internal.metrics.executorRunTime","Update":543,"Value":543,"Internal":true,"Count Failed Values":true},{"ID":459,"Name":"internal.metrics.executorCpuTime","Update":22489940,"Value":22489940,"Internal":true,"Count Failed Values":true},{"ID":460,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":478,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":23,"Executor Deserialize CPU Time":13057922,"Executor Run Time":543,"Executor CPU Time":22489940,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"134\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[59],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":59,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"DataSourceRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520329993,"Completion Time":1668520330577,"Accumulables":[{"ID":425,"Name":"duration","Value":"535","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":426,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":454,"Name":"duration","Value":"535","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":455,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":456,"Name":"internal.metrics.executorDeserializeTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":457,"Name":"internal.metrics.executorDeserializeCpuTime","Value":13057922,"Internal":true,"Count Failed Values":true},{"ID":458,"Name":"internal.metrics.executorRunTime","Value":543,"Internal":true,"Count Failed Values":true},{"ID":459,"Name":"internal.metrics.executorCpuTime","Value":22489940,"Internal":true,"Count Failed Values":true},{"ID":460,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":478,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1668520330577,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":31,"time":1668520330578}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":29,"time":1668520330578}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:52:09.835Z","batchId":7,"batchDuration":770,"durationMs":{"triggerExecution":770,"queryPlanning":14,"getBatch":0,"latestOffset":1,"addBatch":692,"walCommit":34},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":42}}","endOffset":"{\"12003800_test\":{\"0\":43}}","latestOffset":"{\"12003800_test\":{\"0\":43}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.2987012987012987,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":33,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":482,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":483,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":484,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":481,"metricType":"timing"}]},"time":1668520339891,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":32,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 41","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5648ce42, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5188c193\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5ebcfa32, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@3c6f2c15","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":486,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":487,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":488,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":485,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520339892,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":34,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 41","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@45f756b7, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@4e1095e8\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5ebcfa32, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@3c6f2c15","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":486,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":487,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":488,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":485,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520339904,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1668520339926,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"148\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"151\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"DataSourceRDD","Scope":"{\"id\":\"151\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[16],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 41","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"41","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"34","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"148\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"151\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"DataSourceRDD","Scope":"{\"id\":\"151\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520339927,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 41","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"41","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"34","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520339936,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":35,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#236, value#237, timestamp#238]\nArguments: [topic#236, value#237, timestamp#238], SQLExecutionRDD[67] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#236, value#237, timestamp#238]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@1b04972f, org.apache.spark.sql.connector.write.WriteBuilder$1@7d91594c\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@1b04972f, org.apache.spark.sql.connector.write.WriteBuilder$1@7d91594c","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#236,value#237,timestamp#238]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":515,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":514,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520339954,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1668520339959,"Stage Infos":[{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"152\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"147\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"147\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[17],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"35","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"152\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"147\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"147\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520339960,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"35","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520339988,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520339936,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520340500,"Failed":false,"Killed":false,"Accumulables":[{"ID":485,"Name":"duration","Update":"534","Value":"534","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":486,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":489,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":490,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9302503,"Value":9302503,"Internal":true,"Count Failed Values":true},{"ID":491,"Name":"internal.metrics.executorRunTime","Update":538,"Value":538,"Internal":true,"Count Failed Values":true},{"ID":492,"Name":"internal.metrics.executorCpuTime","Update":19133527,"Value":19133527,"Internal":true,"Count Failed Values":true},{"ID":493,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":511,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":9302503,"Executor Run Time":538,"Executor CPU Time":19133527,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":70,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"148\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"151\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"DataSourceRDD","Scope":"{\"id\":\"151\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520339927,"Completion Time":1668520340503,"Accumulables":[{"ID":485,"Name":"duration","Value":"534","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":486,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":489,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":490,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9302503,"Internal":true,"Count Failed Values":true},{"ID":491,"Name":"internal.metrics.executorRunTime","Value":538,"Internal":true,"Count Failed Values":true},{"ID":492,"Name":"internal.metrics.executorCpuTime","Value":19133527,"Internal":true,"Count Failed Values":true},{"ID":493,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":511,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1668520340504,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":34,"time":1668520340505}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":32,"time":1668520340505}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:52:19.838Z","batchId":41,"batchDuration":693,"durationMs":{"triggerExecution":693,"queryPlanning":13,"getBatch":0,"latestOffset":1,"addBatch":624,"walCommit":28},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":43}}","endOffset":"{\"12003800_test\":{\"0\":44}}","latestOffset":"{\"12003800_test\":{\"0\":44}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.443001443001443,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520339988,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520340545,"Failed":false,"Killed":false,"Accumulables":[{"ID":481,"Name":"duration","Update":"528","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":482,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":514,"Name":"duration","Update":"528","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":515,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":516,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":517,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7419232,"Value":7419232,"Internal":true,"Count Failed Values":true},{"ID":518,"Name":"internal.metrics.executorRunTime","Update":537,"Value":537,"Internal":true,"Count Failed Values":true},{"ID":519,"Name":"internal.metrics.executorCpuTime","Update":18564799,"Value":18564799,"Internal":true,"Count Failed Values":true},{"ID":520,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":538,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7419232,"Executor Run Time":537,"Executor CPU Time":18564799,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"152\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"147\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"147\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520339960,"Completion Time":1668520340546,"Accumulables":[{"ID":481,"Name":"duration","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":482,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":514,"Name":"duration","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":515,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":516,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":517,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7419232,"Internal":true,"Count Failed Values":true},{"ID":518,"Name":"internal.metrics.executorRunTime","Value":537,"Internal":true,"Count Failed Values":true},{"ID":519,"Name":"internal.metrics.executorCpuTime","Value":18564799,"Internal":true,"Count Failed Values":true},{"ID":520,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":538,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1668520340547,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":35,"time":1668520340547}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":33,"time":1668520340547}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:52:19.838Z","batchId":8,"batchDuration":741,"durationMs":{"triggerExecution":741,"queryPlanning":11,"getBatch":0,"latestOffset":1,"addBatch":666,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":43}}","endOffset":"{\"12003800_test\":{\"0\":44}}","latestOffset":"{\"12003800_test\":{\"0\":44}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.349527665317139,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":36,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 42","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@16e106f, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@7877d7ab\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5e624f71, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6d73ae93","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":542,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":543,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":544,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":541,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520349890,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":37,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":546,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":547,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":548,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":545,"metricType":"timing"}]},"time":1668520349896,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":38,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 42","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3fa221e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@425c3d1a\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5e624f71, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6d73ae93","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":542,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":543,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":544,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":541,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520349900,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1668520349909,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"166\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"DataSourceRDD","Scope":"{\"id\":\"169\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[18],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 42","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"42","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"38","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"166\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"DataSourceRDD","Scope":"{\"id\":\"169\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520349909,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 42","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"42","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"38","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520349916,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":39,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#259, value#260, timestamp#261]\nArguments: [topic#259, value#260, timestamp#261], SQLExecutionRDD[75] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#259, value#260, timestamp#261]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@3369139d, org.apache.spark.sql.connector.write.WriteBuilder$1@168b9f47\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@3369139d, org.apache.spark.sql.connector.write.WriteBuilder$1@168b9f47","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#259,value#260,timestamp#261]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":575,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":574,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520349975,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1668520349979,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"170\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"DataSourceRDD","Scope":"{\"id\":\"165\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"165\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[19],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"39","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"170\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"DataSourceRDD","Scope":"{\"id\":\"165\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"165\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520349980,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"39","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520349992,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520349916,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520350473,"Failed":false,"Killed":false,"Accumulables":[{"ID":541,"Name":"duration","Update":"524","Value":"524","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":542,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":549,"Name":"internal.metrics.executorDeserializeTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":550,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9079152,"Value":9079152,"Internal":true,"Count Failed Values":true},{"ID":551,"Name":"internal.metrics.executorRunTime","Update":528,"Value":528,"Internal":true,"Count Failed Values":true},{"ID":552,"Name":"internal.metrics.executorCpuTime","Update":22319179,"Value":22319179,"Internal":true,"Count Failed Values":true},{"ID":553,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":571,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":20,"Executor Deserialize CPU Time":9079152,"Executor Run Time":528,"Executor CPU Time":22319179,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":78,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"166\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"DataSourceRDD","Scope":"{\"id\":\"169\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520349909,"Completion Time":1668520350475,"Accumulables":[{"ID":541,"Name":"duration","Value":"524","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":542,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":549,"Name":"internal.metrics.executorDeserializeTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":550,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9079152,"Internal":true,"Count Failed Values":true},{"ID":551,"Name":"internal.metrics.executorRunTime","Value":528,"Internal":true,"Count Failed Values":true},{"ID":552,"Name":"internal.metrics.executorCpuTime","Value":22319179,"Internal":true,"Count Failed Values":true},{"ID":553,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":571,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1668520350476,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":38,"time":1668520350477}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":36,"time":1668520350477}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:52:29.843Z","batchId":42,"batchDuration":665,"durationMs":{"triggerExecution":665,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":596,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":44}}","endOffset":"{\"12003800_test\":{\"0\":45}}","latestOffset":"{\"12003800_test\":{\"0\":45}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.5037593984962405,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520349992,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520350561,"Failed":false,"Killed":false,"Accumulables":[{"ID":545,"Name":"duration","Update":"533","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":546,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":574,"Name":"duration","Update":"533","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":575,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":576,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":577,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9418508,"Value":9418508,"Internal":true,"Count Failed Values":true},{"ID":578,"Name":"internal.metrics.executorRunTime","Update":543,"Value":543,"Internal":true,"Count Failed Values":true},{"ID":579,"Name":"internal.metrics.executorCpuTime","Update":22324901,"Value":22324901,"Internal":true,"Count Failed Values":true},{"ID":580,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":598,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":9418508,"Executor Run Time":543,"Executor CPU Time":22324901,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"170\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"162\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"DataSourceRDD","Scope":"{\"id\":\"165\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[74],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"165\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520349980,"Completion Time":1668520350561,"Accumulables":[{"ID":545,"Name":"duration","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":546,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":574,"Name":"duration","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":575,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":576,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":577,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9418508,"Internal":true,"Count Failed Values":true},{"ID":578,"Name":"internal.metrics.executorRunTime","Value":543,"Internal":true,"Count Failed Values":true},{"ID":579,"Name":"internal.metrics.executorCpuTime","Value":22324901,"Internal":true,"Count Failed Values":true},{"ID":580,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":598,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1668520350562,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":39,"time":1668520350562}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":37,"time":1668520350563}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:52:29.843Z","batchId":9,"batchDuration":750,"durationMs":{"triggerExecution":750,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":680,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":44}}","endOffset":"{\"12003800_test\":{\"0\":45}}","latestOffset":"{\"12003800_test\":{\"0\":45}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.3333333333333333,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":40,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 43","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@44af6c66, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@2bc9bf1\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6e4ce55d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@12946804","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":602,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":603,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":604,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":601,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520359928,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":42,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 43","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@61ced988, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@3e0a410c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6e4ce55d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@12946804","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":602,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":603,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":604,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":601,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520359937,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":41,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":606,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":607,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":608,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":605,"metricType":"timing"}]},"time":1668520359937,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1668520359951,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"183\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"DataSourceRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[20],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 43","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"43","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"42","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"183\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"DataSourceRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520359958,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 43","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"43","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"42","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520359963,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":43,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#281, value#282, timestamp#283]\nArguments: [topic#281, value#282, timestamp#283], SQLExecutionRDD[85] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#281, value#282, timestamp#283]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@2d5af6, org.apache.spark.sql.connector.write.WriteBuilder$1@50fb4119\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@2d5af6, org.apache.spark.sql.connector.write.WriteBuilder$1@50fb4119","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#281,value#282,timestamp#283]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":635,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":634,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520360007,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1668520360014,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"186\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"186\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[21],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"43","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"186\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"186\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520360015,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"43","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520360025,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520359963,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520360514,"Failed":false,"Killed":false,"Accumulables":[{"ID":601,"Name":"duration","Update":"521","Value":"521","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":602,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":609,"Name":"internal.metrics.executorDeserializeTime","Update":21,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":610,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7721297,"Value":7721297,"Internal":true,"Count Failed Values":true},{"ID":611,"Name":"internal.metrics.executorRunTime","Update":524,"Value":524,"Internal":true,"Count Failed Values":true},{"ID":612,"Name":"internal.metrics.executorCpuTime","Update":18284751,"Value":18284751,"Internal":true,"Count Failed Values":true},{"ID":613,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":631,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":21,"Executor Deserialize CPU Time":7721297,"Executor Run Time":524,"Executor CPU Time":18284751,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":86,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"183\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"DataSourceRDD","Scope":"{\"id\":\"187\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520359958,"Completion Time":1668520360516,"Accumulables":[{"ID":601,"Name":"duration","Value":"521","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":602,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":609,"Name":"internal.metrics.executorDeserializeTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":610,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7721297,"Internal":true,"Count Failed Values":true},{"ID":611,"Name":"internal.metrics.executorRunTime","Value":524,"Internal":true,"Count Failed Values":true},{"ID":612,"Name":"internal.metrics.executorCpuTime","Value":18284751,"Internal":true,"Count Failed Values":true},{"ID":613,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":631,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1668520360517,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":42,"time":1668520360517}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":40,"time":1668520360517}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:52:39.852Z","batchId":43,"batchDuration":697,"durationMs":{"triggerExecution":697,"queryPlanning":33,"getBatch":0,"latestOffset":1,"addBatch":601,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":45}}","endOffset":"{\"12003800_test\":{\"0\":46}}","latestOffset":"{\"12003800_test\":{\"0\":46}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.4347202295552368,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520360025,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520360587,"Failed":false,"Killed":false,"Accumulables":[{"ID":605,"Name":"duration","Update":"532","Value":"532","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":606,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":634,"Name":"duration","Update":"532","Value":"532","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":635,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":636,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":637,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8642644,"Value":8642644,"Internal":true,"Count Failed Values":true},{"ID":638,"Name":"internal.metrics.executorRunTime","Update":540,"Value":540,"Internal":true,"Count Failed Values":true},{"ID":639,"Name":"internal.metrics.executorCpuTime","Update":20161996,"Value":20161996,"Internal":true,"Count Failed Values":true},{"ID":640,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":658,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8642644,"Executor Run Time":540,"Executor CPU Time":20161996,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[85],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":85,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"180\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[82],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"186\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"186\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520360015,"Completion Time":1668520360588,"Accumulables":[{"ID":605,"Name":"duration","Value":"532","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":606,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":634,"Name":"duration","Value":"532","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":635,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":636,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":637,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8642644,"Internal":true,"Count Failed Values":true},{"ID":638,"Name":"internal.metrics.executorRunTime","Value":540,"Internal":true,"Count Failed Values":true},{"ID":639,"Name":"internal.metrics.executorCpuTime","Value":20161996,"Internal":true,"Count Failed Values":true},{"ID":640,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":658,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1668520360588,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":43,"time":1668520360588}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":41,"time":1668520360589}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:52:39.854Z","batchId":10,"batchDuration":765,"durationMs":{"triggerExecution":765,"queryPlanning":11,"getBatch":0,"latestOffset":0,"addBatch":664,"walCommit":52},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":45}}","endOffset":"{\"12003800_test\":{\"0\":46}}","latestOffset":"{\"12003800_test\":{\"0\":46}}","numInputRows":1,"inputRowsPerSecond":83.33333333333333,"processedRowsPerSecond":1.3071895424836601,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":44,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 44","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@48add0c0, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@77c5b1ac\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3bf145aa, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@70cb20ef","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":662,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":663,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":664,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":661,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520369898,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":45,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":666,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":667,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":668,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":665,"metricType":"timing"}]},"time":1668520369905,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":46,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 44","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@74d583ee, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5a9db5e9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3bf145aa, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@70cb20ef","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":662,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":663,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":664,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":661,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520369911,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":22,"Submission Time":1668520369924,"Stage Infos":[{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"202\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":92,"Name":"DataSourceRDD","Scope":"{\"id\":\"205\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[92],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[22],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 44","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"44","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"46","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"202\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":92,"Name":"DataSourceRDD","Scope":"{\"id\":\"205\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[92],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520369926,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 44","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"44","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"46","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":22,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520369942,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":47,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#302, value#303, timestamp#304]\nArguments: [topic#302, value#303, timestamp#304], SQLExecutionRDD[91] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#302, value#303, timestamp#304]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@13b1f8c6, org.apache.spark.sql.connector.write.WriteBuilder$1@35cf30cd\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@13b1f8c6, org.apache.spark.sql.connector.write.WriteBuilder$1@35cf30cd","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#302,value#303,timestamp#304]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":695,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":694,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520369978,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":23,"Submission Time":1668520369983,"Stage Infos":[{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"206\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"198\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"DataSourceRDD","Scope":"{\"id\":\"201\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"201\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[23],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"47","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"206\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"198\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"DataSourceRDD","Scope":"{\"id\":\"201\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"201\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520369984,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"47","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":23,"Stage Attempt ID":0,"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520369992,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":22,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520369942,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520370489,"Failed":false,"Killed":false,"Accumulables":[{"ID":661,"Name":"duration","Update":"516","Value":"516","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":662,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":669,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":670,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10320410,"Value":10320410,"Internal":true,"Count Failed Values":true},{"ID":671,"Name":"internal.metrics.executorRunTime","Update":519,"Value":519,"Internal":true,"Count Failed Values":true},{"ID":672,"Name":"internal.metrics.executorCpuTime","Update":15838377,"Value":15838377,"Internal":true,"Count Failed Values":true},{"ID":673,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":691,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":10320410,"Executor Run Time":519,"Executor CPU Time":15838377,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":94,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"202\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[93],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":92,"Name":"DataSourceRDD","Scope":"{\"id\":\"205\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":93,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"205\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[92],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520369926,"Completion Time":1668520370491,"Accumulables":[{"ID":661,"Name":"duration","Value":"516","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":662,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":669,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":670,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10320410,"Internal":true,"Count Failed Values":true},{"ID":671,"Name":"internal.metrics.executorRunTime","Value":519,"Internal":true,"Count Failed Values":true},{"ID":672,"Name":"internal.metrics.executorCpuTime","Value":15838377,"Internal":true,"Count Failed Values":true},{"ID":673,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":691,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":22,"Completion Time":1668520370491,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":46,"time":1668520370491}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":44,"time":1668520370492}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:52:49.847Z","batchId":44,"batchDuration":673,"durationMs":{"triggerExecution":673,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":602,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":46}}","endOffset":"{\"12003800_test\":{\"0\":47}}","latestOffset":"{\"12003800_test\":{\"0\":47}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.4858841010401187,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":23,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520369992,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520370553,"Failed":false,"Killed":false,"Accumulables":[{"ID":665,"Name":"duration","Update":"529","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":666,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":694,"Name":"duration","Update":"529","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":695,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":696,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":697,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8549650,"Value":8549650,"Internal":true,"Count Failed Values":true},{"ID":698,"Name":"internal.metrics.executorRunTime","Update":538,"Value":538,"Internal":true,"Count Failed Values":true},{"ID":699,"Name":"internal.metrics.executorCpuTime","Update":20168003,"Value":20168003,"Internal":true,"Count Failed Values":true},{"ID":700,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":718,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":8549650,"Executor Run Time":538,"Executor CPU Time":20168003,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":95,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"206\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[91],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"198\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":91,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[90],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"DataSourceRDD","Scope":"{\"id\":\"201\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"201\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520369984,"Completion Time":1668520370553,"Accumulables":[{"ID":665,"Name":"duration","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":666,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":694,"Name":"duration","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":695,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":696,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":697,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8549650,"Internal":true,"Count Failed Values":true},{"ID":698,"Name":"internal.metrics.executorRunTime","Value":538,"Internal":true,"Count Failed Values":true},{"ID":699,"Name":"internal.metrics.executorCpuTime","Value":20168003,"Internal":true,"Count Failed Values":true},{"ID":700,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":718,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":23,"Completion Time":1668520370553,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":47,"time":1668520370554}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":45,"time":1668520370554}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:52:49.847Z","batchId":11,"batchDuration":736,"durationMs":{"triggerExecution":736,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":663,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":46}}","endOffset":"{\"12003800_test\":{\"0\":47}}","latestOffset":"{\"12003800_test\":{\"0\":47}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.358695652173913,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":48,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 45","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@74936460, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6139a104\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@25649ac9, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@2c2bc690","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":722,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":723,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":724,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":721,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520379895,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":49,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":726,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":727,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":728,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":725,"metricType":"timing"}]},"time":1668520379901,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":50,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 45","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7f98c619, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5dac307f\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@25649ac9, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@2c2bc690","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":722,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":723,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":724,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":721,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520379902,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":24,"Submission Time":1668520379912,"Stage Infos":[{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"220\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"223\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[100],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":100,"Name":"DataSourceRDD","Scope":"{\"id\":\"223\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[24],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 45","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"45","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"50","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"220\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"223\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[100],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":100,"Name":"DataSourceRDD","Scope":"{\"id\":\"223\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520379912,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 45","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"45","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"50","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":24,"Stage Attempt ID":0,"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520379918,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":51,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#325, value#326, timestamp#327]\nArguments: [topic#325, value#326, timestamp#327], SQLExecutionRDD[99] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#325, value#326, timestamp#327]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@4e11d41b, org.apache.spark.sql.connector.write.WriteBuilder$1@ec01d1d\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@4e11d41b, org.apache.spark.sql.connector.write.WriteBuilder$1@ec01d1d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#325,value#326,timestamp#327]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":755,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":754,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520379964,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":25,"Submission Time":1668520379968,"Stage Infos":[{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"224\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"216\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"219\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"DataSourceRDD","Scope":"{\"id\":\"219\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[25],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"51","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"224\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"216\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"219\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"DataSourceRDD","Scope":"{\"id\":\"219\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520379969,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"51","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":25,"Stage Attempt ID":0,"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520379975,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":24,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520379918,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520380466,"Failed":false,"Killed":false,"Accumulables":[{"ID":721,"Name":"duration","Update":"522","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":722,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":729,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":730,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8242476,"Value":8242476,"Internal":true,"Count Failed Values":true},{"ID":731,"Name":"internal.metrics.executorRunTime","Update":525,"Value":525,"Internal":true,"Count Failed Values":true},{"ID":732,"Name":"internal.metrics.executorCpuTime","Update":19067790,"Value":19067790,"Internal":true,"Count Failed Values":true},{"ID":733,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":751,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":8242476,"Executor Run Time":525,"Executor CPU Time":19067790,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":102,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"220\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[101],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":101,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"223\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[100],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":100,"Name":"DataSourceRDD","Scope":"{\"id\":\"223\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520379912,"Completion Time":1668520380466,"Accumulables":[{"ID":721,"Name":"duration","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":722,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":729,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":730,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8242476,"Internal":true,"Count Failed Values":true},{"ID":731,"Name":"internal.metrics.executorRunTime","Value":525,"Internal":true,"Count Failed Values":true},{"ID":732,"Name":"internal.metrics.executorCpuTime","Value":19067790,"Internal":true,"Count Failed Values":true},{"ID":733,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":751,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":24,"Completion Time":1668520380466,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":50,"time":1668520380467}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":48,"time":1668520380468}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:52:59.852Z","batchId":45,"batchDuration":637,"durationMs":{"triggerExecution":637,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":581,"walCommit":25},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":47}}","endOffset":"{\"12003800_test\":{\"0\":48}}","latestOffset":"{\"12003800_test\":{\"0\":48}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.5698587127158556,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":25,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":25,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520379975,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520380532,"Failed":false,"Killed":false,"Accumulables":[{"ID":725,"Name":"duration","Update":"530","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":726,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":754,"Name":"duration","Update":"530","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":755,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":756,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":757,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8499816,"Value":8499816,"Internal":true,"Count Failed Values":true},{"ID":758,"Name":"internal.metrics.executorRunTime","Update":538,"Value":538,"Internal":true,"Count Failed Values":true},{"ID":759,"Name":"internal.metrics.executorCpuTime","Update":19568835,"Value":19568835,"Internal":true,"Count Failed Values":true},{"ID":760,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":778,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":8499816,"Executor Run Time":538,"Executor CPU Time":19568835,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":25,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":103,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"224\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[99],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":98,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"216\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[97],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":99,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[98],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":97,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"219\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[96],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":96,"Name":"DataSourceRDD","Scope":"{\"id\":\"219\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520379969,"Completion Time":1668520380533,"Accumulables":[{"ID":725,"Name":"duration","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":726,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":754,"Name":"duration","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":755,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":756,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":757,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8499816,"Internal":true,"Count Failed Values":true},{"ID":758,"Name":"internal.metrics.executorRunTime","Value":538,"Internal":true,"Count Failed Values":true},{"ID":759,"Name":"internal.metrics.executorCpuTime","Value":19568835,"Internal":true,"Count Failed Values":true},{"ID":760,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":778,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":25,"Completion Time":1668520380533,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":51,"time":1668520380533}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":49,"time":1668520380534}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:52:59.853Z","batchId":12,"batchDuration":703,"durationMs":{"triggerExecution":703,"queryPlanning":10,"getBatch":0,"latestOffset":0,"addBatch":643,"walCommit":24},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":47}}","endOffset":"{\"12003800_test\":{\"0\":48}}","latestOffset":"{\"12003800_test\":{\"0\":48}}","numInputRows":1,"inputRowsPerSecond":83.33333333333333,"processedRowsPerSecond":1.4224751066856332,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":52,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 46","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@32a26734, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@4463550e\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1d1122c8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@593e88d6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":782,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":783,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":784,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":781,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520389900,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":53,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 46","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4175a9d8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@6e3a3739\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1d1122c8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@593e88d6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":782,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":783,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":784,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":781,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520389906,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":54,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":786,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":787,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":788,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":785,"metricType":"timing"}]},"time":1668520389908,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":26,"Submission Time":1668520389914,"Stage Infos":[{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"234\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"240\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[104],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":104,"Name":"DataSourceRDD","Scope":"{\"id\":\"240\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[26],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 46","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"46","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"53","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"234\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"240\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[104],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":104,"Name":"DataSourceRDD","Scope":"{\"id\":\"240\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520389914,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 46","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"46","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"53","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":26,"Stage Attempt ID":0,"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520389921,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":55,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#347, value#348, timestamp#349]\nArguments: [topic#347, value#348, timestamp#349], SQLExecutionRDD[110] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#347, value#348, timestamp#349]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@3e2c746f, org.apache.spark.sql.connector.write.WriteBuilder$1@301d40a6\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@3e2c746f, org.apache.spark.sql.connector.write.WriteBuilder$1@301d40a6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#347,value#348,timestamp#349]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":815,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":814,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520389973,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":27,"Submission Time":1668520389977,"Stage Infos":[{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"242\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":105,"Name":"DataSourceRDD","Scope":"{\"id\":\"241\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[105],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[109],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":109,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"237\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[27],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"55","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"242\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":105,"Name":"DataSourceRDD","Scope":"{\"id\":\"241\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[105],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[109],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":109,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"237\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520389978,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"55","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":27,"Stage Attempt ID":0,"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520389985,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":26,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":26,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520389921,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520390462,"Failed":false,"Killed":false,"Accumulables":[{"ID":781,"Name":"duration","Update":"518","Value":"518","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":782,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":789,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":790,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7605249,"Value":7605249,"Internal":true,"Count Failed Values":true},{"ID":791,"Name":"internal.metrics.executorRunTime","Update":521,"Value":521,"Internal":true,"Count Failed Values":true},{"ID":792,"Name":"internal.metrics.executorCpuTime","Update":16771086,"Value":16771086,"Internal":true,"Count Failed Values":true},{"ID":793,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":811,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":7605249,"Executor Run Time":521,"Executor CPU Time":16771086,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":26,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":108,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"234\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[106],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":106,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"240\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[104],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":104,"Name":"DataSourceRDD","Scope":"{\"id\":\"240\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520389914,"Completion Time":1668520390463,"Accumulables":[{"ID":781,"Name":"duration","Value":"518","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":782,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":789,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":790,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7605249,"Internal":true,"Count Failed Values":true},{"ID":791,"Name":"internal.metrics.executorRunTime","Value":521,"Internal":true,"Count Failed Values":true},{"ID":792,"Name":"internal.metrics.executorCpuTime","Value":16771086,"Internal":true,"Count Failed Values":true},{"ID":793,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":811,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":26,"Completion Time":1668520390463,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":53,"time":1668520390463}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":52,"time":1668520390463}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:53:09.857Z","batchId":46,"batchDuration":628,"durationMs":{"triggerExecution":628,"queryPlanning":8,"getBatch":0,"latestOffset":0,"addBatch":571,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":48}}","endOffset":"{\"12003800_test\":{\"0\":49}}","latestOffset":"{\"12003800_test\":{\"0\":49}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.5923566878980893,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":27,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":27,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520389985,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520390539,"Failed":false,"Killed":false,"Accumulables":[{"ID":785,"Name":"duration","Update":"528","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":786,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":814,"Name":"duration","Update":"528","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":815,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":816,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":817,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7707642,"Value":7707642,"Internal":true,"Count Failed Values":true},{"ID":818,"Name":"internal.metrics.executorRunTime","Update":535,"Value":535,"Internal":true,"Count Failed Values":true},{"ID":819,"Name":"internal.metrics.executorCpuTime","Update":18087502,"Value":18087502,"Internal":true,"Count Failed Values":true},{"ID":820,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":838,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7707642,"Executor Run Time":535,"Executor CPU Time":18087502,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":27,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":111,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"242\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[110],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":105,"Name":"DataSourceRDD","Scope":"{\"id\":\"241\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":107,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"241\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[105],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":110,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[109],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":109,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"237\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[107],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520389978,"Completion Time":1668520390540,"Accumulables":[{"ID":785,"Name":"duration","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":786,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":814,"Name":"duration","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":815,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":816,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":817,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7707642,"Internal":true,"Count Failed Values":true},{"ID":818,"Name":"internal.metrics.executorRunTime","Value":535,"Internal":true,"Count Failed Values":true},{"ID":819,"Name":"internal.metrics.executorCpuTime","Value":18087502,"Internal":true,"Count Failed Values":true},{"ID":820,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":838,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":27,"Completion Time":1668520390540,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":55,"time":1668520390540}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":54,"time":1668520390541}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:53:09.860Z","batchId":13,"batchDuration":705,"durationMs":{"triggerExecution":705,"queryPlanning":11,"getBatch":0,"latestOffset":1,"addBatch":640,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":48}}","endOffset":"{\"12003800_test\":{\"0\":49}}","latestOffset":"{\"12003800_test\":{\"0\":49}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.4184397163120568,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":56,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 47","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5e61891d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@55ade213\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38ac1ffa, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@13724531","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":842,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":843,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":844,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":841,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520399917,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":57,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":846,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":847,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":848,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":845,"metricType":"timing"}]},"time":1668520399925,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":58,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 47","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2ba632cc, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@26a6a24b\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38ac1ffa, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@13724531","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":842,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":843,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":844,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":841,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520399928,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":28,"Submission Time":1668520399935,"Stage Infos":[{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"256\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"259\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[116],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":116,"Name":"DataSourceRDD","Scope":"{\"id\":\"259\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[28],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 47","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"47","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"58","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"256\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"259\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[116],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":116,"Name":"DataSourceRDD","Scope":"{\"id\":\"259\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520399936,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 47","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"47","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"58","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":28,"Stage Attempt ID":0,"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520399941,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":59,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#369, value#370, timestamp#371]\nArguments: [topic#369, value#370, timestamp#371], SQLExecutionRDD[115] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#369, value#370, timestamp#371]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@7eac3cce, org.apache.spark.sql.connector.write.WriteBuilder$1@4b648536\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@7eac3cce, org.apache.spark.sql.connector.write.WriteBuilder$1@4b648536","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#369,value#370,timestamp#371]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":875,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":874,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520399980,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":29,"Submission Time":1668520399985,"Stage Infos":[{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":119,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"260\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[115],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"DataSourceRDD","Scope":"{\"id\":\"255\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"252\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[113],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":113,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"255\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":115,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[29],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"59","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":119,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"260\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[115],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"DataSourceRDD","Scope":"{\"id\":\"255\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"252\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[113],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":113,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"255\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":115,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520399986,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"59","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":29,"Stage Attempt ID":0,"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520399995,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":28,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":28,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520399941,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520400487,"Failed":false,"Killed":false,"Accumulables":[{"ID":841,"Name":"duration","Update":"519","Value":"519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":842,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":849,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":850,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7382141,"Value":7382141,"Internal":true,"Count Failed Values":true},{"ID":851,"Name":"internal.metrics.executorRunTime","Update":523,"Value":523,"Internal":true,"Count Failed Values":true},{"ID":852,"Name":"internal.metrics.executorCpuTime","Update":18723426,"Value":18723426,"Internal":true,"Count Failed Values":true},{"ID":853,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":871,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":7382141,"Executor Run Time":523,"Executor CPU Time":18723426,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":28,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":118,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"256\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[117],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":117,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"259\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[116],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":116,"Name":"DataSourceRDD","Scope":"{\"id\":\"259\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520399936,"Completion Time":1668520400487,"Accumulables":[{"ID":841,"Name":"duration","Value":"519","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":842,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":849,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":850,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7382141,"Internal":true,"Count Failed Values":true},{"ID":851,"Name":"internal.metrics.executorRunTime","Value":523,"Internal":true,"Count Failed Values":true},{"ID":852,"Name":"internal.metrics.executorCpuTime","Value":18723426,"Internal":true,"Count Failed Values":true},{"ID":853,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":871,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":28,"Completion Time":1668520400487,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":58,"time":1668520400488}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":56,"time":1668520400488}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:53:19.867Z","batchId":47,"batchDuration":647,"durationMs":{"triggerExecution":647,"queryPlanning":7,"getBatch":0,"latestOffset":1,"addBatch":581,"walCommit":31},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":49}}","endOffset":"{\"12003800_test\":{\"0\":50}}","latestOffset":"{\"12003800_test\":{\"0\":50}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.5455950540958268,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":29,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":29,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520399995,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520400555,"Failed":false,"Killed":false,"Accumulables":[{"ID":845,"Name":"duration","Update":"531","Value":"531","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":846,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":874,"Name":"duration","Update":"531","Value":"531","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":875,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":876,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":877,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7888450,"Value":7888450,"Internal":true,"Count Failed Values":true},{"ID":878,"Name":"internal.metrics.executorRunTime","Update":539,"Value":539,"Internal":true,"Count Failed Values":true},{"ID":879,"Name":"internal.metrics.executorCpuTime","Update":18723807,"Value":18723807,"Internal":true,"Count Failed Values":true},{"ID":880,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":898,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":7888450,"Executor Run Time":539,"Executor CPU Time":18723807,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":29,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":119,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"260\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[115],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":112,"Name":"DataSourceRDD","Scope":"{\"id\":\"255\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":114,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"252\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[113],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":113,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"255\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[112],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":115,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[114],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520399986,"Completion Time":1668520400557,"Accumulables":[{"ID":845,"Name":"duration","Value":"531","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":846,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":874,"Name":"duration","Value":"531","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":875,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":876,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":877,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7888450,"Internal":true,"Count Failed Values":true},{"ID":878,"Name":"internal.metrics.executorRunTime","Value":539,"Internal":true,"Count Failed Values":true},{"ID":879,"Name":"internal.metrics.executorCpuTime","Value":18723807,"Internal":true,"Count Failed Values":true},{"ID":880,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":898,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":29,"Completion Time":1668520400558,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":59,"time":1668520400558}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":57,"time":1668520400559}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:53:19.867Z","batchId":14,"batchDuration":715,"durationMs":{"triggerExecution":715,"queryPlanning":15,"getBatch":0,"latestOffset":0,"addBatch":642,"walCommit":33},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":49}}","endOffset":"{\"12003800_test\":{\"0\":50}}","latestOffset":"{\"12003800_test\":{\"0\":50}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.3986013986013988,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":60,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 48","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3d157c1f, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@529325cf\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@63532142, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@59c284d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":905,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":907,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":908,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":902,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520409912,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":61,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 15","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":903,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":904,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":906,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":901,"metricType":"timing"}]},"time":1668520409912,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":62,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 48","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2fcd1f74, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@3a0db46e\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@63532142, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@59c284d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":905,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":907,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":908,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":902,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520409922,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":30,"Submission Time":1668520409955,"Stage Infos":[{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"277\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"DataSourceRDD","Scope":"{\"id\":\"277\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[30],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 48","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"48","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"62","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"277\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"DataSourceRDD","Scope":"{\"id\":\"277\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520409956,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 48","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"48","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"62","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":30,"Stage Attempt ID":0,"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520409964,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":63,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 15","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#390, value#391, timestamp#392]\nArguments: [topic#390, value#391, timestamp#392], SQLExecutionRDD[123] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#390, value#391, timestamp#392]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@17947781, org.apache.spark.sql.connector.write.WriteBuilder$1@65f70c60\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@17947781, org.apache.spark.sql.connector.write.WriteBuilder$1@65f70c60","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#390,value#391,timestamp#392]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":935,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":934,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520410027,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":31,"Submission Time":1668520410033,"Stage Infos":[{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"278\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[122],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"DataSourceRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[31],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 15","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"15","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"63","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"278\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[122],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"DataSourceRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520410034,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 15","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"15","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"63","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":31,"Stage Attempt ID":0,"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520410041,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":30,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":30,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520409964,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520410526,"Failed":false,"Killed":false,"Accumulables":[{"ID":902,"Name":"duration","Update":"530","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":905,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":909,"Name":"internal.metrics.executorDeserializeTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":910,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7748288,"Value":7748288,"Internal":true,"Count Failed Values":true},{"ID":911,"Name":"internal.metrics.executorRunTime","Update":534,"Value":534,"Internal":true,"Count Failed Values":true},{"ID":912,"Name":"internal.metrics.executorCpuTime","Update":16519211,"Value":16519211,"Internal":true,"Count Failed Values":true},{"ID":913,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":931,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":22,"Executor Deserialize CPU Time":7748288,"Executor Run Time":534,"Executor CPU Time":16519211,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":30,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":126,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"274\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[125],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":125,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"277\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[124],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":124,"Name":"DataSourceRDD","Scope":"{\"id\":\"277\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520409956,"Completion Time":1668520410527,"Accumulables":[{"ID":902,"Name":"duration","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":905,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":909,"Name":"internal.metrics.executorDeserializeTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":910,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7748288,"Internal":true,"Count Failed Values":true},{"ID":911,"Name":"internal.metrics.executorRunTime","Value":534,"Internal":true,"Count Failed Values":true},{"ID":912,"Name":"internal.metrics.executorCpuTime","Value":16519211,"Internal":true,"Count Failed Values":true},{"ID":913,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":931,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":30,"Completion Time":1668520410527,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":62,"time":1668520410528}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":60,"time":1668520410528}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:53:29.866Z","batchId":48,"batchDuration":684,"durationMs":{"triggerExecution":684,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":625,"walCommit":26},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":50}}","endOffset":"{\"12003800_test\":{\"0\":51}}","latestOffset":"{\"12003800_test\":{\"0\":51}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.461988304093567,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":31,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":31,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520410041,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520410603,"Failed":false,"Killed":false,"Accumulables":[{"ID":901,"Name":"duration","Update":"533","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":903,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":934,"Name":"duration","Update":"533","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":935,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":936,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":937,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10036938,"Value":10036938,"Internal":true,"Count Failed Values":true},{"ID":938,"Name":"internal.metrics.executorRunTime","Update":541,"Value":541,"Internal":true,"Count Failed Values":true},{"ID":939,"Name":"internal.metrics.executorCpuTime","Update":18962755,"Value":18962755,"Internal":true,"Count Failed Values":true},{"ID":940,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":958,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":10036938,"Executor Run Time":541,"Executor CPU Time":18962755,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":31,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":127,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"278\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[123],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":122,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"270\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[121],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":121,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[120],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":123,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[122],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":120,"Name":"DataSourceRDD","Scope":"{\"id\":\"273\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520410034,"Completion Time":1668520410603,"Accumulables":[{"ID":901,"Name":"duration","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":903,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":934,"Name":"duration","Value":"533","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":935,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":936,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":937,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10036938,"Internal":true,"Count Failed Values":true},{"ID":938,"Name":"internal.metrics.executorRunTime","Value":541,"Internal":true,"Count Failed Values":true},{"ID":939,"Name":"internal.metrics.executorCpuTime","Value":18962755,"Internal":true,"Count Failed Values":true},{"ID":940,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":958,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":31,"Completion Time":1668520410604,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":63,"time":1668520410604}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":61,"time":1668520410605}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:53:29.867Z","batchId":15,"batchDuration":764,"durationMs":{"triggerExecution":764,"queryPlanning":10,"getBatch":0,"latestOffset":0,"addBatch":701,"walCommit":25},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":50}}","endOffset":"{\"12003800_test\":{\"0\":51}}","latestOffset":"{\"12003800_test\":{\"0\":51}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.3089005235602094,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":64,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 49","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7f8df24b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@598a0dfd\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2931a260, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5e3b383b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":962,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":963,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":964,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":961,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520419914,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":65,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 16","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":966,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":967,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":968,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":965,"metricType":"timing"}]},"time":1668520419916,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":66,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 49","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e4d67bd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@d685720\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2931a260, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5e3b383b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":962,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":963,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":964,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":961,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520419924,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":32,"Submission Time":1668520419939,"Stage Infos":[{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":134,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"292\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"DataSourceRDD","Scope":"{\"id\":\"295\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"295\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[32],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 49","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"49","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"66","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":134,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"292\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"DataSourceRDD","Scope":"{\"id\":\"295\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"295\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520419940,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 49","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"49","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"66","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":32,"Stage Attempt ID":0,"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520419952,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":67,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 16","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#412, value#413, timestamp#414]\nArguments: [topic#412, value#413, timestamp#414], SQLExecutionRDD[131] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#412, value#413, timestamp#414]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@5df345cb, org.apache.spark.sql.connector.write.WriteBuilder$1@18de7f0b\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@5df345cb, org.apache.spark.sql.connector.write.WriteBuilder$1@18de7f0b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#412,value#413,timestamp#414]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":995,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":994,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520419976,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":33,"Submission Time":1668520419981,"Stage Infos":[{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"296\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[131],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":131,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[130],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"DataSourceRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"288\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[33],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 16","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"16","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"67","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"296\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[131],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":131,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[130],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"DataSourceRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"288\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520419983,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 16","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"16","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"67","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":33,"Stage Attempt ID":0,"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520419991,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":32,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":32,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520419952,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520420492,"Failed":false,"Killed":false,"Accumulables":[{"ID":961,"Name":"duration","Update":"517","Value":"517","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":962,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":969,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":970,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6267652,"Value":6267652,"Internal":true,"Count Failed Values":true},{"ID":971,"Name":"internal.metrics.executorRunTime","Update":521,"Value":521,"Internal":true,"Count Failed Values":true},{"ID":972,"Name":"internal.metrics.executorCpuTime","Update":15645005,"Value":15645005,"Internal":true,"Count Failed Values":true},{"ID":973,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":991,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":6267652,"Executor Run Time":521,"Executor CPU Time":15645005,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":32,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":134,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"292\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[133],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":132,"Name":"DataSourceRDD","Scope":"{\"id\":\"295\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":133,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"295\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[132],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520419940,"Completion Time":1668520420493,"Accumulables":[{"ID":961,"Name":"duration","Value":"517","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":962,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":969,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":970,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6267652,"Internal":true,"Count Failed Values":true},{"ID":971,"Name":"internal.metrics.executorRunTime","Value":521,"Internal":true,"Count Failed Values":true},{"ID":972,"Name":"internal.metrics.executorCpuTime","Value":15645005,"Internal":true,"Count Failed Values":true},{"ID":973,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":991,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":32,"Completion Time":1668520420493,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":66,"time":1668520420494}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":64,"time":1668520420494}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:53:39.874Z","batchId":49,"batchDuration":648,"durationMs":{"triggerExecution":648,"queryPlanning":9,"getBatch":0,"latestOffset":0,"addBatch":588,"walCommit":22},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":51}}","endOffset":"{\"12003800_test\":{\"0\":52}}","latestOffset":"{\"12003800_test\":{\"0\":52}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.5432098765432098,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":33,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":33,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520419991,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520420547,"Failed":false,"Killed":false,"Accumulables":[{"ID":965,"Name":"duration","Update":"530","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":966,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":994,"Name":"duration","Update":"530","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":995,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":996,"Name":"internal.metrics.executorDeserializeTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":997,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6649195,"Value":6649195,"Internal":true,"Count Failed Values":true},{"ID":998,"Name":"internal.metrics.executorRunTime","Update":538,"Value":538,"Internal":true,"Count Failed Values":true},{"ID":999,"Name":"internal.metrics.executorCpuTime","Update":18552795,"Value":18552795,"Internal":true,"Count Failed Values":true},{"ID":1000,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1018,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":12,"Executor Deserialize CPU Time":6649195,"Executor Run Time":538,"Executor CPU Time":18552795,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":33,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":135,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"296\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[131],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":131,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[130],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":129,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[128],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":128,"Name":"DataSourceRDD","Scope":"{\"id\":\"291\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":130,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"288\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[129],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520419983,"Completion Time":1668520420548,"Accumulables":[{"ID":965,"Name":"duration","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":966,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":994,"Name":"duration","Value":"530","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":995,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":996,"Name":"internal.metrics.executorDeserializeTime","Value":12,"Internal":true,"Count Failed Values":true},{"ID":997,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6649195,"Internal":true,"Count Failed Values":true},{"ID":998,"Name":"internal.metrics.executorRunTime","Value":538,"Internal":true,"Count Failed Values":true},{"ID":999,"Name":"internal.metrics.executorCpuTime","Value":18552795,"Internal":true,"Count Failed Values":true},{"ID":1000,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1018,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":33,"Completion Time":1668520420548,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":67,"time":1668520420550}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":65,"time":1668520420550}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:53:39.874Z","batchId":16,"batchDuration":706,"durationMs":{"triggerExecution":706,"queryPlanning":8,"getBatch":0,"latestOffset":0,"addBatch":643,"walCommit":23},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":51}}","endOffset":"{\"12003800_test\":{\"0\":52}}","latestOffset":"{\"12003800_test\":{\"0\":52}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.41643059490085,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":68,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 50","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@b77bb91, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@2e2265bf\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3d000c66, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@1ca3f75b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1022,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1023,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1024,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1021,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520429912,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":70,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 50","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@70cc49cd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@e8b8e7\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3d000c66, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@1ca3f75b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1022,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1023,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1024,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1021,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520429918,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":69,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 17","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1026,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1027,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1028,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1025,"metricType":"timing"}]},"time":1668520429919,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":34,"Submission Time":1668520429927,"Stage Infos":[{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":142,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"309\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[139],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":139,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"313\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"DataSourceRDD","Scope":"{\"id\":\"313\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[34],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 50","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"50","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"70","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":142,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"309\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[139],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":139,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"313\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"DataSourceRDD","Scope":"{\"id\":\"313\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520429927,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 50","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"50","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"70","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":34,"Stage Attempt ID":0,"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520429934,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":71,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 17","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#435, value#436, timestamp#437]\nArguments: [topic#435, value#436, timestamp#437], SQLExecutionRDD[141] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#435, value#436, timestamp#437]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@5a61af69, org.apache.spark.sql.connector.write.WriteBuilder$1@1b3fcd21\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@5a61af69, org.apache.spark.sql.connector.write.WriteBuilder$1@1b3fcd21","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#435,value#436,timestamp#437]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1055,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1054,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520429970,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":35,"Submission Time":1668520429978,"Stage Infos":[{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":143,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"314\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[141],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":136,"Name":"DataSourceRDD","Scope":"{\"id\":\"312\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":141,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[140],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":140,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"306\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[138],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"312\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[136],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[35],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 17","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"17","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"71","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":143,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"314\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[141],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":136,"Name":"DataSourceRDD","Scope":"{\"id\":\"312\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":141,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[140],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":140,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"306\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[138],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"312\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[136],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520429979,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 17","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"17","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"71","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":35,"Stage Attempt ID":0,"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520429985,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":34,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":34,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520429934,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520430482,"Failed":false,"Killed":false,"Accumulables":[{"ID":1021,"Name":"duration","Update":"518","Value":"518","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1022,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1029,"Name":"internal.metrics.executorDeserializeTime","Update":17,"Value":17,"Internal":true,"Count Failed Values":true},{"ID":1030,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7266994,"Value":7266994,"Internal":true,"Count Failed Values":true},{"ID":1031,"Name":"internal.metrics.executorRunTime","Update":522,"Value":522,"Internal":true,"Count Failed Values":true},{"ID":1032,"Name":"internal.metrics.executorCpuTime","Update":15283737,"Value":15283737,"Internal":true,"Count Failed Values":true},{"ID":1033,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1051,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":17,"Executor Deserialize CPU Time":7266994,"Executor Run Time":522,"Executor CPU Time":15283737,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":34,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":142,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"309\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[139],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":139,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"313\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[137],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":137,"Name":"DataSourceRDD","Scope":"{\"id\":\"313\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520429927,"Completion Time":1668520430483,"Accumulables":[{"ID":1021,"Name":"duration","Value":"518","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1022,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1029,"Name":"internal.metrics.executorDeserializeTime","Value":17,"Internal":true,"Count Failed Values":true},{"ID":1030,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7266994,"Internal":true,"Count Failed Values":true},{"ID":1031,"Name":"internal.metrics.executorRunTime","Value":522,"Internal":true,"Count Failed Values":true},{"ID":1032,"Name":"internal.metrics.executorCpuTime","Value":15283737,"Internal":true,"Count Failed Values":true},{"ID":1033,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1051,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":34,"Completion Time":1668520430483,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":70,"time":1668520430484}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":68,"time":1668520430484}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:53:49.867Z","batchId":50,"batchDuration":649,"durationMs":{"triggerExecution":649,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":580,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":52}}","endOffset":"{\"12003800_test\":{\"0\":53}}","latestOffset":"{\"12003800_test\":{\"0\":53}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.5408320493066254,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":35,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":35,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520429985,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520430541,"Failed":false,"Killed":false,"Accumulables":[{"ID":1025,"Name":"duration","Update":"526","Value":"526","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1026,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1054,"Name":"duration","Update":"526","Value":"526","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1055,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1056,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":1057,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7158392,"Value":7158392,"Internal":true,"Count Failed Values":true},{"ID":1058,"Name":"internal.metrics.executorRunTime","Update":534,"Value":534,"Internal":true,"Count Failed Values":true},{"ID":1059,"Name":"internal.metrics.executorCpuTime","Update":15860891,"Value":15860891,"Internal":true,"Count Failed Values":true},{"ID":1060,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1078,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":7158392,"Executor Run Time":534,"Executor CPU Time":15860891,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":35,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":143,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"314\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[141],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":136,"Name":"DataSourceRDD","Scope":"{\"id\":\"312\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":141,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[140],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":140,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"306\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[138],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":138,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"312\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[136],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520429979,"Completion Time":1668520430542,"Accumulables":[{"ID":1025,"Name":"duration","Value":"526","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1026,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1054,"Name":"duration","Value":"526","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1055,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1056,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":1057,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7158392,"Internal":true,"Count Failed Values":true},{"ID":1058,"Name":"internal.metrics.executorRunTime","Value":534,"Internal":true,"Count Failed Values":true},{"ID":1059,"Name":"internal.metrics.executorCpuTime","Value":15860891,"Internal":true,"Count Failed Values":true},{"ID":1060,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1078,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":35,"Completion Time":1668520430542,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":71,"time":1668520430542}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":69,"time":1668520430543}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:53:49.867Z","batchId":17,"batchDuration":703,"durationMs":{"triggerExecution":703,"queryPlanning":10,"getBatch":0,"latestOffset":0,"addBatch":634,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":52}}","endOffset":"{\"12003800_test\":{\"0\":53}}","latestOffset":"{\"12003800_test\":{\"0\":53}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.4224751066856332,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":73,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 18","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1083,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1085,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1086,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1081,"metricType":"timing"}]},"time":1668520439918,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":72,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 51","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@73bdc132, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@3b5f9172\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6ee256cd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@50d85b24","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1084,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1087,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1088,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1082,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520439918,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":74,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 51","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3df5bec3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@1b001930\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6ee256cd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@50d85b24","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1084,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1087,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1088,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1082,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520439926,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":36,"Submission Time":1668520439937,"Stage Infos":[{"Stage ID":36,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":150,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"328\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[149],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":148,"Name":"DataSourceRDD","Scope":"{\"id\":\"331\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":149,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"331\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[148],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[36],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 51","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"51","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"74","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":36,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":150,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"328\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[149],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":148,"Name":"DataSourceRDD","Scope":"{\"id\":\"331\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":149,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"331\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[148],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520439938,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 51","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"51","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"74","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":36,"Stage Attempt ID":0,"Task Info":{"Task ID":36,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520439947,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":75,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 18","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#456, value#457, timestamp#458]\nArguments: [topic#456, value#457, timestamp#458], SQLExecutionRDD[147] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#456, value#457, timestamp#458]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@1cdc0f6a, org.apache.spark.sql.connector.write.WriteBuilder$1@40e88043\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@1cdc0f6a, org.apache.spark.sql.connector.write.WriteBuilder$1@40e88043","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#456,value#457,timestamp#458]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1115,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1114,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520439982,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":37,"Submission Time":1668520439988,"Stage Infos":[{"Stage ID":37,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":151,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"332\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[147],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":147,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[146],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":146,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"324\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[145],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":145,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"327\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[144],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":144,"Name":"DataSourceRDD","Scope":"{\"id\":\"327\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[37],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 18","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"18","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"75","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":37,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":151,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"332\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[147],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":147,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[146],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":146,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"324\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[145],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":145,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"327\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[144],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":144,"Name":"DataSourceRDD","Scope":"{\"id\":\"327\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520439989,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 18","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"18","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"75","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":37,"Stage Attempt ID":0,"Task Info":{"Task ID":37,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520439998,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":36,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":36,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520439947,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520440493,"Failed":false,"Killed":false,"Accumulables":[{"ID":1082,"Name":"duration","Update":"523","Value":"523","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1084,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1089,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":1090,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7195472,"Value":7195472,"Internal":true,"Count Failed Values":true},{"ID":1091,"Name":"internal.metrics.executorRunTime","Update":526,"Value":526,"Internal":true,"Count Failed Values":true},{"ID":1092,"Name":"internal.metrics.executorCpuTime","Update":14828354,"Value":14828354,"Internal":true,"Count Failed Values":true},{"ID":1093,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1111,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7195472,"Executor Run Time":526,"Executor CPU Time":14828354,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":36,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":150,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"328\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[149],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":148,"Name":"DataSourceRDD","Scope":"{\"id\":\"331\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":149,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"331\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[148],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520439938,"Completion Time":1668520440494,"Accumulables":[{"ID":1082,"Name":"duration","Value":"523","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1084,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1089,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":1090,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7195472,"Internal":true,"Count Failed Values":true},{"ID":1091,"Name":"internal.metrics.executorRunTime","Value":526,"Internal":true,"Count Failed Values":true},{"ID":1092,"Name":"internal.metrics.executorCpuTime","Value":14828354,"Internal":true,"Count Failed Values":true},{"ID":1093,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1111,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":36,"Completion Time":1668520440494,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":74,"time":1668520440495}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":72,"time":1668520440495}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:53:59.879Z","batchId":51,"batchDuration":644,"durationMs":{"triggerExecution":644,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":584,"walCommit":22},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":53}}","endOffset":"{\"12003800_test\":{\"0\":54}}","latestOffset":"{\"12003800_test\":{\"0\":54}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.5527950310559007,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":37,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":37,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520439998,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520440551,"Failed":false,"Killed":false,"Accumulables":[{"ID":1081,"Name":"duration","Update":"522","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1083,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1114,"Name":"duration","Update":"522","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1115,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1116,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":1117,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6973938,"Value":6973938,"Internal":true,"Count Failed Values":true},{"ID":1118,"Name":"internal.metrics.executorRunTime","Update":533,"Value":533,"Internal":true,"Count Failed Values":true},{"ID":1119,"Name":"internal.metrics.executorCpuTime","Update":14853901,"Value":14853901,"Internal":true,"Count Failed Values":true},{"ID":1120,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1138,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":6973938,"Executor Run Time":533,"Executor CPU Time":14853901,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":37,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":151,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"332\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[147],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":147,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[146],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":146,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"324\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[145],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":145,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"327\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[144],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":144,"Name":"DataSourceRDD","Scope":"{\"id\":\"327\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520439989,"Completion Time":1668520440552,"Accumulables":[{"ID":1081,"Name":"duration","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1083,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1114,"Name":"duration","Value":"522","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1115,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1116,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":1117,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6973938,"Internal":true,"Count Failed Values":true},{"ID":1118,"Name":"internal.metrics.executorRunTime","Value":533,"Internal":true,"Count Failed Values":true},{"ID":1119,"Name":"internal.metrics.executorCpuTime","Value":14853901,"Internal":true,"Count Failed Values":true},{"ID":1120,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1138,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":37,"Completion Time":1668520440552,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":75,"time":1668520440552}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":73,"time":1668520440553}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:53:59.879Z","batchId":18,"batchDuration":702,"durationMs":{"triggerExecution":702,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":641,"walCommit":22},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":53}}","endOffset":"{\"12003800_test\":{\"0\":54}}","latestOffset":"{\"12003800_test\":{\"0\":54}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.4245014245014247,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":76,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 52","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4fecf273, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@dc07278\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5a08f95b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5a479f9e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1142,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1143,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1144,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1141,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520449924,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":77,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 19","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1146,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1147,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1148,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1145,"metricType":"timing"}]},"time":1668520449925,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":78,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 52","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7127bda8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@660fda9d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5a08f95b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5a479f9e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1142,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1143,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1144,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1141,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520449933,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":38,"Submission Time":1668520449945,"Stage Infos":[{"Stage ID":38,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":158,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"346\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[157],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":157,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"349\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[156],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":156,"Name":"DataSourceRDD","Scope":"{\"id\":\"349\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[38],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 52","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"52","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"78","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":38,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":158,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"346\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[157],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":157,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"349\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[156],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":156,"Name":"DataSourceRDD","Scope":"{\"id\":\"349\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520449946,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 52","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"52","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"78","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":38,"Stage Attempt ID":0,"Task Info":{"Task ID":38,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520449959,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":79,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 19","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#479, value#480, timestamp#481]\nArguments: [topic#479, value#480, timestamp#481], SQLExecutionRDD[155] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#479, value#480, timestamp#481]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@45b98f9e, org.apache.spark.sql.connector.write.WriteBuilder$1@532f7847\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@45b98f9e, org.apache.spark.sql.connector.write.WriteBuilder$1@532f7847","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#479,value#480,timestamp#481]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1175,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1174,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520449987,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":39,"Submission Time":1668520449997,"Stage Infos":[{"Stage ID":39,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":159,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"350\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[155],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":152,"Name":"DataSourceRDD","Scope":"{\"id\":\"345\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":153,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"345\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[152],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":154,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"342\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[153],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":155,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[154],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[39],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 19","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"19","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"79","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":39,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":159,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"350\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[155],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":152,"Name":"DataSourceRDD","Scope":"{\"id\":\"345\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":153,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"345\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[152],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":154,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"342\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[153],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":155,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[154],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520449998,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 19","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"19","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"79","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":39,"Stage Attempt ID":0,"Task Info":{"Task ID":39,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520450008,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":38,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":38,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520449959,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520450501,"Failed":false,"Killed":false,"Accumulables":[{"ID":1141,"Name":"duration","Update":"514","Value":"514","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1142,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1149,"Name":"internal.metrics.executorDeserializeTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":1150,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7255295,"Value":7255295,"Internal":true,"Count Failed Values":true},{"ID":1151,"Name":"internal.metrics.executorRunTime","Update":518,"Value":518,"Internal":true,"Count Failed Values":true},{"ID":1152,"Name":"internal.metrics.executorCpuTime","Update":13419058,"Value":13419058,"Internal":true,"Count Failed Values":true},{"ID":1153,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1171,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":18,"Executor Deserialize CPU Time":7255295,"Executor Run Time":518,"Executor CPU Time":13419058,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":38,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":158,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"346\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[157],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":157,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"349\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[156],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":156,"Name":"DataSourceRDD","Scope":"{\"id\":\"349\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520449946,"Completion Time":1668520450502,"Accumulables":[{"ID":1141,"Name":"duration","Value":"514","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1142,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1149,"Name":"internal.metrics.executorDeserializeTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":1150,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7255295,"Internal":true,"Count Failed Values":true},{"ID":1151,"Name":"internal.metrics.executorRunTime","Value":518,"Internal":true,"Count Failed Values":true},{"ID":1152,"Name":"internal.metrics.executorCpuTime","Value":13419058,"Internal":true,"Count Failed Values":true},{"ID":1153,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1171,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":38,"Completion Time":1668520450502,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":78,"time":1668520450503}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":76,"time":1668520450503}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:54:09.875Z","batchId":52,"batchDuration":652,"durationMs":{"triggerExecution":652,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":587,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":54}}","endOffset":"{\"12003800_test\":{\"0\":55}}","latestOffset":"{\"12003800_test\":{\"0\":55}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.5337423312883436,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":39,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":39,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520450008,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520450562,"Failed":false,"Killed":false,"Accumulables":[{"ID":1145,"Name":"duration","Update":"528","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1146,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1174,"Name":"duration","Update":"528","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1175,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1176,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":1177,"Name":"internal.metrics.executorDeserializeCpuTime","Update":7845750,"Value":7845750,"Internal":true,"Count Failed Values":true},{"ID":1178,"Name":"internal.metrics.executorRunTime","Update":535,"Value":535,"Internal":true,"Count Failed Values":true},{"ID":1179,"Name":"internal.metrics.executorCpuTime","Update":17442539,"Value":17442539,"Internal":true,"Count Failed Values":true},{"ID":1180,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1198,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":7845750,"Executor Run Time":535,"Executor CPU Time":17442539,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":39,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":159,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"350\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[155],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":152,"Name":"DataSourceRDD","Scope":"{\"id\":\"345\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":153,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"345\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[152],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":154,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"342\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[153],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":155,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[154],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520449998,"Completion Time":1668520450563,"Accumulables":[{"ID":1145,"Name":"duration","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1146,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1174,"Name":"duration","Value":"528","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1175,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1176,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":1177,"Name":"internal.metrics.executorDeserializeCpuTime","Value":7845750,"Internal":true,"Count Failed Values":true},{"ID":1178,"Name":"internal.metrics.executorRunTime","Value":535,"Internal":true,"Count Failed Values":true},{"ID":1179,"Name":"internal.metrics.executorCpuTime","Value":17442539,"Internal":true,"Count Failed Values":true},{"ID":1180,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1198,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":39,"Completion Time":1668520450563,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":79,"time":1668520450564}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":77,"time":1668520450564}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:54:09.875Z","batchId":19,"batchDuration":716,"durationMs":{"triggerExecution":716,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":647,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":54}}","endOffset":"{\"12003800_test\":{\"0\":55}}","latestOffset":"{\"12003800_test\":{\"0\":55}}","numInputRows":1,"inputRowsPerSecond":100.0,"processedRowsPerSecond":1.3966480446927374,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":80,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 53","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6e78be56, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@21dac967\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e3fb96, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5b7aa834","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1202,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1203,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1204,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1201,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520459952,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":81,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 20","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1206,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1207,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1208,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1205,"metricType":"timing"}]},"time":1668520459955,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":82,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 53","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3fe25372, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@52fe1cb9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e3fb96, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@5b7aa834","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1202,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1203,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1204,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1201,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520459962,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":40,"Submission Time":1668520459969,"Stage Infos":[{"Stage ID":40,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":166,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"364\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[165],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":165,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"367\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[164],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":164,"Name":"DataSourceRDD","Scope":"{\"id\":\"367\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[40],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 53","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"53","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"82","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":40,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":166,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"364\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[165],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":165,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"367\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[164],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":164,"Name":"DataSourceRDD","Scope":"{\"id\":\"367\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520459970,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 53","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"53","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"82","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":40,"Stage Attempt ID":0,"Task Info":{"Task ID":40,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520459979,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":83,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 20","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#500, value#501, timestamp#502]\nArguments: [topic#500, value#501, timestamp#502], SQLExecutionRDD[163] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#500, value#501, timestamp#502]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@1fc19e5, org.apache.spark.sql.connector.write.WriteBuilder$1@56d9d26d\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@1fc19e5, org.apache.spark.sql.connector.write.WriteBuilder$1@56d9d26d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#500,value#501,timestamp#502]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1235,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1234,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520460013,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":41,"Submission Time":1668520460017,"Stage Infos":[{"Stage ID":41,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":167,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"368\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[163],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":162,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"360\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[161],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":160,"Name":"DataSourceRDD","Scope":"{\"id\":\"363\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":163,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[162],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":161,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"363\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[160],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[41],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 20","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"20","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"83","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":41,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":167,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"368\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[163],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":162,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"360\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[161],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":160,"Name":"DataSourceRDD","Scope":"{\"id\":\"363\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":163,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[162],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":161,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"363\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[160],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520460018,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 20","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"20","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"83","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":41,"Stage Attempt ID":0,"Task Info":{"Task ID":41,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520460025,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":40,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":40,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520459979,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520460519,"Failed":false,"Killed":false,"Accumulables":[{"ID":1201,"Name":"duration","Update":"514","Value":"514","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1202,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1209,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":1210,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6920336,"Value":6920336,"Internal":true,"Count Failed Values":true},{"ID":1211,"Name":"internal.metrics.executorRunTime","Update":518,"Value":518,"Internal":true,"Count Failed Values":true},{"ID":1212,"Name":"internal.metrics.executorCpuTime","Update":13907850,"Value":13907850,"Internal":true,"Count Failed Values":true},{"ID":1213,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1231,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":6920336,"Executor Run Time":518,"Executor CPU Time":13907850,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":40,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":166,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"364\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[165],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":165,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"367\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[164],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":164,"Name":"DataSourceRDD","Scope":"{\"id\":\"367\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520459970,"Completion Time":1668520460519,"Accumulables":[{"ID":1201,"Name":"duration","Value":"514","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1202,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1209,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":1210,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6920336,"Internal":true,"Count Failed Values":true},{"ID":1211,"Name":"internal.metrics.executorRunTime","Value":518,"Internal":true,"Count Failed Values":true},{"ID":1212,"Name":"internal.metrics.executorCpuTime","Value":13907850,"Internal":true,"Count Failed Values":true},{"ID":1213,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1231,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":40,"Completion Time":1668520460520,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":82,"time":1668520460520}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":80,"time":1668520460520}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:54:19.878Z","batchId":53,"batchDuration":669,"durationMs":{"triggerExecution":669,"queryPlanning":10,"getBatch":0,"latestOffset":3,"addBatch":579,"walCommit":48},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":55}}","endOffset":"{\"12003800_test\":{\"0\":56}}","latestOffset":"{\"12003800_test\":{\"0\":56}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.4947683109118086,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":41,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":41,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520460025,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520460580,"Failed":false,"Killed":false,"Accumulables":[{"ID":1205,"Name":"duration","Update":"529","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1206,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1234,"Name":"duration","Update":"529","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1235,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1236,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":1237,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6815387,"Value":6815387,"Internal":true,"Count Failed Values":true},{"ID":1238,"Name":"internal.metrics.executorRunTime","Update":537,"Value":537,"Internal":true,"Count Failed Values":true},{"ID":1239,"Name":"internal.metrics.executorCpuTime","Update":15580513,"Value":15580513,"Internal":true,"Count Failed Values":true},{"ID":1240,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1258,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":6815387,"Executor Run Time":537,"Executor CPU Time":15580513,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":41,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":167,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"368\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[163],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":162,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"360\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[161],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":160,"Name":"DataSourceRDD","Scope":"{\"id\":\"363\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":163,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[162],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":161,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"363\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[160],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520460018,"Completion Time":1668520460581,"Accumulables":[{"ID":1205,"Name":"duration","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1206,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1234,"Name":"duration","Value":"529","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1235,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1236,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":1237,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6815387,"Internal":true,"Count Failed Values":true},{"ID":1238,"Name":"internal.metrics.executorRunTime","Value":537,"Internal":true,"Count Failed Values":true},{"ID":1239,"Name":"internal.metrics.executorCpuTime","Value":15580513,"Internal":true,"Count Failed Values":true},{"ID":1240,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1258,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":41,"Completion Time":1668520460581,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":83,"time":1668520460582}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":81,"time":1668520460582}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:54:19.878Z","batchId":20,"batchDuration":732,"durationMs":{"triggerExecution":732,"queryPlanning":11,"getBatch":0,"latestOffset":3,"addBatch":638,"walCommit":50},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":55}}","endOffset":"{\"12003800_test\":{\"0\":56}}","latestOffset":"{\"12003800_test\":{\"0\":56}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.366120218579235,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":84,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 21","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [3]: [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#44, timestamp#12]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1262,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1263,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1264,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1261,"metricType":"timing"}]},"time":1668520469927,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":85,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 54","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@59406f6, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@3e205947\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7b5b1d1e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@181095ef","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1266,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1267,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1268,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1265,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520469928,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":86,"description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 54","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3771f022, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@36c998b2\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7b5b1d1e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2566/1375998975@181095ef","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1266,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":1267,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":1268,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1265,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520469934,"modifiedConfigs":{"spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.adaptive.enabled":"false","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.sql.cbo.enabled":"false","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerJobStart","Job ID":42,"Submission Time":1668520469940,"Stage Infos":[{"Stage ID":42,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":174,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"382\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[173],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":173,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"385\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[172],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":172,"Name":"DataSourceRDD","Scope":"{\"id\":\"385\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[42],"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 54","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"54","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"86","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":42,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":174,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"382\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[173],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":173,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"385\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[172],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":172,"Name":"DataSourceRDD","Scope":"{\"id\":\"385\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520469941,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"1a524b61-9b0f-4843-b7c0-9255c13803c3","spark.sql.streaming.stateStore.providerClass":"org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.sql.streaming.join.stateFormatVersion":"2","spark.sql.streaming.stateStore.compression.codec":"lz4","spark.jars":"*********(redacted)","spark.sql.streaming.stateStore.rocksdb.formatVersion":"5","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","spark.sql.streaming.statefulOperator.useStrictDistribution":"true","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion":"2","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.sql.streaming.multipleWatermarkPolicy":"min","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 1a524b61-9b0f-4843-b7c0-9255c13803c3\nrunId = 2fb1c175-b730-4f4d-af22-f897fa3f09b8\nbatch = 54","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"54","spark.jobGroup.id":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.sql.streaming.aggregation.stateFormatVersion":"2","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"86","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra","spark.sql.shuffle.partitions":"200"}}
{"Event":"SparkListenerTaskStart","Stage ID":42,"Stage Attempt ID":0,"Task Info":{"Task ID":42,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520469948,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":87,"description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 21","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [3]: [topic#522, value#523, timestamp#524]\nArguments: [topic#522, value#523, timestamp#524], SQLExecutionRDD[171] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [3]: [topic#522, value#523, timestamp#524]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@74731c1c, org.apache.spark.sql.connector.write.WriteBuilder$1@6f4ee951\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3711/2121296359@74731c1c, org.apache.spark.sql.connector.write.WriteBuilder$1@6f4ee951","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#522,value#523,timestamp#524]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":1295,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1294,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1668520469976,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":43,"Submission Time":1668520469981,"Stage Infos":[{"Stage ID":43,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":175,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"386\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[171],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":168,"Name":"DataSourceRDD","Scope":"{\"id\":\"381\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":171,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[170],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":170,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"378\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[169],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":169,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"381\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[168],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[43],"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 21","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"21","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"87","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":43,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":175,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"386\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[171],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":168,"Name":"DataSourceRDD","Scope":"{\"id\":\"381\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":171,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[170],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":170,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"378\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[169],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":169,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"381\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[168],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520469982,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"59d58a6d-7f8d-4a8c-9720-0108756aed21","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"221a64cc1b2e","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"43125","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1668520253696","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 59d58a6d-7f8d-4a8c-9720-0108756aed21\nrunId = eb1baa07-9778-48c7-87f5-df066da5c56d\nbatch = 21","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1668520253910","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"21","spark.jobGroup.id":"eb1baa07-9778-48c7-87f5-df066da5c56d","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"87","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221115145055-0003","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":43,"Stage Attempt ID":0,"Task Info":{"Task ID":43,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520469993,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":42,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":42,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520469948,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520470486,"Failed":false,"Killed":false,"Accumulables":[{"ID":1265,"Name":"duration","Update":"514","Value":"514","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1266,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1269,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":1270,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6953587,"Value":6953587,"Internal":true,"Count Failed Values":true},{"ID":1271,"Name":"internal.metrics.executorRunTime","Update":518,"Value":518,"Internal":true,"Count Failed Values":true},{"ID":1272,"Name":"internal.metrics.executorCpuTime","Update":13984092,"Value":13984092,"Internal":true,"Count Failed Values":true},{"ID":1273,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1291,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":6953587,"Executor Run Time":518,"Executor CPU Time":13984092,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":42,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":174,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"382\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[173],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":173,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"385\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[172],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":172,"Name":"DataSourceRDD","Scope":"{\"id\":\"385\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520469941,"Completion Time":1668520470486,"Accumulables":[{"ID":1265,"Name":"duration","Value":"514","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1266,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1269,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":1270,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6953587,"Internal":true,"Count Failed Values":true},{"ID":1271,"Name":"internal.metrics.executorRunTime","Value":518,"Internal":true,"Count Failed Values":true},{"ID":1272,"Name":"internal.metrics.executorCpuTime","Value":13984092,"Internal":true,"Count Failed Values":true},{"ID":1273,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":1291,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":42,"Completion Time":1668520470486,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":86,"time":1668520470487}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":85,"time":1668520470487}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"1a524b61-9b0f-4843-b7c0-9255c13803c3","runId":"2fb1c175-b730-4f4d-af22-f897fa3f09b8","name":null,"timestamp":"2022-11-15T13:54:29.885Z","batchId":54,"batchDuration":630,"durationMs":{"triggerExecution":630,"queryPlanning":8,"getBatch":0,"latestOffset":0,"addBatch":567,"walCommit":27},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":56}}","endOffset":"{\"12003800_test\":{\"0\":57}}","latestOffset":"{\"12003800_test\":{\"0\":57}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.5873015873015872,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4ddbd53e","numOutputRows":1},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":43,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":43,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1668520469993,"Executor ID":"0","Host":"172.19.0.11","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1668520470546,"Failed":false,"Killed":false,"Accumulables":[{"ID":1261,"Name":"duration","Update":"524","Value":"524","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1262,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1294,"Name":"duration","Update":"524","Value":"524","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1295,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1296,"Name":"internal.metrics.executorDeserializeTime","Update":16,"Value":16,"Internal":true,"Count Failed Values":true},{"ID":1297,"Name":"internal.metrics.executorDeserializeCpuTime","Update":6908974,"Value":6908974,"Internal":true,"Count Failed Values":true},{"ID":1298,"Name":"internal.metrics.executorRunTime","Update":531,"Value":531,"Internal":true,"Count Failed Values":true},{"ID":1299,"Name":"internal.metrics.executorCpuTime","Update":15825916,"Value":15825916,"Internal":true,"Count Failed Values":true},{"ID":1300,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1318,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":16,"Executor Deserialize CPU Time":6908974,"Executor Run Time":531,"Executor CPU Time":15825916,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":43,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":175,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"386\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[171],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":168,"Name":"DataSourceRDD","Scope":"{\"id\":\"381\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":171,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[170],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":170,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"378\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[169],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":169,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"381\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[168],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1668520469982,"Completion Time":1668520470547,"Accumulables":[{"ID":1261,"Name":"duration","Value":"524","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1262,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1294,"Name":"duration","Value":"524","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1295,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":1296,"Name":"internal.metrics.executorDeserializeTime","Value":16,"Internal":true,"Count Failed Values":true},{"ID":1297,"Name":"internal.metrics.executorDeserializeCpuTime","Value":6908974,"Internal":true,"Count Failed Values":true},{"ID":1298,"Name":"internal.metrics.executorRunTime","Value":531,"Internal":true,"Count Failed Values":true},{"ID":1299,"Name":"internal.metrics.executorCpuTime","Value":15825916,"Internal":true,"Count Failed Values":true},{"ID":1300,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":1318,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":43,"Completion Time":1668520470547,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":87,"time":1668520470547}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":84,"time":1668520470548}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"59d58a6d-7f8d-4a8c-9720-0108756aed21","runId":"eb1baa07-9778-48c7-87f5-df066da5c56d","name":null,"timestamp":"2022-11-15T13:54:29.885Z","batchId":21,"batchDuration":689,"durationMs":{"triggerExecution":689,"queryPlanning":7,"getBatch":0,"latestOffset":1,"addBatch":628,"walCommit":26},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":56}}","endOffset":"{\"12003800_test\":{\"0\":57}}","latestOffset":"{\"12003800_test\":{\"0\":57}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":1.451378809869376,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1668520477841}
