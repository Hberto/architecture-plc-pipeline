{"Event":"SparkListenerLogStart","Spark Version":"3.3.1"}
{"Event":"SparkListenerResourceProfileAdded","Resource Profile Id":0,"Executor Resource Requests":{"cores":{"Resource Name":"cores","Amount":1,"Discovery Script":"","Vendor":""},"memory":{"Resource Name":"memory","Amount":1024,"Discovery Script":"","Vendor":""},"offHeap":{"Resource Name":"offHeap","Amount":0,"Discovery Script":"","Vendor":""}},"Task Resource Requests":{"cpus":{"Resource Name":"cpus","Amount":1.0}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"afe89519116f","Port":34911},"Maximum Memory":384093388,"Timestamp":1669336525463,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-8-openjdk-amd64/jre","Java Version":"1.8.0_352 (Private Build)","Scala Version":"version 2.12.15"},"Spark Properties":{"spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","spark.app.name":"Testing the Stream with Kafka","spark.app.initial.file.urls":"*********(redacted)","spark.scheduler.mode":"FIFO","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.cassandra.connection.port":"9042","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"},"Hadoop Properties":{"hadoop.service.shutdown.timeout":"30s","yarn.resourcemanager.amlauncher.thread-count":"50","yarn.sharedcache.enabled":"false","fs.s3a.connection.maximum":"96","yarn.nodemanager.numa-awareness.numactl.cmd":"/usr/bin/numactl","fs.viewfs.overload.scheme.target.o3fs.impl":"org.apache.hadoop.fs.ozone.OzoneFileSystem","fs.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms":"1000","yarn.timeline-service.timeline-client.number-of-async-entities-to-merge":"10","hadoop.security.kms.client.timeout":"60","hadoop.http.authentication.kerberos.principal":"HTTP/_HOST@LOCALHOST","mapreduce.jobhistory.loadedjob.tasks.max":"-1","yarn.resourcemanager.application-tag-based-placement.enable":"false","mapreduce.framework.name":"local","yarn.sharedcache.uploader.server.thread-count":"50","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min":"3600","yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern":"^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$","tfile.fs.output.buffer.size":"262144","yarn.app.mapreduce.am.job.task.listener.thread-count":"30","yarn.nodemanager.node-attributes.resync-interval-ms":"120000","yarn.nodemanager.container-log-monitor.interval-ms":"60000","hadoop.security.groups.cache.background.reload.threads":"3","yarn.resourcemanager.webapp.cross-origin.enabled":"false","fs.AbstractFileSystem.ftp.impl":"org.apache.hadoop.fs.ftp.FtpFs","fs.viewfs.overload.scheme.target.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","hadoop.registry.secure":"false","hadoop.shell.safely.delete.limit.num.files":"100","mapreduce.job.acl-view-job":" ","fs.s3a.s3guard.ddb.background.sleep":"25ms","fs.s3a.retry.limit":"7","mapreduce.jobhistory.loadedjobs.cache.size":"5","fs.s3a.s3guard.ddb.table.create":"false","fs.viewfs.overload.scheme.target.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.nodemanager.amrmproxy.enabled":"false","yarn.timeline-service.entity-group-fs-store.with-user-dir":"false","mapreduce.shuffle.pathcache.expire-after-access-minutes":"5","mapreduce.input.fileinputformat.split.minsize":"0","yarn.resourcemanager.container.liveness-monitor.interval-ms":"600000","yarn.resourcemanager.client.thread-count":"50","io.seqfile.compress.blocksize":"1000000","yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes":"runc","fs.viewfs.overload.scheme.target.http.impl":"org.apache.hadoop.fs.http.HttpFileSystem","yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor":"1.0","yarn.sharedcache.checksum.algo.impl":"org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl","yarn.nodemanager.amrmproxy.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor","yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size":"10485760","mapreduce.reduce.shuffle.fetch.retry.interval-ms":"1000","mapreduce.task.profile.maps":"0-2","yarn.scheduler.include-port-in-node-name":"false","yarn.nodemanager.admin-env":"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX","yarn.resourcemanager.node-removal-untracked.timeout-ms":"60000","mapreduce.am.max-attempts":"2","hadoop.security.kms.client.failover.sleep.base.millis":"100","mapreduce.jobhistory.webapp.https.address":"0.0.0.0:19890","yarn.node-labels.fs-store.impl.class":"org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore","yarn.nodemanager.collector-service.address":"${yarn.nodemanager.hostname}:8048","fs.trash.checkpoint.interval":"0","mapreduce.job.map.output.collector.class":"org.apache.hadoop.mapred.MapTask$MapOutputBuffer","yarn.resourcemanager.node-ip-cache.expiry-interval-secs":"-1","hadoop.http.authentication.signature.secret.file":"*********(redacted)","hadoop.jetty.logs.serve.aliases":"true","yarn.resourcemanager.placement-constraints.handler":"disabled","yarn.timeline-service.handler-thread-count":"10","yarn.resourcemanager.max-completed-applications":"1000","yarn.nodemanager.aux-services.manifest.enabled":"false","yarn.resourcemanager.system-metrics-publisher.enabled":"false","yarn.resourcemanager.placement-constraints.algorithm.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm","yarn.sharedcache.webapp.address":"0.0.0.0:8788","fs.s3a.select.input.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.renew-interval":"*********(redacted)","yarn.sharedcache.nm.uploader.replication.factor":"10","hadoop.security.groups.negative-cache.secs":"30","yarn.app.mapreduce.task.container.log.backups":"0","mapreduce.reduce.skip.proc-count.auto-incr":"true","fs.viewfs.overload.scheme.target.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","hadoop.security.group.mapping.ldap.posix.attr.gid.name":"gidNumber","ipc.client.fallback-to-simple-auth-allowed":"false","yarn.nodemanager.resource.memory.enforced":"true","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch":"false","yarn.client.failover-proxy-provider":"org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider","yarn.timeline-service.http-authentication.simple.anonymous.allowed":"true","ha.health-monitor.check-interval.ms":"1000","yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed":"false","hadoop.metrics.jvm.use-thread-mxbean":"false","ipc.[port_number].faircallqueue.multiplexer.weights":"8,4,2,1","yarn.acl.reservation-enable":"false","yarn.resourcemanager.store.class":"org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore","yarn.app.mapreduce.am.hard-kill-timeout-ms":"10000","fs.s3a.etag.checksum.enabled":"false","yarn.nodemanager.container-metrics.enable":"true","ha.health-monitor.rpc.connect.max.retries":"1","yarn.timeline-service.client.fd-clean-interval-secs":"60","yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable":"false","yarn.resourcemanager.nodemanagers.heartbeat-interval-ms":"1000","hadoop.common.configuration.version":"3.0.0","fs.s3a.s3guard.ddb.table.capacity.read":"0","yarn.nodemanager.remote-app-log-dir-suffix":"logs","yarn.nodemanager.container-log-monitor.dir-size-limit-bytes":"1000000000","yarn.nodemanager.windows-container.cpu-limit.enabled":"false","yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed":"false","file.blocksize":"67108864","hadoop.http.idle_timeout.ms":"60000","hadoop.registry.zk.retry.ceiling.ms":"60000","yarn.scheduler.configuration.leveldb-store.path":"${hadoop.tmp.dir}/yarn/system/confstore","yarn.sharedcache.store.in-memory.initial-delay-mins":"10","mapreduce.jobhistory.principal":"jhs/_HOST@REALM.TLD","mapreduce.map.skip.proc-count.auto-incr":"true","fs.s3a.committer.name":"file","mapreduce.task.profile.reduces":"0-2","hadoop.zk.num-retries":"1000","yarn.webapp.xfs-filter.enabled":"true","fs.viewfs.overload.scheme.target.hdfs.impl":"org.apache.hadoop.hdfs.DistributedFileSystem","seq.io.sort.mb":"100","yarn.scheduler.configuration.max.version":"100","yarn.timeline-service.webapp.https.address":"${yarn.timeline-service.hostname}:8190","yarn.resourcemanager.scheduler.address":"${yarn.resourcemanager.hostname}:8030","yarn.node-labels.enabled":"false","yarn.resourcemanager.webapp.ui-actions.enabled":"true","mapreduce.task.timeout":"600000","yarn.sharedcache.client-server.thread-count":"50","hadoop.security.groups.shell.command.timeout":"0s","hadoop.security.crypto.cipher.suite":"AES/CTR/NoPadding","yarn.nodemanager.elastic-memory-control.oom-handler":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler","yarn.resourcemanager.connect.max-wait.ms":"900000","fs.defaultFS":"file:///","yarn.minicluster.use-rpc":"false","ipc.[port_number].decay-scheduler.decay-factor":"0.5","fs.har.impl.disable.cache":"true","yarn.webapp.ui2.enable":"false","io.compression.codec.bzip2.library":"system-native","yarn.webapp.filter-invalid-xml-chars":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs":"600","fs.s3a.select.input.csv.record.delimiter":"\\n","fs.s3a.change.detection.source":"etag","ipc.[port_number].backoff.enable":"false","yarn.nodemanager.distributed-scheduling.enabled":"false","mapreduce.shuffle.connection-keep-alive.timeout":"5","yarn.resourcemanager.webapp.https.address":"${yarn.resourcemanager.hostname}:8090","yarn.webapp.enable-rest-app-submissions":"true","mapreduce.jobhistory.address":"0.0.0.0:10020","yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.is.minicluster":"false","yarn.nodemanager.address":"${yarn.nodemanager.hostname}:0","fs.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","fs.AbstractFileSystem.s3a.impl":"org.apache.hadoop.fs.s3a.S3A","mapreduce.task.combine.progress.records":"10000","yarn.resourcemanager.epoch.range":"0","yarn.resourcemanager.am.max-attempts":"2","yarn.nodemanager.runtime.linux.runc.image-toplevel-dir":"/runc-root","yarn.nodemanager.linux-container-executor.cgroups.hierarchy":"/hadoop-yarn","fs.AbstractFileSystem.wasbs.impl":"org.apache.hadoop.fs.azure.Wasbs","yarn.timeline-service.entity-group-fs-store.cache-store-class":"org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore","yarn.nodemanager.runtime.linux.runc.allowed-container-networks":"host,none,bridge","fs.ftp.transfer.mode":"BLOCK_TRANSFER_MODE","ipc.server.log.slow.rpc":"false","ipc.server.reuseaddr":"true","fs.ftp.timeout":"0","yarn.resourcemanager.node-labels.provider.fetch-interval-ms":"1800000","yarn.router.webapp.https.address":"0.0.0.0:8091","yarn.nodemanager.webapp.cross-origin.enabled":"false","fs.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","yarn.resourcemanager.auto-update.containers":"false","yarn.app.mapreduce.am.job.committer.cancel-timeout":"60000","yarn.scheduler.configuration.zk-store.parent-path":"/confstore","yarn.nodemanager.default-container-executor.log-dirs.permissions":"710","yarn.app.attempt.diagnostics.limit.kc":"64","fs.viewfs.overload.scheme.target.swebhdfs.impl":"org.apache.hadoop.hdfs.web.SWebHdfsFileSystem","yarn.client.failover-no-ha-proxy-provider":"org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider","fs.s3a.change.detection.mode":"server","ftp.bytes-per-checksum":"512","yarn.nodemanager.resource.memory-mb":"-1","fs.AbstractFileSystem.abfs.impl":"org.apache.hadoop.fs.azurebfs.Abfs","yarn.timeline-service.writer.flush-interval-seconds":"60","fs.s3a.fast.upload.active.blocks":"4","yarn.resourcemanager.submission-preprocessor.enabled":"false","hadoop.security.credential.clear-text-fallback":"true","yarn.nodemanager.collector-service.thread-count":"5","ipc.[port_number].scheduler.impl":"org.apache.hadoop.ipc.DefaultRpcScheduler","fs.azure.secure.mode":"false","mapreduce.jobhistory.joblist.cache.size":"20000","fs.ftp.host":"0.0.0.0","yarn.timeline-service.writer.async.queue.capacity":"100","yarn.resourcemanager.fs.state-store.num-retries":"0","yarn.resourcemanager.nodemanager-connect-retries":"10","yarn.nodemanager.log-aggregation.num-log-files-per-app":"30","hadoop.security.kms.client.encrypted.key.cache.low-watermark":"0.3f","fs.s3a.committer.magic.enabled":"true","yarn.timeline-service.client.max-retries":"30","dfs.ha.fencing.ssh.connect-timeout":"30000","yarn.log-aggregation-enable":"false","yarn.system-metrics-publisher.enabled":"false","mapreduce.reduce.markreset.buffer.percent":"0.0","fs.AbstractFileSystem.viewfs.impl":"org.apache.hadoop.fs.viewfs.ViewFs","yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor":"1.0","mapreduce.task.io.sort.factor":"10","yarn.nodemanager.amrmproxy.client.thread-count":"25","ha.failover-controller.new-active.rpc-timeout.ms":"60000","yarn.nodemanager.container-localizer.java.opts":"-Xmx256m","mapreduce.jobhistory.datestring.cache.size":"200000","mapreduce.job.acl-modify-job":" ","yarn.nodemanager.windows-container.memory-limit.enabled":"false","yarn.timeline-service.webapp.address":"${yarn.timeline-service.hostname}:8188","yarn.app.mapreduce.am.job.committer.commit-window":"10000","yarn.nodemanager.container-manager.thread-count":"20","yarn.minicluster.fixed.ports":"false","hadoop.tags.system":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.cluster.max-application-priority":"0","yarn.timeline-service.ttl-enable":"true","mapreduce.jobhistory.recovery.store.fs.uri":"${hadoop.tmp.dir}/mapred/history/recoverystore","hadoop.caller.context.signature.max.size":"40","ipc.[port_number].decay-scheduler.backoff.responsetime.enable":"false","yarn.client.load.resource-types.from-server":"false","ha.zookeeper.session-timeout.ms":"10000","ipc.[port_number].decay-scheduler.metrics.top.user.count":"10","tfile.io.chunk.size":"1048576","fs.s3a.s3guard.ddb.table.capacity.write":"0","yarn.dispatcher.print-events-info.threshold":"5000","mapreduce.job.speculative.slowtaskthreshold":"1.0","io.serializations":"org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization","hadoop.security.kms.client.failover.sleep.max.millis":"2000","hadoop.security.group.mapping.ldap.directory.search.timeout":"10000","yarn.scheduler.configuration.store.max-logs":"1000","yarn.nodemanager.node-attributes.provider.fetch-interval-ms":"600000","fs.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","yarn.nodemanager.local-cache.max-files-per-directory":"8192","hadoop.http.cross-origin.enabled":"false","hadoop.zk.acl":"world:anyone:rwcda","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache":"10","mapreduce.map.sort.spill.percent":"0.80","yarn.timeline-service.entity-group-fs-store.scan-interval-seconds":"60","yarn.node-attribute.fs-store.impl.class":"org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore","fs.s3a.retry.interval":"500ms","yarn.timeline-service.client.best-effort":"false","yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled":"*********(redacted)","hadoop.security.group.mapping.ldap.posix.attr.uid.name":"uidNumber","fs.AbstractFileSystem.swebhdfs.impl":"org.apache.hadoop.fs.SWebHdfs","yarn.nodemanager.elastic-memory-control.timeout-sec":"5","fs.s3a.select.enabled":"true","mapreduce.ifile.readahead":"true","yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms":"300000","yarn.timeline-service.reader.webapp.address":"${yarn.timeline-service.webapp.address}","yarn.resourcemanager.placement-constraints.algorithm.pool-size":"1","yarn.timeline-service.hbase.coprocessor.jar.hdfs.location":"/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar","hadoop.security.kms.client.encrypted.key.cache.num.refill.threads":"2","yarn.resourcemanager.scheduler.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler","yarn.app.mapreduce.am.command-opts":"-Xmx1024m","fs.s3a.metadatastore.fail.on.write.error":"true","hadoop.http.sni.host.check.enabled":"false","mapreduce.cluster.local.dir":"${hadoop.tmp.dir}/mapred/local","io.mapfile.bloom.error.rate":"0.005","fs.client.resolve.topology.enabled":"false","yarn.nodemanager.runtime.linux.allowed-runtimes":"default","yarn.sharedcache.store.class":"org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore","ha.failover-controller.graceful-fence.rpc-timeout.ms":"5000","ftp.replication":"3","fs.getspaceused.jitterMillis":"60000","hadoop.security.uid.cache.secs":"14400","mapreduce.job.maxtaskfailures.per.tracker":"3","fs.s3a.metadatastore.impl":"org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore","io.skip.checksum.errors":"false","yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts":"3","yarn.timeline-service.webapp.xfs-filter.xframe-options":"SAMEORIGIN","fs.s3a.connection.timeout":"200000","yarn.app.mapreduce.am.webapp.https.enabled":"false","mapreduce.job.max.split.locations":"15","yarn.resourcemanager.nm-container-queuing.max-queue-length":"15","yarn.resourcemanager.delegation-token.always-cancel":"*********(redacted)","hadoop.registry.zk.session.timeout.ms":"60000","yarn.federation.cache-ttl.secs":"300","mapreduce.jvm.system-properties-to-log":"os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name","yarn.resourcemanager.opportunistic-container-allocation.nodes-used":"10","yarn.timeline-service.entity-group-fs-store.active-dir":"/tmp/entity-file-history/active","mapreduce.shuffle.transfer.buffer.size":"131072","yarn.timeline-service.client.retry-interval-ms":"1000","yarn.timeline-service.flowname.max-size":"0","yarn.http.policy":"HTTP_ONLY","fs.s3a.socket.send.buffer":"8192","fs.AbstractFileSystem.abfss.impl":"org.apache.hadoop.fs.azurebfs.Abfss","yarn.sharedcache.uploader.server.address":"0.0.0.0:8046","yarn.resourcemanager.delegation-token.max-conf-size-bytes":"*********(redacted)","hadoop.http.authentication.token.validity":"*********(redacted)","mapreduce.shuffle.max.connections":"0","yarn.minicluster.yarn.nodemanager.resource.memory-mb":"4096","mapreduce.job.emit-timeline-data":"false","yarn.nodemanager.resource.system-reserved-memory-mb":"-1","hadoop.kerberos.min.seconds.before.relogin":"60","mapreduce.jobhistory.move.thread-count":"3","yarn.resourcemanager.admin.client.thread-count":"1","yarn.dispatcher.drain-events.timeout":"300000","ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds":"10s,20s,30s,40s","fs.s3a.buffer.dir":"${hadoop.tmp.dir}/s3a","hadoop.ssl.enabled.protocols":"TLSv1.2","mapreduce.jobhistory.admin.address":"0.0.0.0:10033","yarn.log-aggregation-status.time-out.ms":"600000","fs.s3a.accesspoint.required":"false","mapreduce.shuffle.port":"13562","yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory":"10","yarn.nodemanager.health-checker.interval-ms":"600000","yarn.router.clientrm.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor","yarn.resourcemanager.zk-appid-node.split-index":"0","ftp.blocksize":"67108864","yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions":"read","yarn.router.rmadmin.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor","yarn.nodemanager.log-container-debug-info.enabled":"true","yarn.resourcemanager.activities-manager.app-activities.max-queue-length":"100","yarn.resourcemanager.application-https.policy":"NONE","yarn.client.max-cached-nodemanagers-proxies":"0","yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms":"20","yarn.nodemanager.delete.debug-delay-sec":"0","yarn.nodemanager.pmem-check-enabled":"true","yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage":"90.0","mapreduce.app-submission.cross-platform":"false","yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms":"10000","yarn.nodemanager.container-retry-minimum-interval-ms":"1000","hadoop.security.groups.cache.secs":"300","yarn.federation.enabled":"false","yarn.workflow-id.tag-prefix":"workflowid:","fs.azure.local.sas.key.mode":"false","ipc.maximum.data.length":"134217728","fs.s3a.endpoint":"s3.amazonaws.com","mapreduce.shuffle.max.threads":"0","yarn.router.pipeline.cache-max-size":"25","yarn.resourcemanager.nm-container-queuing.load-comparator":"QUEUE_LENGTH","yarn.resourcemanager.resource-tracker.nm.ip-hostname-check":"false","hadoop.security.authorization":"false","mapreduce.job.complete.cancel.delegation.tokens":"*********(redacted)","fs.s3a.paging.maximum":"5000","nfs.exports.allowed.hosts":"* rw","yarn.nodemanager.amrmproxy.ha.enable":"false","fs.AbstractFileSystem.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","mapreduce.jobhistory.http.policy":"HTTP_ONLY","yarn.sharedcache.store.in-memory.check-period-mins":"720","hadoop.security.group.mapping.ldap.ssl":"false","fs.s3a.downgrade.syncable.exceptions":"true","yarn.client.application-client-protocol.poll-interval-ms":"200","yarn.scheduler.configuration.leveldb-store.compaction-interval-secs":"86400","yarn.timeline-service.writer.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl","ha.zookeeper.parent-znode":"/hadoop-ha","yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms":"60000","yarn.nodemanager.log-aggregation.policy.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy","mapreduce.reduce.shuffle.merge.percent":"0.66","hadoop.security.group.mapping.ldap.search.filter.group":"(objectClass=group)","yarn.resourcemanager.placement-constraints.scheduler.pool-size":"1","yarn.resourcemanager.activities-manager.cleanup-interval-ms":"5000","yarn.nodemanager.resourcemanager.minimum.version":"NONE","mapreduce.job.speculative.speculative-cap-running-tasks":"0.1","yarn.admin.acl":"*","ipc.[port_number].identity-provider.impl":"org.apache.hadoop.ipc.UserIdentityProvider","yarn.nodemanager.recovery.supervised":"false","yarn.sharedcache.admin.thread-count":"1","yarn.resourcemanager.ha.automatic-failover.enabled":"true","yarn.nodemanager.container-log-monitor.total-size-limit-bytes":"10000000000","mapreduce.reduce.skip.maxgroups":"0","mapreduce.reduce.shuffle.connect.timeout":"180000","yarn.nodemanager.health-checker.scripts":"script","yarn.resourcemanager.address":"${yarn.resourcemanager.hostname}:8032","ipc.client.ping":"true","mapreduce.task.local-fs.write-limit.bytes":"-1","fs.adl.oauth2.access.token.provider.type":"*********(redacted)","mapreduce.shuffle.ssl.file.buffer.size":"65536","yarn.resourcemanager.ha.automatic-failover.embedded":"true","yarn.nodemanager.resource-plugins.gpu.docker-plugin":"nvidia-docker-v1","fs.s3a.s3guard.consistency.retry.interval":"2s","fs.s3a.multipart.purge":"false","yarn.scheduler.configuration.store.class":"file","yarn.resourcemanager.nm-container-queuing.queue-limit-stdev":"1.0f","mapreduce.job.end-notification.max.attempts":"5","mapreduce.output.fileoutputformat.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled":"false","ipc.client.bind.wildcard.addr":"false","yarn.resourcemanager.webapp.rest-csrf.enabled":"false","ha.health-monitor.connect-retry-interval.ms":"1000","yarn.nodemanager.keytab":"/etc/krb5.keytab","mapreduce.jobhistory.keytab":"/etc/security/keytab/jhs.service.keytab","fs.s3a.threads.max":"64","yarn.nodemanager.runtime.linux.docker.image-update":"false","mapreduce.reduce.shuffle.input.buffer.percent":"0.70","fs.viewfs.overload.scheme.target.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","yarn.dispatcher.cpu-monitor.samples-per-min":"60","hadoop.security.token.service.use_ip":"*********(redacted)","yarn.nodemanager.runtime.linux.docker.allowed-container-networks":"host,none,bridge","yarn.nodemanager.node-labels.resync-interval-ms":"120000","hadoop.tmp.dir":"/tmp/hadoop-${user.name}","mapreduce.job.maps":"2","mapreduce.jobhistory.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.job.end-notification.max.retry.interval":"5000","yarn.log-aggregation.retain-check-interval-seconds":"-1","yarn.resourcemanager.resource-tracker.client.thread-count":"50","yarn.nodemanager.containers-launcher.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher","yarn.rm.system-metrics-publisher.emit-container-events":"false","yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size":"10000","yarn.resourcemanager.ha.automatic-failover.zk-base-path":"/yarn-leader-election","io.seqfile.local.dir":"${hadoop.tmp.dir}/io/local","fs.s3a.s3guard.ddb.throttle.retry.interval":"100ms","fs.AbstractFileSystem.wasb.impl":"org.apache.hadoop.fs.azure.Wasb","mapreduce.client.submit.file.replication":"10","mapreduce.jobhistory.minicluster.fixed.ports":"false","fs.s3a.multipart.threshold":"128M","yarn.resourcemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","mapreduce.jobhistory.done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done","ipc.server.purge.interval":"15","ipc.client.idlethreshold":"4000","yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage":"false","mapreduce.reduce.input.buffer.percent":"0.0","yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold":"1","yarn.nodemanager.webapp.rest-csrf.enabled":"false","fs.ftp.host.port":"21","ipc.ping.interval":"60000","yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size":"10","yarn.resourcemanager.admin.address":"${yarn.resourcemanager.hostname}:8033","file.client-write-packet-size":"65536","ipc.client.kill.max":"10","mapreduce.reduce.speculative":"true","hadoop.security.key.default.bitlength":"128","mapreduce.job.reducer.unconditional-preempt.delay.sec":"300","yarn.nodemanager.disk-health-checker.interval-ms":"120000","yarn.nodemanager.log.deletion-threads-count":"4","fs.s3a.committer.abort.pending.uploads":"true","yarn.webapp.filter-entity-list-by-user":"false","yarn.resourcemanager.activities-manager.app-activities.ttl-ms":"600000","ipc.client.connection.maxidletime":"10000","mapreduce.task.io.sort.mb":"100","yarn.nodemanager.localizer.client.thread-count":"5","io.erasurecode.codec.rs.rawcoders":"rs_native,rs_java","io.erasurecode.codec.rs-legacy.rawcoders":"rs-legacy_java","yarn.sharedcache.admin.address":"0.0.0.0:8047","yarn.resourcemanager.placement-constraints.algorithm.iterator":"SERIAL","yarn.nodemanager.localizer.cache.cleanup.interval-ms":"600000","hadoop.security.crypto.codec.classes.aes.ctr.nopadding":"org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec","mapreduce.job.cache.limit.max-resources-mb":"0","fs.s3a.connection.ssl.enabled":"true","yarn.nodemanager.process-kill-wait.ms":"5000","mapreduce.job.hdfs-servers":"${fs.defaultFS}","yarn.app.mapreduce.am.webapp.https.client.auth":"false","hadoop.workaround.non.threadsafe.getpwuid":"true","fs.df.interval":"60000","ipc.[port_number].decay-scheduler.thresholds":"13,25,50","fs.s3a.multiobjectdelete.enable":"true","yarn.sharedcache.cleaner.resource-sleep-ms":"0","yarn.nodemanager.disk-health-checker.min-healthy-disks":"0.25","hadoop.shell.missing.defaultFs.warning":"false","io.file.buffer.size":"65536","fs.viewfs.overload.scheme.target.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","hadoop.security.group.mapping.ldap.search.attr.member":"member","hadoop.security.random.device.file.path":"/dev/urandom","hadoop.security.sensitive-config-keys":"*********(redacted)","fs.s3a.s3guard.ddb.max.retries":"9","fs.viewfs.overload.scheme.target.file.impl":"org.apache.hadoop.fs.LocalFileSystem","hadoop.rpc.socket.factory.class.default":"org.apache.hadoop.net.StandardSocketFactory","yarn.intermediate-data-encryption.enable":"false","yarn.resourcemanager.connect.retry-interval.ms":"30000","yarn.nodemanager.container.stderr.pattern":"{*stderr*,*STDERR*}","yarn.scheduler.minimum-allocation-mb":"1024","yarn.app.mapreduce.am.staging-dir":"/tmp/hadoop-yarn/staging","mapreduce.reduce.shuffle.read.timeout":"180000","hadoop.http.cross-origin.max-age":"1800","io.erasurecode.codec.xor.rawcoders":"xor_native,xor_java","fs.s3a.s3guard.consistency.retry.limit":"7","fs.s3a.connection.establish.timeout":"5000","mapreduce.job.running.map.limit":"0","yarn.minicluster.control-resource-monitoring":"false","hadoop.ssl.require.client.cert":"false","hadoop.kerberos.kinit.command":"kinit","yarn.federation.state-store.class":"org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore","mapreduce.reduce.log.level":"INFO","hadoop.security.dns.log-slow-lookups.threshold.ms":"1000","mapreduce.job.ubertask.enable":"false","adl.http.timeout":"-1","yarn.resourcemanager.placement-constraints.retry-attempts":"3","hadoop.caller.context.enabled":"false","hadoop.security.group.mapping.ldap.num.attempts":"3","yarn.nodemanager.vmem-pmem-ratio":"2.1","hadoop.rpc.protection":"authentication","ha.health-monitor.rpc-timeout.ms":"45000","yarn.nodemanager.remote-app-log-dir":"/tmp/logs","hadoop.zk.timeout-ms":"10000","fs.s3a.s3guard.cli.prune.age":"86400000","yarn.nodemanager.resource.pcores-vcores-multiplier":"1.0","yarn.nodemanager.runtime.linux.sandbox-mode":"disabled","yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size":"10","fs.viewfs.overload.scheme.target.webhdfs.impl":"org.apache.hadoop.hdfs.web.WebHdfsFileSystem","fs.s3a.committer.threads":"8","hadoop.zk.retry-interval-ms":"1000","hadoop.security.crypto.buffer.size":"8192","yarn.nodemanager.node-labels.provider.fetch-interval-ms":"600000","mapreduce.jobhistory.recovery.store.leveldb.path":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.client.failover-retries-on-socket-timeouts":"0","fs.s3a.ssl.channel.mode":"default_jsse","yarn.nodemanager.resource.memory.enabled":"false","fs.azure.authorization.caching.enable":"true","hadoop.security.instrumentation.requires.admin":"false","yarn.nodemanager.delete.thread-count":"4","mapreduce.job.finish-when-all-reducers-done":"true","hadoop.registry.jaas.context":"Client","yarn.timeline-service.leveldb-timeline-store.path":"${hadoop.tmp.dir}/yarn/timeline","io.map.index.interval":"128","yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms":"100","fs.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","mapreduce.job.counters.max":"120","mapreduce.jobhistory.webapp.rest-csrf.enabled":"false","yarn.timeline-service.store-class":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.jobhistory.move.interval-ms":"180000","fs.s3a.change.detection.version.required":"true","yarn.nodemanager.localizer.fetch.thread-count":"4","yarn.resourcemanager.scheduler.client.thread-count":"50","hadoop.ssl.hostname.verifier":"DEFAULT","yarn.timeline-service.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/timeline","mapreduce.job.classloader":"false","mapreduce.task.profile.map.params":"${mapreduce.task.profile.params}","ipc.client.connect.timeout":"20000","hadoop.security.auth_to_local.mechanism":"hadoop","yarn.timeline-service.app-collector.linger-period.ms":"60000","yarn.nm.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.reservation-system.planfollower.time-step":"1000","yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms":"600000","yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed":"true","yarn.webapp.api-service.enable":"false","yarn.nodemanager.recovery.enabled":"false","mapreduce.job.end-notification.retry.interval":"1000","fs.du.interval":"600000","fs.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","yarn.nodemanager.container.stderr.tail.bytes":"4096","yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled":"true","hadoop.security.group.mapping.ldap.read.timeout.ms":"60000","hadoop.security.groups.cache.warn.after.ms":"5000","file.bytes-per-checksum":"512","mapreduce.outputcommitter.factory.scheme.s3a":"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory","hadoop.security.groups.cache.background.reload":"false","yarn.nodemanager.container-monitor.enabled":"true","yarn.nodemanager.elastic-memory-control.enabled":"false","net.topology.script.number.args":"100","mapreduce.task.merge.progress.records":"10000","yarn.nodemanager.localizer.address":"${yarn.nodemanager.hostname}:8040","yarn.timeline-service.keytab":"/etc/krb5.keytab","mapreduce.reduce.shuffle.fetch.retry.timeout-ms":"30000","yarn.resourcemanager.rm.container-allocation.expiry-interval-ms":"600000","yarn.nodemanager.container-executor.exit-code-file.timeout-ms":"2000","mapreduce.fileoutputcommitter.algorithm.version":"1","yarn.resourcemanager.work-preserving-recovery.enabled":"true","mapreduce.map.skip.maxrecords":"0","yarn.sharedcache.root-dir":"/sharedcache","fs.s3a.retry.throttle.limit":"20","hadoop.http.authentication.type":"simple","fs.viewfs.overload.scheme.target.oss.impl":"org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem","mapreduce.job.cache.limit.max-resources":"0","mapreduce.task.userlog.limit.kb":"0","ipc.[port_number].weighted-cost.handler":"1","yarn.resourcemanager.scheduler.monitor.enable":"false","ipc.client.connect.max.retries":"10","hadoop.registry.zk.retry.times":"5","yarn.nodemanager.resource-monitor.interval-ms":"3000","yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices":"auto","mapreduce.job.sharedcache.mode":"disabled","yarn.nodemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.shuffle.listen.queue.size":"128","yarn.scheduler.configuration.mutation.acl-policy.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy","mapreduce.map.cpu.vcores":"1","yarn.log-aggregation.file-formats":"TFile","yarn.timeline-service.client.fd-retain-secs":"300","fs.s3a.select.output.csv.field.delimiter":",","yarn.nodemanager.health-checker.timeout-ms":"1200000","hadoop.user.group.static.mapping.overrides":"dr.who=;","fs.azure.sas.expiry.period":"90d","fs.s3a.select.output.csv.record.delimiter":"\\n","mapreduce.jobhistory.recovery.store.class":"org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService","fs.viewfs.overload.scheme.target.https.impl":"org.apache.hadoop.fs.http.HttpsFileSystem","fs.s3a.s3guard.ddb.table.sse.enabled":"false","yarn.resourcemanager.fail-fast":"${yarn.fail-fast}","yarn.resourcemanager.proxy-user-privileges.enabled":"false","yarn.router.webapp.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST","yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage":"90.0","mapreduce.job.reducer.preempt.delay.sec":"0","hadoop.util.hash.type":"murmur","yarn.nodemanager.disk-validator":"basic","yarn.app.mapreduce.client.job.max-retries":"3","fs.viewfs.overload.scheme.target.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","mapreduce.reduce.shuffle.retry-delay.max.ms":"60000","hadoop.security.group.mapping.ldap.connection.timeout.ms":"60000","mapreduce.task.profile.params":"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s","yarn.app.mapreduce.shuffle.log.backups":"0","yarn.nodemanager.container-diagnostics-maximum-size":"10000","hadoop.registry.zk.retry.interval.ms":"1000","yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms":"1000","fs.AbstractFileSystem.file.impl":"org.apache.hadoop.fs.local.LocalFs","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds":"-1","mapreduce.jobhistory.cleaner.interval-ms":"86400000","hadoop.registry.zk.quorum":"localhost:2181","yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes":"runc","mapreduce.output.fileoutputformat.compress":"false","yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs":"*********(redacted)","fs.s3a.assumed.role.session.duration":"30m","hadoop.security.group.mapping.ldap.conversion.rule":"none","hadoop.ssl.server.conf":"ssl-server.xml","fs.s3a.retry.throttle.interval":"100ms","seq.io.sort.factor":"100","fs.viewfs.overload.scheme.target.ofs.impl":"org.apache.hadoop.fs.ozone.RootedOzoneFileSystem","yarn.sharedcache.cleaner.initial-delay-mins":"10","mapreduce.client.completion.pollinterval":"5000","hadoop.ssl.keystores.factory.class":"org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory","yarn.app.mapreduce.am.resource.cpu-vcores":"1","yarn.timeline-service.enabled":"false","yarn.nodemanager.runtime.linux.docker.capabilities":"CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE","yarn.acl.enable":"false","yarn.timeline-service.entity-group-fs-store.done-dir":"/tmp/entity-file-history/done/","hadoop.security.group.mapping.ldap.num.attempts.before.failover":"3","mapreduce.task.profile":"false","hadoop.prometheus.endpoint.enabled":"false","yarn.resourcemanager.fs.state-store.uri":"${hadoop.tmp.dir}/yarn/system/rmstore","mapreduce.jobhistory.always-scan-user-dir":"false","fs.s3a.metadatastore.metadata.ttl":"15m","yarn.nodemanager.opportunistic-containers-use-pause-for-preemption":"false","yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user":"nobody","yarn.timeline-service.reader.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl","yarn.resourcemanager.configuration.provider-class":"org.apache.hadoop.yarn.LocalConfigurationProvider","yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold":"1","yarn.resourcemanager.configuration.file-system-based-store":"/yarn/conf","mapreduce.job.cache.limit.max-single-resource-mb":"0","yarn.nodemanager.runtime.linux.docker.stop.grace-period":"10","yarn.resourcemanager.resource-profiles.source-file":"resource-profiles.json","mapreduce.job.dfs.storage.capacity.kill-limit-exceed":"false","yarn.nodemanager.resource.percentage-physical-cpu-limit":"100","mapreduce.jobhistory.client.thread-count":"10","tfile.fs.input.buffer.size":"262144","mapreduce.client.progressmonitor.pollinterval":"1000","yarn.nodemanager.log-dirs":"${yarn.log.dir}/userlogs","yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat":"-1","fs.automatic.close":"true","yarn.resourcemanager.delegation-token-renewer.thread-retry-interval":"*********(redacted)","fs.s3a.select.input.csv.quote.character":"\"","yarn.nodemanager.hostname":"0.0.0.0","ipc.[port_number].cost-provider.impl":"org.apache.hadoop.ipc.DefaultCostProvider","yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin","yarn.nodemanager.remote-app-log-dir-include-older":"true","yarn.nodemanager.resource.memory.cgroups.swappiness":"0","ftp.stream-buffer-size":"4096","yarn.fail-fast":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep":"100","yarn.timeline-service.app-aggregation-interval-secs":"15","hadoop.security.group.mapping.ldap.search.filter.user":"(&(objectClass=user)(sAMAccountName={0}))","ipc.[port_number].weighted-cost.lockshared":"10","yarn.nodemanager.container-localizer.log.level":"INFO","yarn.timeline-service.address":"${yarn.timeline-service.hostname}:10200","mapreduce.job.ubertask.maxmaps":"9","fs.s3a.threads.keepalivetime":"60","mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.task.files.preserve.failedtasks":"false","yarn.app.mapreduce.client.job.retry-interval":"2000","ha.failover-controller.graceful-fence.connection.retries":"1","fs.s3a.select.output.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.max-lifetime":"*********(redacted)","hadoop.kerberos.keytab.login.autorenewal.enabled":"false","yarn.timeline-service.client.drain-entities.timeout.ms":"2000","yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin","yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms":"1000","yarn.timeline-service.entity-group-fs-store.summary-store":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.reduce.cpu.vcores":"1","mapreduce.job.encrypted-intermediate-data.buffer.kb":"128","fs.client.resolve.remote.symlinks":"true","yarn.nodemanager.webapp.https.address":"0.0.0.0:8044","hadoop.http.cross-origin.allowed-origins":"*","mapreduce.job.encrypted-intermediate-data":"false","yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled":"true","fs.s3a.executor.capacity":"16","yarn.timeline-service.entity-group-fs-store.retain-seconds":"604800","yarn.resourcemanager.metrics.runtime.buckets":"60,300,1440","yarn.timeline-service.generic-application-history.max-applications":"10000","yarn.nodemanager.local-dirs":"${hadoop.tmp.dir}/nm-local-dir","mapreduce.shuffle.connection-keep-alive.enable":"false","yarn.node-labels.configuration-type":"centralized","fs.s3a.path.style.access":"false","yarn.nodemanager.aux-services.mapreduce_shuffle.class":"org.apache.hadoop.mapred.ShuffleHandler","yarn.sharedcache.store.in-memory.staleness-period-mins":"10080","fs.adl.impl":"org.apache.hadoop.fs.adl.AdlFileSystem","yarn.resourcemanager.application.max-tags":"10","hadoop.domainname.resolver.impl":"org.apache.hadoop.net.DNSDomainNameResolver","yarn.resourcemanager.nodemanager.minimum.version":"NONE","mapreduce.jobhistory.webapp.xfs-filter.xframe-options":"SAMEORIGIN","yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled":"false","net.topology.impl":"org.apache.hadoop.net.NetworkTopology","io.map.index.skip":"0","yarn.timeline-service.reader.webapp.https.address":"${yarn.timeline-service.webapp.https.address}","fs.ftp.data.connection.mode":"ACTIVE_LOCAL_DATA_CONNECTION_MODE","mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed":"true","fs.azure.buffer.dir":"${hadoop.tmp.dir}/abfs","yarn.scheduler.maximum-allocation-vcores":"4","hadoop.http.cross-origin.allowed-headers":"X-Requested-With,Content-Type,Accept,Origin","yarn.nodemanager.log-aggregation.compression-type":"none","yarn.timeline-service.version":"1.0f","yarn.ipc.rpc.class":"org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC","mapreduce.reduce.maxattempts":"4","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size":"1000","hadoop.security.dns.log-slow-lookups.enabled":"false","mapreduce.job.committer.setup.cleanup.needed":"true","hadoop.security.secure.random.impl":"org.apache.hadoop.crypto.random.OpensslSecureRandom","mapreduce.job.running.reduce.limit":"0","fs.s3a.select.errors.include.sql":"false","fs.s3a.connection.request.timeout":"0","ipc.maximum.response.length":"134217728","yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.job.token.tracking.ids.enabled":"*********(redacted)","hadoop.caller.context.max.size":"128","yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed":"false","yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed":"false","hadoop.registry.system.acls":"sasl:yarn@, sasl:mapred@, sasl:hdfs@","yarn.nodemanager.recovery.dir":"${hadoop.tmp.dir}/yarn-nm-recovery","fs.s3a.fast.upload.buffer":"disk","mapreduce.jobhistory.intermediate-done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate","yarn.app.mapreduce.shuffle.log.separate":"true","yarn.log-aggregation.debug.filesize":"104857600","fs.s3a.max.total.tasks":"32","fs.s3a.readahead.range":"64K","hadoop.http.authentication.simple.anonymous.allowed":"true","fs.s3a.attempts.maximum":"20","hadoop.registry.zk.connection.timeout.ms":"15000","yarn.resourcemanager.delegation-token-renewer.thread-count":"*********(redacted)","yarn.resourcemanager.delegation-token-renewer.thread-timeout":"*********(redacted)","yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size":"10000","yarn.nodemanager.aux-services.manifest.reload-ms":"0","yarn.nodemanager.emit-container-events":"true","yarn.resourcemanager.resource-profiles.enabled":"false","yarn.timeline-service.hbase-schema.prefix":"prod.","fs.azure.authorization":"false","mapreduce.map.log.level":"INFO","ha.failover-controller.active-standby-elector.zk.op.retries":"3","yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs":"20","mapreduce.output.fileoutputformat.compress.type":"RECORD","yarn.resourcemanager.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/system/rmstore","yarn.timeline-service.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.ifile.readahead.bytes":"4194304","yarn.sharedcache.app-checker.class":"org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker","yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users":"true","yarn.nodemanager.resource.detect-hardware-capabilities":"false","mapreduce.cluster.acls.enabled":"false","mapreduce.job.speculative.retry-after-no-speculate":"1000","fs.viewfs.overload.scheme.target.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","hadoop.security.group.mapping.ldap.search.group.hierarchy.levels":"0","yarn.resourcemanager.fs.state-store.retry-interval-ms":"1000","file.stream-buffer-size":"4096","yarn.resourcemanager.application-timeouts.monitor.interval-ms":"3000","mapreduce.map.output.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","mapreduce.map.speculative":"true","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file":"/runc-root/image-tag-to-hash","mapreduce.job.speculative.retry-after-speculate":"15000","yarn.nodemanager.linux-container-executor.cgroups.mount":"false","yarn.app.mapreduce.am.container.log.backups":"0","yarn.app.mapreduce.am.log.level":"INFO","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin","io.bytes.per.checksum":"512","mapreduce.job.reduce.slowstart.completedmaps":"0.05","yarn.timeline-service.http-authentication.type":"simple","hadoop.security.group.mapping.ldap.search.attr.group.name":"cn","yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices":"auto","yarn.timeline-service.client.internal-timers-ttl-secs":"420","fs.s3a.select.output.csv.quote.character":"\"","hadoop.http.logs.enabled":"true","fs.s3a.block.size":"32M","yarn.sharedcache.client-server.address":"0.0.0.0:8045","yarn.nodemanager.logaggregation.threadpool-size-max":"100","yarn.resourcemanager.hostname":"0.0.0.0","yarn.resourcemanager.delegation.key.update-interval":"86400000","mapreduce.reduce.shuffle.fetch.retry.enabled":"${yarn.nodemanager.recovery.enabled}","mapreduce.map.memory.mb":"-1","mapreduce.task.skip.start.attempts":"2","fs.AbstractFileSystem.hdfs.impl":"org.apache.hadoop.fs.Hdfs","yarn.nodemanager.disk-health-checker.enable":"true","fs.s3a.select.output.csv.quote.fields":"always","ipc.client.tcpnodelay":"true","ipc.client.rpc-timeout.ms":"0","yarn.nodemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts":"*********(redacted)","ipc.client.low-latency":"false","mapreduce.input.lineinputformat.linespermap":"1","yarn.router.interceptor.user.threadpool-size":"5","ipc.client.connect.max.retries.on.timeouts":"45","yarn.timeline-service.leveldb-timeline-store.read-cache-size":"104857600","fs.AbstractFileSystem.har.impl":"org.apache.hadoop.fs.HarFs","mapreduce.job.split.metainfo.maxsize":"10000000","yarn.am.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.timeline-service.entity-group-fs-store.app-cache-size":"10","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs":"360","fs.s3a.socket.recv.buffer":"8192","rpc.metrics.timeunit":"MILLISECONDS","yarn.resourcemanager.resource-tracker.address":"${yarn.resourcemanager.hostname}:8031","yarn.nodemanager.node-labels.provider.fetch-timeout-ms":"1200000","mapreduce.job.heap.memory-mb.ratio":"0.8","yarn.resourcemanager.leveldb-state-store.compaction-interval-secs":"3600","yarn.resourcemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","yarn.nodemanager.pluggable-device-framework.enabled":"false","yarn.scheduler.configuration.fs.path":"file://${hadoop.tmp.dir}/yarn/system/schedconf","mapreduce.client.output.filter":"FAILED","hadoop.http.filter.initializers":"org.apache.hadoop.http.lib.StaticUserWebFilter","mapreduce.reduce.memory.mb":"-1","yarn.timeline-service.hostname":"0.0.0.0","file.replication":"1","yarn.nodemanager.container-metrics.unregister-delay-ms":"10000","yarn.nodemanager.container-metrics.period-ms":"-1","mapreduce.fileoutputcommitter.task.cleanup.enabled":"false","yarn.nodemanager.log.retain-seconds":"10800","yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds":"3600","ipc.[port_number].callqueue.impl":"java.util.concurrent.LinkedBlockingQueue","yarn.resourcemanager.keytab":"/etc/krb5.keytab","hadoop.security.group.mapping.providers.combined":"true","mapreduce.reduce.merge.inmem.threshold":"1000","yarn.timeline-service.recovery.enabled":"false","fs.azure.saskey.usecontainersaskeyforallaccess":"true","yarn.sharedcache.nm.uploader.thread-count":"20","yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs":"3600","ipc.[port_number].weighted-cost.lockfree":"1","mapreduce.shuffle.ssl.enabled":"false","yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds":"259200000","yarn.nodemanager.opportunistic-containers-max-queue-length":"0","yarn.resourcemanager.state-store.max-completed-applications":"${yarn.resourcemanager.max-completed-applications}","mapreduce.job.speculative.minimum-allowed-tasks":"10","fs.s3a.aws.credentials.provider":"\n    org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,\n    org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,\n    com.amazonaws.auth.EnvironmentVariableCredentialsProvider,\n    org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider\n  ","yarn.log-aggregation.retain-seconds":"-1","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb":"0","mapreduce.jobhistory.max-age-ms":"604800000","hadoop.http.cross-origin.allowed-methods":"GET,POST,HEAD","yarn.resourcemanager.opportunistic-container-allocation.enabled":"false","mapreduce.jobhistory.webapp.address":"0.0.0.0:19888","hadoop.system.tags":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.log-aggregation.file-controller.TFile.class":"org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController","yarn.client.nodemanager-connect.max-wait-ms":"180000","yarn.resourcemanager.webapp.address":"${yarn.resourcemanager.hostname}:8088","mapreduce.jobhistory.recovery.enable":"false","mapreduce.reduce.shuffle.parallelcopies":"5","fs.AbstractFileSystem.webhdfs.impl":"org.apache.hadoop.fs.WebHdfs","fs.trash.interval":"0","yarn.app.mapreduce.client.max-retries":"3","hadoop.security.authentication":"simple","mapreduce.task.profile.reduce.params":"${mapreduce.task.profile.params}","yarn.app.mapreduce.am.resource.mb":"1536","mapreduce.input.fileinputformat.list-status.num-threads":"1","yarn.nodemanager.container-executor.class":"org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor","io.mapfile.bloom.size":"1048576","yarn.timeline-service.ttl-ms":"604800000","yarn.resourcemanager.nm-container-queuing.min-queue-length":"5","yarn.nodemanager.resource.cpu-vcores":"-1","mapreduce.job.reduces":"1","fs.s3a.multipart.size":"64M","fs.s3a.select.input.csv.comment.marker":"#","yarn.scheduler.minimum-allocation-vcores":"1","mapreduce.job.speculative.speculative-cap-total-tasks":"0.01","hadoop.ssl.client.conf":"ssl-client.xml","mapreduce.job.queuename":"default","mapreduce.job.encrypted-intermediate-data-key-size-bits":"128","fs.s3a.metadatastore.authoritative":"false","ipc.[port_number].weighted-cost.response":"1","yarn.nodemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","ha.health-monitor.sleep-after-disconnect.ms":"1000","yarn.app.mapreduce.shuffle.log.limit.kb":"0","hadoop.security.group.mapping":"org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback","yarn.client.application-client-protocol.poll-timeout-ms":"-1","mapreduce.jobhistory.jhist.format":"binary","mapreduce.task.stuck.timeout-ms":"600000","yarn.resourcemanager.application.max-tag.length":"100","yarn.resourcemanager.ha.enabled":"false","dfs.client.ignore.namenode.default.kms.uri":"false","hadoop.http.staticuser.user":"dr.who","mapreduce.task.exit.timeout.check-interval-ms":"20000","mapreduce.jobhistory.intermediate-user-done-dir.permissions":"770","mapreduce.task.exit.timeout":"60000","yarn.nodemanager.linux-container-executor.resources-handler.class":"org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler","mapreduce.reduce.shuffle.memory.limit.percent":"0.25","yarn.resourcemanager.reservation-system.enable":"false","mapreduce.map.output.compress":"false","ha.zookeeper.acl":"world:anyone:rwcda","ipc.server.max.connections":"0","yarn.nodemanager.runtime.linux.docker.default-container-network":"host","yarn.router.webapp.address":"0.0.0.0:8089","yarn.scheduler.maximum-allocation-mb":"8192","yarn.resourcemanager.scheduler.monitor.policies":"org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy","yarn.sharedcache.cleaner.period-mins":"1440","yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint":"http://localhost:3476/v1.0/docker/cli","yarn.app.mapreduce.am.container.log.limit.kb":"0","ipc.client.connect.retry.interval":"1000","yarn.timeline-service.http-cross-origin.enabled":"false","fs.wasbs.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure","yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms":"1000","yarn.federation.subcluster-resolver.class":"org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl","yarn.resourcemanager.zk-state-store.parent-path":"/rmstore","fs.s3a.select.input.csv.field.delimiter":",","mapreduce.jobhistory.cleaner.enable":"true","yarn.timeline-service.client.fd-flush-interval-secs":"10","hadoop.security.kms.client.encrypted.key.cache.expiry":"43200000","yarn.client.nodemanager-client-async.thread-pool-max-size":"500","mapreduce.map.maxattempts":"4","yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms":"1000","fs.s3a.committer.staging.tmp.path":"tmp/staging","yarn.nodemanager.sleep-delay-before-sigkill.ms":"250","yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms":"10","mapreduce.job.end-notification.retry.attempts":"0","yarn.nodemanager.resource.count-logical-processors-as-cores":"false","hadoop.registry.zk.root":"/registry","adl.feature.ownerandgroup.enableupn":"false","yarn.resourcemanager.zk-max-znode-size.bytes":"1048576","mapreduce.job.reduce.shuffle.consumer.plugin.class":"org.apache.hadoop.mapreduce.task.reduce.Shuffle","yarn.resourcemanager.delayed.delegation-token.removal-interval-ms":"*********(redacted)","yarn.nodemanager.localizer.cache.target-size-mb":"10240","fs.s3a.committer.staging.conflict-mode":"append","mapreduce.client.libjars.wildcard":"true","fs.s3a.committer.staging.unique-filenames":"true","yarn.nodemanager.node-attributes.provider.fetch-timeout-ms":"1200000","fs.s3a.list.version":"2","ftp.client-write-packet-size":"65536","ipc.[port_number].weighted-cost.lockexclusive":"100","fs.AbstractFileSystem.adl.impl":"org.apache.hadoop.fs.adl.Adl","yarn.nodemanager.container-log-monitor.enable":"false","hadoop.security.key.default.cipher":"AES/CTR/NoPadding","yarn.client.failover-retries":"0","fs.s3a.multipart.purge.age":"86400","mapreduce.job.local-fs.single-disk-limit.check.interval-ms":"5000","net.topology.node.switch.mapping.impl":"org.apache.hadoop.net.ScriptBasedMapping","yarn.nodemanager.amrmproxy.address":"0.0.0.0:8049","ipc.server.listen.queue.size":"256","ipc.[port_number].decay-scheduler.period-ms":"5000","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs":"60","map.sort.class":"org.apache.hadoop.util.QuickSort","fs.viewfs.rename.strategy":"SAME_MOUNTPOINT","hadoop.security.kms.client.authentication.retry-count":"1","fs.permissions.umask-mode":"022","fs.s3a.assumed.role.credentials.provider":"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed":"false","yarn.nodemanager.vmem-check-enabled":"true","yarn.nodemanager.numa-awareness.enabled":"false","yarn.nodemanager.recovery.compaction-interval-secs":"3600","yarn.app.mapreduce.client-am.ipc.max-retries":"3","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds":"60","yarn.federation.registry.base-dir":"yarnfederation/","yarn.nodemanager.health-checker.run-before-startup":"false","mapreduce.job.max.map":"-1","mapreduce.job.local-fs.single-disk-limit.bytes":"-1","mapreduce.shuffle.pathcache.concurrency-level":"16","mapreduce.job.ubertask.maxreduces":"1","mapreduce.shuffle.pathcache.max-weight":"10485760","hadoop.security.kms.client.encrypted.key.cache.size":"500","hadoop.security.java.secure.random.algorithm":"SHA1PRNG","ha.failover-controller.cli-check.rpc-timeout.ms":"20000","mapreduce.jobhistory.jobname.limit":"50","fs.s3a.select.input.compression":"none","yarn.client.nodemanager-connect.retry-interval-ms":"10000","ipc.[port_number].scheduler.priority.levels":"4","yarn.timeline-service.state-store-class":"org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore","yarn.nodemanager.env-whitelist":"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ","yarn.sharedcache.nested-level":"3","yarn.timeline-service.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","fs.azure.user.agent.prefix":"unknown","yarn.resourcemanager.zk-delegation-token-node.split-index":"*********(redacted)","yarn.nodemanager.numa-awareness.read-topology":"false","yarn.nodemanager.webapp.address":"${yarn.nodemanager.hostname}:8042","rpc.metrics.quantile.enable":"false","yarn.registry.class":"org.apache.hadoop.registry.client.impl.FSRegistryOperationsService","mapreduce.jobhistory.admin.acl":"*","yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size":"10","yarn.scheduler.queue-placement-rules":"user-group","hadoop.http.authentication.kerberos.keytab":"${user.home}/hadoop.keytab","yarn.resourcemanager.recovery.enabled":"false","fs.s3a.select.input.csv.header":"none","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size":"500","yarn.timeline-service.webapp.rest-csrf.enabled":"false","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb":"0"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.maintenance.version":"4","java.specification.version":"1.8","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Private Build","java.vm.specification.version":"1.8","user.home":"/root","file.encoding.pkg":"sun.io","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64","user.dir":"/scripts","java.library.path":"/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"25.352-b08","jetty.git.hash":"6b67c5719d1f4371b33655ff2d047d24e171e49a","java.endorsed.dirs":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/endorsed","java.runtime.version":"1.8.0_352-8u352-ga-1~20.04-b08","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"52.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/classes","file.encoding":"UTF-8","user.timezone":"Europe/Berlin","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"5.15.0-53-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Private Build","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"root","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"*********(redacted)","java.home":"/usr/lib/jvm/java-8-openjdk-amd64/jre","java.version":"1.8.0_352","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"spark://afe89519116f:36889/files/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-policy-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-network-shuffle_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/HikariCP-2.5.1.jar":"System Classpath","spark://afe89519116f:36889/jars/com.squareup.moshi_moshi-1.5.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/univocity-parsers-2.9.1.jar":"System Classpath","spark://afe89519116f:36889/jars/org.apache.kafka_kafka-clients-3.2.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/flatbuffers-java-1.12.0.jar":"System Classpath","spark://afe89519116f:36889/files/com.datastax.oss_native-protocol-1.4.10.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-dbcp-1.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/stax-api-1.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-metrics-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/okhttp-3.12.12.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-core-asl-1.9.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.ws.rs-api-2.1.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-platform_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/compress-lzf-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-api-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-cli-2.3.9.jar":"System Classpath","spark://afe89519116f:36889/files/commons-logging_commons-logging-1.1.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-scalap_2.12-3.7.0-M11.jar":"System Classpath","spark://afe89519116f:36889/files/org.influxdb_influxdb-java-2.14.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-pool-1.5.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/tink-1.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-sketch_2.12-3.3.1.jar":"System Classpath","spark://afe89519116f:36889/jars/commons-logging_commons-logging-1.1.3.jar":"Added By User","spark://afe89519116f:36889/files/org.scala-lang_scala-reflect-2.12.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-memory-netty-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-kvstore_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-util_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/slf4j-api-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/chill-java-0.10.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javolution-5.5.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/blas-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/chill_2.12-0.10.0.jar":"System Classpath","spark://afe89519116f:36889/files/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/JLargeArrays-1.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-locator-2.6.1.jar":"System Classpath","spark://afe89519116f:36889/files/org.apache.hadoop_hadoop-client-api-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-ipc-1.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-encoding-1.12.2.jar":"System Classpath","spark://afe89519116f:36889/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-jdbc-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/shapeless_2.12-2.3.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire-macros_2.12-0.17.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/algebra_2.12-2.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar":"System Classpath","spark://afe89519116f:36889/files/org.javatuples_javatuples-1.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-logging-1.1.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-reflect-2.12.15.jar":"System Classpath","spark://afe89519116f:36889/files/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-tcnative-classes-2.0.48.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-compiler-3.0.16.jar":"System Classpath","spark://afe89519116f:36889/jars/org.msgpack_msgpack-core-0.8.16.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-rdbms-4.1.19.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-batch-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-math3-3.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/snappy-java-1.1.8.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jpam-1.1.jar":"System Classpath","spark://afe89519116f:36889/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/paranamer-2.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/aopalliance-repackaged-2.6.1.jar":"System Classpath","spark://afe89519116f:36889/jars/com.squareup.retrofit2_converter-moshi-2.4.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/minlog-1.3.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arpack-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/aircompressor-0.21.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/xbean-asm9-shaded-4.20.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/lz4-java-1.8.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/osgi-resource-locator-1.0.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/automaton-1.11-8.jar":"System Classpath","spark://afe89519116f:36889/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar":"Added By User","spark://afe89519116f:36889/jars/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jdo-api-3.0.1.jar":"System Classpath","spark://afe89519116f:36889/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-2.3.9.jar":"System Classpath","spark://afe89519116f:36889/files/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar":"Added By User","spark://afe89519116f:36889/jars/io.dropwizard.metrics_metrics-core-4.0.5.jar":"Added By User","spark://afe89519116f:36889/files/org.spark-project.spark_unused-1.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/derby-10.14.2.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-mapreduce-1.7.6.jar":"System Classpath","spark://afe89519116f:36889/jars/org.influxdb_influxdb-java-2.14.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/velocity-1.5.jar":"System Classpath","spark://afe89519116f:36889/files/ch.cern.sparkmeasure_spark-measure_2.12-0.19.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/stream-2.9.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jaxb-runtime-2.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-sql_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zookeeper-3.6.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-server-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-vector-code-gen-2.3.9.jar":"System Classpath","spark://afe89519116f:36889/files/org.msgpack_msgpack-core-0.8.16.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/protobuf-java-2.5.0.jar":"System Classpath","spark://afe89519116f:36889/files/com.squareup.okio_okio-1.14.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-core_2.12-3.7.0-M11.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-memory-core-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-autoscaling-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/guava-14.0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-common-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mesos_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/shims-0.9.25.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-datatype-jsr310-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-network-common_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/RoaringBitmap-0.9.25.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/istack-commons-runtime-3.0.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/httpcore-4.4.14.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-module-scala_2.12-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-handler-4.1.74.Final.jar":"System Classpath","spark://afe89519116f:36889/files/org.apache.commons_commons-lang3-3.9.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-api-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-exec-2.3.9-core.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/breeze_2.12-1.2.jar":"System Classpath","spark://afe89519116f:36889/files/com.squareup.retrofit2_converter-moshi-2.4.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/httpclient-4.5.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-cli-1.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/libthrift-0.12.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-yarn_2.12-3.3.1.jar":"System Classpath","spark://afe89519116f:36889/jars/org.reactivestreams_reactive-streams-1.0.2.jar":"Added By User","spark://afe89519116f:36889/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-unix-common-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jul-to-slf4j-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jta-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-catalyst_2.12-3.3.1.jar":"System Classpath","spark://afe89519116f:36889/jars/com.squareup.okio_okio-1.14.0.jar":"Added By User","spark://afe89519116f:36889/jars/org.hdrhistogram_HdrHistogram-2.1.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/ST4-4.0.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-shaded-guava-1.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-apiextensions-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-collection-compat_2.12-2.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spire_2.12-0.17.0.jar":"System Classpath","spark://afe89519116f:36889/jars/org.slf4j_slf4j-api-1.7.36.jar":"Added By User","spark://afe89519116f:36889/jars/org.spark-project.spark_unused-1.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/libfb303-0.9.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-admissionregistration-5.12.2.jar":"System Classpath","spark://afe89519116f:36889/files/org.reactivestreams_reactive-streams-1.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-text-1.9.jar":"System Classpath","spark://afe89519116f:36889/files/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/super-csv-2.2.0.jar":"System Classpath","spark://afe89519116f:36889/jars/com.github.luben_zstd-jni-1.5.2-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/leveldbjni-all-1.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-io-2.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-hk2-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/JTransforms-3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-node-5.12.2.jar":"System Classpath","spark://afe89519116f:36889/files/com.squareup.okhttp3_logging-interceptor-3.11.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-service-rpc-3.1.2.jar":"System Classpath","spark://afe89519116f:36889/files/com.squareup.okhttp3_okhttp-3.11.0.jar":"Added By User","spark://afe89519116f:36889/jars/org.apache.commons_commons-lang3-3.9.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-dataformat-yaml-2.13.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-framework-2.13.0.jar":"System Classpath","spark://afe89519116f:36889/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-kubernetes_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-compress-1.21.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-yarn-server-web-proxy-3.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-mapred-1.11.0.jar":"System Classpath","spark://afe89519116f:36889/files/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar":"Added By User","spark://afe89519116f:36889/files/com.datastax.oss_java-driver-core-shaded-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-api-jdo-4.2.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-core_2.12-3.3.1.jar":"System Classpath","spark://afe89519116f:36889/files/org.hdrhistogram_HdrHistogram-2.1.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/janino-3.0.16.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-library-2.12.15.jar":"System Classpath","spark://afe89519116f:36889/files/com.github.luben_zstd-jni-1.5.2-1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-metastore-2.3.9.jar":"System Classpath","spark://afe89519116f:36889/files/com.squareup.moshi_moshi-1.5.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/avro-1.11.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/opencsv-2.3.jar":"System Classpath","spark://afe89519116f:36889/files/com.datastax.oss_java-driver-mapper-runtime-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-codec-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-jackson_2.12-3.7.0-M11.jar":"System Classpath","spark://afe89519116f:36889/files/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-compiler-2.12.15.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-databind-2.13.4.1.jar":"System Classpath","spark://afe89519116f:36889/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/oro-2.0.8.jar":"System Classpath","spark://afe89519116f:36889/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-all-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/mesos-1.4.3-shaded-protobuf.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-classes-kqueue-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-container-servlet-2.36.jar":"System Classpath","spark://afe89519116f:36889/files/org.slf4j_slf4j-api-1.7.36.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jsr305-3.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-coordination-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/okio-1.14.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-graphite-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-lang3-3.12.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/xz-1.8.jar":"System Classpath","spark://afe89519116f:36889/files/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/antlr4-runtime-4.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-buffer-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-jmx-4.2.7.jar":"System Classpath","spark://afe89519116f:36889/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/lapack-2.2.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-rbac-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-jvm-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/conf":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-common-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-serde-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-flowcontrol-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/audience-annotations-0.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-repl_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-1.2-api-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-classes-epoll-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-storageclass-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-discovery-5.12.2.jar":"System Classpath","spark://afe89519116f:36889/files/com.squareup.retrofit2_retrofit-2.4.0.jar":"Added By User","spark://afe89519116f:36889/files/org.lz4_lz4-java-1.8.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mllib_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-vector-7.0.0.jar":"System Classpath","spark://afe89519116f:36889/jars/com.typesafe_config-1.3.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-core-2.13.4.jar":"System Classpath","spark://afe89519116f:36889/jars/com.datastax.oss_java-driver-query-builder-4.7.2.jar":"Added By User","spark://afe89519116f:36889/jars/com.fasterxml.jackson.module_jackson-module-scala_2.12-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.validation-api-2.0.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.inject-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javassist-3.25.0-GA.jar":"System Classpath","spark://afe89519116f:36889/files/com.github.spotbugs_spotbugs-annotations-3.1.12.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-format-structures-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-core-1.7.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jcl-over-slf4j-1.7.32.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-graphx_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-storage-api-2.7.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-hive_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-codec-1.15.jar":"System Classpath","spark://afe89519116f:36889/jars/org.apache.commons_commons-pool2-2.11.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-jackson-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-core-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/breeze-macros_2.12-1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-mllib-local_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-tags_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-common-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json-1.8.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-common-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/py4j-0.10.9.5.jar":"System Classpath","spark://afe89519116f:36889/files/com.google.code.findbugs_jsr305-3.0.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-parser-combinators_2.12-1.1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-scheduler-2.3.9.jar":"System Classpath","spark://afe89519116f:36889/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/orc-shims-1.7.6.jar":"System Classpath","spark://afe89519116f:36889/files/com.datastax.oss_java-driver-query-builder-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/scala-xml_2.12-1.2.0.jar":"System Classpath","spark://afe89519116f:36889/files/org.xerial.snappy_snappy-java-1.1.8.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arrow-format-7.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-collections-3.2.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.annotation-api-1.3.5.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jodd-core-3.5.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/cats-kernel_2.12-2.1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zstd-jni-1.5.2-1.jar":"System Classpath","spark://afe89519116f:36889/jars/com.datastax.oss_java-driver-core-shaded-4.7.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/antlr-runtime-3.5.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/joda-time-2.10.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-shims-0.23-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-annotations-2.13.4.jar":"System Classpath","spark://afe89519116f:36889/jars/com.squareup.okhttp3_logging-interceptor-3.11.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-recipes-2.13.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/gson-2.2.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/activation-1.1.1.jar":"System Classpath","spark://afe89519116f:36889/files/com.thoughtworks.paranamer_paranamer-2.8.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/bonecp-0.8.0.RELEASE.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-client-5.12.2.jar":"System Classpath","spark://afe89519116f:36889/files/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/ivy-2.5.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-core-2.17.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-networking-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-unsafe_2.12-3.3.1.jar":"System Classpath","spark://afe89519116f:36889/jars/org.scala-lang_scala-reflect-2.12.11.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zookeeper-jute-3.6.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hk2-utils-2.6.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jackson-mapper-asl-1.9.13.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-crypto-1.1.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/javax.jdo-3.2.0-m3.jar":"System Classpath","spark://afe89519116f:36889/files/io.dropwizard.metrics_metrics-core-4.0.5.jar":"Added By User","spark://afe89519116f:36889/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.3.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-lang-2.6.jar":"System Classpath","spark://afe89519116f:36889/jars/com.datastax.oss_native-protocol-1.4.10.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jline-2.14.6.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-beeline-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/curator-client-2.13.0.jar":"System Classpath","spark://afe89519116f:36889/jars/org.lz4_lz4-java-1.8.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/transaction-api-1.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar":"System Classpath","spark://afe89519116f:36889/jars/com.google.code.findbugs_jsr305-3.0.2.jar":"Added By User","spark://afe89519116f:36889/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/json4s-ast_2.12-3.7.0-M11.jar":"System Classpath","spark://afe89519116f:36889/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar":"Added By User","spark://afe89519116f:36889/files/com.typesafe_config-1.3.4.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/core-1.1.2.jar":"System Classpath","spark://afe89519116f:36889/jars/com.squareup.retrofit2_retrofit-2.4.0.jar":"Added By User","spark://afe89519116f:36889/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/rocksdbjni-6.20.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/threeten-extra-1.5.0.jar":"System Classpath","spark://afe89519116f:36889/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.0.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/datanucleus-core-4.1.17.jar":"System Classpath","spark://afe89519116f:36889/jars/ch.cern.sparkmeasure_spark-measure_2.12-0.19.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-core-4.2.7.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-common-2.36.jar":"System Classpath","spark://afe89519116f:36889/files/org.apache.kafka_kafka-clients-3.2.1.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-scheduling-5.12.2.jar":"System Classpath","spark://afe89519116f:36889/jars/org.javatuples_javatuples-1.2.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hive-llap-common-2.3.9.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.xml.bind-api-2.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-common-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-tags_2.12-3.3.1-tests.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-certificates-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/logging-interceptor-3.12.12.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/metrics-json-4.2.7.jar":"System Classpath","spark://afe89519116f:36889/jars/com.squareup.okhttp3_okhttp-3.11.0.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/pickle-1.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-resolver-4.1.74.Final.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-client-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-events-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-extensions-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jakarta.servlet-api-4.0.3.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-api-3.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/jersey-container-servlet-core-2.36.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/objenesis-3.2.jar":"System Classpath","spark://afe89519116f:36889/jars/com.thoughtworks.paranamer_paranamer-2.8.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/zjsonpatch-0.3.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/annotations-17.0.0.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-hive-thriftserver_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/snakeyaml-1.31.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kubernetes-model-apps-5.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-hadoop-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-streaming_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/parquet-column-1.12.2.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-launcher_2.12-3.3.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/commons-collections4-4.4.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/arpack_combined_all-0.1.jar":"System Classpath","/usr/local/lib/python3.8/dist-packages/pyspark/jars/generex-1.0.2.jar":"System Classpath","spark://afe89519116f:36889/files/com.fasterxml.jackson.core_jackson-core-2.13.3.jar":"Added By User","/usr/local/lib/python3.8/dist-packages/pyspark/jars/kryo-shaded-4.0.2.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"Testing the Stream with Kafka","App ID":"app-20221125013525-0000","Timestamp":1669336524050,"User":"root"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1669336528697,"Executor ID":"1","Executor Info":{"Host":"172.22.0.9","Total Cores":4,"Log Urls":{"stdout":"http://172.22.0.9:8081/logPage/?appId=app-20221125013525-0000&executorId=1&logType=stdout","stderr":"http://172.22.0.9:8081/logPage/?appId=app-20221125013525-0000&executorId=1&logType=stderr"},"Attributes":{},"Resources":{},"Resource Profile Id":0}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1669336528731,"Executor ID":"0","Executor Info":{"Host":"172.22.0.10","Total Cores":4,"Log Urls":{"stdout":"http://172.22.0.10:8081/logPage/?appId=app-20221125013525-0000&executorId=0&logType=stdout","stderr":"http://172.22.0.10:8081/logPage/?appId=app-20221125013525-0000&executorId=0&logType=stderr"},"Attributes":{},"Resources":{},"Resource Profile Id":0}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"172.22.0.9","Port":32905},"Maximum Memory":384093388,"Timestamp":1669336528798,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"172.22.0.10","Port":40645},"Maximum Memory":384093388,"Timestamp":1669336528831,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:35:30.684Z"}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryStartedEvent","id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:35:31.311Z"}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":1,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:35:32.757 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:35:32.757 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":6,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":7,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":8,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":3,"metricType":"timing"}]},"time":1669336533457,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":0,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@a296bd7, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@5fdaec08\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@182d61cd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@77a7f1f8","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":4,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":5,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336533456,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":2,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3d9c0172, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@4ac07da1\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@182d61cd, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@77a7f1f8","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":2,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":4,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":5,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":1,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336533493,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1669336533979,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"8\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[0],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"2","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"8\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336534003,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"2","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336534176,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336534176,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336535371,"Failed":false,"Killed":false,"Accumulables":[{"ID":9,"Name":"internal.metrics.executorDeserializeTime","Update":410,"Value":410,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.executorDeserializeCpuTime","Update":335689231,"Value":335689231,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.executorRunTime","Update":704,"Value":704,"Internal":true,"Count Failed Values":true},{"ID":12,"Name":"internal.metrics.executorCpuTime","Update":649638953,"Value":649638953,"Internal":true,"Count Failed Values":true},{"ID":13,"Name":"internal.metrics.resultSize","Update":1117,"Value":1117,"Internal":true,"Count Failed Values":true},{"ID":14,"Name":"internal.metrics.jvmGCTime","Update":31,"Value":31,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":410,"Executor Deserialize CPU Time":335689231,"Executor Run Time":704,"Executor CPU Time":649638953,"Peak Execution Memory":0,"Result Size":1117,"JVM GC Time":31,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"8\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336534003,"Completion Time":1669336535383,"Accumulables":[{"ID":9,"Name":"internal.metrics.executorDeserializeTime","Value":410,"Internal":true,"Count Failed Values":true},{"ID":10,"Name":"internal.metrics.executorDeserializeCpuTime","Value":335689231,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"internal.metrics.executorRunTime","Value":704,"Internal":true,"Count Failed Values":true},{"ID":12,"Name":"internal.metrics.executorCpuTime","Value":649638953,"Internal":true,"Count Failed Values":true},{"ID":13,"Name":"internal.metrics.resultSize","Value":1117,"Internal":true,"Count Failed Values":true},{"ID":14,"Name":"internal.metrics.jvmGCTime","Value":31,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1669336535401,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":2,"time":1669336535406}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":0,"time":1669336535407}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:35:30.815Z","batchId":0,"batchDuration":4629,"durationMs":{"triggerExecution":4628,"queryPlanning":490,"getBatch":34,"latestOffset":1925,"addBatch":2034,"walCommit":55},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":null,"endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":3,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 0","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#70, value#71, timestamp#72, current_timestamp#73]\nArguments: [topic#70, value#71, timestamp#72, current_timestamp#73], SQLExecutionRDD[6] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#70, value#71, timestamp#72, current_timestamp#73]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@767c47c7, org.apache.spark.sql.connector.write.WriteBuilder$1@58ad40d0\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@767c47c7, org.apache.spark.sql.connector.write.WriteBuilder$1@58ad40d0","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#70,value#71,timestamp#72,current_timestamp#73]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":35,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":34,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336535832,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1669336535915,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":9,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"12\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[1],"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"3","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":9,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"12\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336535918,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 0","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"0","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"3","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336535931,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336535931,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336539027,"Failed":false,"Killed":false,"Accumulables":[{"ID":36,"Name":"internal.metrics.executorDeserializeTime","Update":167,"Value":167,"Internal":true,"Count Failed Values":true},{"ID":37,"Name":"internal.metrics.executorDeserializeCpuTime","Update":135842342,"Value":135842342,"Internal":true,"Count Failed Values":true},{"ID":38,"Name":"internal.metrics.executorRunTime","Update":2915,"Value":2915,"Internal":true,"Count Failed Values":true},{"ID":39,"Name":"internal.metrics.executorCpuTime","Update":1963755010,"Value":1963755010,"Internal":true,"Count Failed Values":true},{"ID":40,"Name":"internal.metrics.resultSize","Update":1120,"Value":1120,"Internal":true,"Count Failed Values":true},{"ID":41,"Name":"internal.metrics.jvmGCTime","Update":141,"Value":141,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":167,"Executor Deserialize CPU Time":135842342,"Executor Run Time":2915,"Executor CPU Time":1963755010,"Peak Execution Memory":0,"Result Size":1120,"JVM GC Time":141,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":9,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"12\",\"name\":\"parallelize\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336535918,"Completion Time":1669336539029,"Accumulables":[{"ID":36,"Name":"internal.metrics.executorDeserializeTime","Value":167,"Internal":true,"Count Failed Values":true},{"ID":37,"Name":"internal.metrics.executorDeserializeCpuTime","Value":135842342,"Internal":true,"Count Failed Values":true},{"ID":38,"Name":"internal.metrics.executorRunTime","Value":2915,"Internal":true,"Count Failed Values":true},{"ID":39,"Name":"internal.metrics.executorCpuTime","Value":1963755010,"Internal":true,"Count Failed Values":true},{"ID":40,"Name":"internal.metrics.resultSize","Value":1120,"Internal":true,"Count Failed Values":true},{"ID":41,"Name":"internal.metrics.jvmGCTime","Value":141,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1669336539029,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":3,"time":1669336539034}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":1,"time":1669336539035}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:35:31.314Z","batchId":0,"batchDuration":7751,"durationMs":{"triggerExecution":7750,"queryPlanning":490,"getBatch":37,"latestOffset":1440,"addBatch":5660,"walCommit":56},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":null,"endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:35:45.469Z","batchId":1,"batchDuration":2,"durationMs":{"triggerExecution":2,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:35:49.074Z","batchId":1,"batchDuration":2,"durationMs":{"triggerExecution":2,"latestOffset":2},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:35:55.479Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:35:59.082Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:36:05.483Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:36:09.088Z","batchId":1,"batchDuration":2,"durationMs":{"triggerExecution":2,"latestOffset":2},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:36:15.493Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:36:19.093Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:36:25.497Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:36:29.101Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:36:35.503Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:36:39.105Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:36:45.504Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:36:49.115Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:36:55.506Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:36:59.119Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:37:05.507Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:37:09.121Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:37:15.517Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:37:19.129Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:37:25.521Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:37:29.137Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:37:35.527Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:37:39.144Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:37:45.529Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:37:49.153Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:37:55.530Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:37:59.156Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:05.537Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:09.157Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:15.545Z","batchId":1,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:19.158Z","batchId":1,"batchDuration":0,"durationMs":{"triggerExecution":0,"latestOffset":0},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":0}}","latestOffset":"{\"12003800_test\":{\"0\":0}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":4,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3d1c0412, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@707d0fa0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@21b95dc6, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@41c278ac","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":62,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":63,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":64,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":61,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336704052,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":5,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:23.976 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:23.976 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":66,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":67,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":68,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":65,"metricType":"timing"}]},"time":1669336704059,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":6,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3f33c0b1, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@65f3d162\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@21b95dc6, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@41c278ac","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":62,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":63,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":64,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":61,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336704065,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1669336704079,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"DataSourceRDD","Scope":"{\"id\":\"20\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"20\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[2],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"6","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"DataSourceRDD","Scope":"{\"id\":\"20\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"20\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336704083,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"6","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336704100,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":7,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 1","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#97, value#98, timestamp#99, current_timestamp#100]\nArguments: [topic#97, value#98, timestamp#99, current_timestamp#100], SQLExecutionRDD[16] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#97, value#98, timestamp#99, current_timestamp#100]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@4965f40, org.apache.spark.sql.connector.write.WriteBuilder$1@267437ab\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@4965f40, org.apache.spark.sql.connector.write.WriteBuilder$1@267437ab","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#97,value#98,timestamp#99,current_timestamp#100]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":95,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":94,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336704206,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1669336704212,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"DataSourceRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"14\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[3],"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"7","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"DataSourceRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"14\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336704216,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 1","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"1","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"7","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336704236,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336704236,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336705998,"Failed":false,"Killed":false,"Accumulables":[{"ID":65,"Name":"duration","Update":"1436","Value":"1436","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":66,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":94,"Name":"duration","Update":"1414","Value":"1414","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":95,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":96,"Name":"internal.metrics.executorDeserializeTime","Update":216,"Value":216,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeCpuTime","Update":181864856,"Value":181864856,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorRunTime","Update":1532,"Value":1532,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.executorCpuTime","Update":1362277994,"Value":1362277994,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.resultSize","Update":1916,"Value":1916,"Internal":true,"Count Failed Values":true},{"ID":101,"Name":"internal.metrics.jvmGCTime","Update":22,"Value":22,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":216,"Executor Deserialize CPU Time":181864856,"Executor Run Time":1532,"Executor CPU Time":1362277994,"Peak Execution Memory":0,"Result Size":1916,"JVM GC Time":22,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"22\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"DataSourceRDD","Scope":"{\"id\":\"21\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"14\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336704216,"Completion Time":1669336706004,"Accumulables":[{"ID":65,"Name":"duration","Value":"1436","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":66,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":94,"Name":"duration","Value":"1414","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":95,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":96,"Name":"internal.metrics.executorDeserializeTime","Value":216,"Internal":true,"Count Failed Values":true},{"ID":97,"Name":"internal.metrics.executorDeserializeCpuTime","Value":181864856,"Internal":true,"Count Failed Values":true},{"ID":98,"Name":"internal.metrics.executorRunTime","Value":1532,"Internal":true,"Count Failed Values":true},{"ID":99,"Name":"internal.metrics.executorCpuTime","Value":1362277994,"Internal":true,"Count Failed Values":true},{"ID":100,"Name":"internal.metrics.resultSize","Value":1916,"Internal":true,"Count Failed Values":true},{"ID":101,"Name":"internal.metrics.jvmGCTime","Value":22,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1669336706004,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":7,"time":1669336706005}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":5,"time":1669336706006}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:23.975Z","batchId":1,"batchDuration":2065,"durationMs":{"triggerExecution":2065,"queryPlanning":29,"getBatch":0,"latestOffset":0,"addBatch":1964,"walCommit":34},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":1}}","latestOffset":"{\"12003800_test\":{\"0\":1}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":0.48426150121065376,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":8,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:26.044 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:26.044 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":122,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":123,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":124,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":121,"metricType":"timing"}]},"time":1669336706134,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":9,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#117, value#118, timestamp#119, current_timestamp#120]\nArguments: [topic#117, value#118, timestamp#119, current_timestamp#120], SQLExecutionRDD[21] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#117, value#118, timestamp#119, current_timestamp#120]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@4da22f81, org.apache.spark.sql.connector.write.WriteBuilder$1@26d4981d\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@4da22f81, org.apache.spark.sql.connector.write.WriteBuilder$1@26d4981d","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#117,value#118,timestamp#119,current_timestamp#120]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":126,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":125,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336706283,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1669336706294,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"29\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"DataSourceRDD","Scope":"{\"id\":\"32\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"32\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[4],"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"9","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"29\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"DataSourceRDD","Scope":"{\"id\":\"32\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"32\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336706300,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"9","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336706321,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336704100,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336707430,"Failed":false,"Killed":false,"Accumulables":[{"ID":61,"Name":"duration","Update":"2063","Value":"2063","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":62,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":69,"Name":"internal.metrics.executorDeserializeTime","Update":618,"Value":618,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorDeserializeCpuTime","Update":576805463,"Value":576805463,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.executorRunTime","Update":2653,"Value":2653,"Internal":true,"Count Failed Values":true},{"ID":72,"Name":"internal.metrics.executorCpuTime","Update":2187393325,"Value":2187393325,"Internal":true,"Count Failed Values":true},{"ID":73,"Name":"internal.metrics.resultSize","Update":1844,"Value":1844,"Internal":true,"Count Failed Values":true},{"ID":74,"Name":"internal.metrics.jvmGCTime","Update":171,"Value":171,"Internal":true,"Count Failed Values":true},{"ID":75,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":618,"Executor Deserialize CPU Time":576805463,"Executor Run Time":2653,"Executor CPU Time":2187393325,"Peak Execution Memory":0,"Result Size":1844,"JVM GC Time":171,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"DataSourceRDD","Scope":"{\"id\":\"20\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"20\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336704083,"Completion Time":1669336707432,"Accumulables":[{"ID":61,"Name":"duration","Value":"2063","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":62,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":69,"Name":"internal.metrics.executorDeserializeTime","Value":618,"Internal":true,"Count Failed Values":true},{"ID":70,"Name":"internal.metrics.executorDeserializeCpuTime","Value":576805463,"Internal":true,"Count Failed Values":true},{"ID":71,"Name":"internal.metrics.executorRunTime","Value":2653,"Internal":true,"Count Failed Values":true},{"ID":72,"Name":"internal.metrics.executorCpuTime","Value":2187393325,"Internal":true,"Count Failed Values":true},{"ID":73,"Name":"internal.metrics.resultSize","Value":1844,"Internal":true,"Count Failed Values":true},{"ID":74,"Name":"internal.metrics.jvmGCTime","Value":171,"Internal":true,"Count Failed Values":true},{"ID":75,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1669336707434,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":6,"time":1669336707434}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":4,"time":1669336707435}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:23.974Z","batchId":1,"batchDuration":3491,"durationMs":{"triggerExecution":3491,"queryPlanning":28,"getBatch":0,"latestOffset":1,"addBatch":3395,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":0}}","endOffset":"{\"12003800_test\":{\"0\":1}}","latestOffset":"{\"12003800_test\":{\"0\":1}}","numInputRows":1,"inputRowsPerSecond":90.90909090909092,"processedRowsPerSecond":0.2864508736751647,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":10,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@49887b65, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@16868199\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5d7431c7, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@1f03eddd","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":153,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":154,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":155,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":152,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336707531,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":11,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 2","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@9712e28, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@2f5e09d9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5d7431c7, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@1f03eddd","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":153,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":154,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":155,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":152,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336707546,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1669336707559,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"38\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[23],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"DataSourceRDD","Scope":"{\"id\":\"41\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[5],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"11","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"38\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[23],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"DataSourceRDD","Scope":"{\"id\":\"41\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336707561,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 2","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"2","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"11","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336707567,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336707567,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336707837,"Failed":false,"Killed":false,"Accumulables":[{"ID":152,"Name":"duration","Update":"185","Value":"185","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":153,"Name":"number of output rows","Update":"46","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":156,"Name":"internal.metrics.executorDeserializeTime","Update":28,"Value":28,"Internal":true,"Count Failed Values":true},{"ID":157,"Name":"internal.metrics.executorDeserializeCpuTime","Update":13668919,"Value":13668919,"Internal":true,"Count Failed Values":true},{"ID":158,"Name":"internal.metrics.executorRunTime","Update":234,"Value":234,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorCpuTime","Update":124259283,"Value":124259283,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.input.recordsRead","Update":46,"Value":46,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":28,"Executor Deserialize CPU Time":13668919,"Executor Run Time":234,"Executor CPU Time":124259283,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":46},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"38\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[23],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"DataSourceRDD","Scope":"{\"id\":\"41\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336707561,"Completion Time":1669336707839,"Accumulables":[{"ID":152,"Name":"duration","Value":"185","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":153,"Name":"number of output rows","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":156,"Name":"internal.metrics.executorDeserializeTime","Value":28,"Internal":true,"Count Failed Values":true},{"ID":157,"Name":"internal.metrics.executorDeserializeCpuTime","Value":13668919,"Internal":true,"Count Failed Values":true},{"ID":158,"Name":"internal.metrics.executorRunTime","Value":234,"Internal":true,"Count Failed Values":true},{"ID":159,"Name":"internal.metrics.executorCpuTime","Value":124259283,"Internal":true,"Count Failed Values":true},{"ID":160,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":178,"Name":"internal.metrics.input.recordsRead","Value":46,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1669336707840,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":11,"time":1669336707841}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":10,"time":1669336707842}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:27.467Z","batchId":2,"batchDuration":399,"durationMs":{"triggerExecution":399,"queryPlanning":16,"getBatch":0,"latestOffset":1,"addBatch":321,"walCommit":36},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":1}}","endOffset":"{\"12003800_test\":{\"0\":47}}","latestOffset":"{\"12003800_test\":{\"0\":47}}","numInputRows":46,"inputRowsPerSecond":13.169195533924993,"processedRowsPerSecond":115.28822055137844,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":46},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":12,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@386b93b6, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@39f2746f\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@17aee50f, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@530104a1","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":182,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":183,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":184,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":181,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336707940,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":13,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@f910917, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@56a6de88\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@17aee50f, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@530104a1","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":182,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":183,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":184,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":181,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336707950,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1669336707963,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"48\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"DataSourceRDD","Scope":"{\"id\":\"48\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[6],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"13","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"48\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"DataSourceRDD","Scope":"{\"id\":\"48\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336707965,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"13","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336707971,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336707971,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336708099,"Failed":false,"Killed":false,"Accumulables":[{"ID":181,"Name":"duration","Update":"86","Value":"86","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":182,"Name":"number of output rows","Update":"5","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":185,"Name":"internal.metrics.executorDeserializeTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":186,"Name":"internal.metrics.executorDeserializeCpuTime","Update":12266731,"Value":12266731,"Internal":true,"Count Failed Values":true},{"ID":187,"Name":"internal.metrics.executorRunTime","Update":96,"Value":96,"Internal":true,"Count Failed Values":true},{"ID":188,"Name":"internal.metrics.executorCpuTime","Update":32915568,"Value":32915568,"Internal":true,"Count Failed Values":true},{"ID":189,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":207,"Name":"internal.metrics.input.recordsRead","Update":5,"Value":5,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":20,"Executor Deserialize CPU Time":12266731,"Executor Run Time":96,"Executor CPU Time":32915568,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":5},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"48\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[26],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"DataSourceRDD","Scope":"{\"id\":\"48\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336707965,"Completion Time":1669336708100,"Accumulables":[{"ID":181,"Name":"duration","Value":"86","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":182,"Name":"number of output rows","Value":"5","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":185,"Name":"internal.metrics.executorDeserializeTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":186,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12266731,"Internal":true,"Count Failed Values":true},{"ID":187,"Name":"internal.metrics.executorRunTime","Value":96,"Internal":true,"Count Failed Values":true},{"ID":188,"Name":"internal.metrics.executorCpuTime","Value":32915568,"Internal":true,"Count Failed Values":true},{"ID":189,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":207,"Name":"internal.metrics.input.recordsRead","Value":5,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1669336708101,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":13,"time":1669336708101}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":12,"time":1669336708101}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:27.868Z","batchId":3,"batchDuration":262,"durationMs":{"triggerExecution":262,"queryPlanning":19,"getBatch":0,"latestOffset":1,"addBatch":173,"walCommit":40},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":47}}","endOffset":"{\"12003800_test\":{\"0\":52}}","latestOffset":"{\"12003800_test\":{\"0\":52}}","numInputRows":5,"inputRowsPerSecond":12.468827930174562,"processedRowsPerSecond":19.083969465648853,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":5},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":14,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@10bbfc69, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@6705ce4e\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5ea981e2, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@43e91d6f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":211,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":212,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":213,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":210,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708216,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":15,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@27b6594e, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@633fb1a9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5ea981e2, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@43e91d6f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":211,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":212,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":213,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":210,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708228,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1669336708238,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"52\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"DataSourceRDD","Scope":"{\"id\":\"55\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[7],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"15","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"52\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"DataSourceRDD","Scope":"{\"id\":\"55\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708241,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"15","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708248,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708248,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336708334,"Failed":false,"Killed":false,"Accumulables":[{"ID":210,"Name":"duration","Update":"46","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":211,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":214,"Name":"internal.metrics.executorDeserializeTime","Update":26,"Value":26,"Internal":true,"Count Failed Values":true},{"ID":215,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10255903,"Value":10255903,"Internal":true,"Count Failed Values":true},{"ID":216,"Name":"internal.metrics.executorRunTime","Update":50,"Value":50,"Internal":true,"Count Failed Values":true},{"ID":217,"Name":"internal.metrics.executorCpuTime","Update":31046778,"Value":31046778,"Internal":true,"Count Failed Values":true},{"ID":218,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":236,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":26,"Executor Deserialize CPU Time":10255903,"Executor Run Time":50,"Executor CPU Time":31046778,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"52\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"DataSourceRDD","Scope":"{\"id\":\"55\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[29],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708241,"Completion Time":1669336708336,"Accumulables":[{"ID":210,"Name":"duration","Value":"46","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":211,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":214,"Name":"internal.metrics.executorDeserializeTime","Value":26,"Internal":true,"Count Failed Values":true},{"ID":215,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10255903,"Internal":true,"Count Failed Values":true},{"ID":216,"Name":"internal.metrics.executorRunTime","Value":50,"Internal":true,"Count Failed Values":true},{"ID":217,"Name":"internal.metrics.executorCpuTime","Value":31046778,"Internal":true,"Count Failed Values":true},{"ID":218,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":236,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1669336708336,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":15,"time":1669336708337}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":14,"time":1669336708337}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:28.135Z","batchId":4,"batchDuration":228,"durationMs":{"triggerExecution":228,"queryPlanning":40,"getBatch":1,"latestOffset":1,"addBatch":131,"walCommit":28},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":52}}","endOffset":"{\"12003800_test\":{\"0\":56}}","latestOffset":"{\"12003800_test\":{\"0\":56}}","numInputRows":4,"inputRowsPerSecond":14.9812734082397,"processedRowsPerSecond":17.543859649122805,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":4},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":16,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5e807ed9, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@63b5fd31\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38f08898, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@1230ed90","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":240,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":241,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":242,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":239,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708428,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":17,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3c3ac1a5, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@67925a43\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38f08898, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@1230ed90","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":240,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":241,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":242,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":239,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708435,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1669336708452,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"59\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[32],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"DataSourceRDD","Scope":"{\"id\":\"62\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[8],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"17","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"59\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[32],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"DataSourceRDD","Scope":"{\"id\":\"62\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708453,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"17","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708460,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708460,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336708528,"Failed":false,"Killed":false,"Accumulables":[{"ID":239,"Name":"duration","Update":"31","Value":"31","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":240,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":243,"Name":"internal.metrics.executorDeserializeTime","Update":21,"Value":21,"Internal":true,"Count Failed Values":true},{"ID":244,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10871353,"Value":10871353,"Internal":true,"Count Failed Values":true},{"ID":245,"Name":"internal.metrics.executorRunTime","Update":39,"Value":39,"Internal":true,"Count Failed Values":true},{"ID":246,"Name":"internal.metrics.executorCpuTime","Update":30925122,"Value":30925122,"Internal":true,"Count Failed Values":true},{"ID":247,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":265,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":21,"Executor Deserialize CPU Time":10871353,"Executor Run Time":39,"Executor CPU Time":30925122,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"59\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"62\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[32],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"DataSourceRDD","Scope":"{\"id\":\"62\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708453,"Completion Time":1669336708530,"Accumulables":[{"ID":239,"Name":"duration","Value":"31","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":240,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":243,"Name":"internal.metrics.executorDeserializeTime","Value":21,"Internal":true,"Count Failed Values":true},{"ID":244,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10871353,"Internal":true,"Count Failed Values":true},{"ID":245,"Name":"internal.metrics.executorRunTime","Value":39,"Internal":true,"Count Failed Values":true},{"ID":246,"Name":"internal.metrics.executorCpuTime","Value":30925122,"Internal":true,"Count Failed Values":true},{"ID":247,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":265,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1669336708530,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":17,"time":1669336708530}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":16,"time":1669336708530}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:28.364Z","batchId":5,"batchDuration":188,"durationMs":{"triggerExecution":188,"queryPlanning":12,"getBatch":1,"latestOffset":1,"addBatch":113,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":56}}","endOffset":"{\"12003800_test\":{\"0\":59}}","latestOffset":"{\"12003800_test\":{\"0\":59}}","numInputRows":3,"inputRowsPerSecond":13.100436681222707,"processedRowsPerSecond":15.957446808510639,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":18,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@65720f5d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@4ca581c0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2bd40669, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@26a90b2","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":269,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":270,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":271,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":268,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708613,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":19,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@628bf5d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@73de5715\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2bd40669, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@26a90b2","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":269,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":270,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":271,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":268,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708623,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1669336708643,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"66\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"DataSourceRDD","Scope":"{\"id\":\"69\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"69\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[9],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"19","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"66\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"DataSourceRDD","Scope":"{\"id\":\"69\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"69\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708645,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"19","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708653,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708653,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336708749,"Failed":false,"Killed":false,"Accumulables":[{"ID":268,"Name":"duration","Update":"34","Value":"34","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":269,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":272,"Name":"internal.metrics.executorDeserializeTime","Update":45,"Value":45,"Internal":true,"Count Failed Values":true},{"ID":273,"Name":"internal.metrics.executorDeserializeCpuTime","Update":13097238,"Value":13097238,"Internal":true,"Count Failed Values":true},{"ID":274,"Name":"internal.metrics.executorRunTime","Update":40,"Value":40,"Internal":true,"Count Failed Values":true},{"ID":275,"Name":"internal.metrics.executorCpuTime","Update":30122809,"Value":30122809,"Internal":true,"Count Failed Values":true},{"ID":276,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":294,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":45,"Executor Deserialize CPU Time":13097238,"Executor Run Time":40,"Executor CPU Time":30122809,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"66\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"DataSourceRDD","Scope":"{\"id\":\"69\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"69\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[35],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708645,"Completion Time":1669336708750,"Accumulables":[{"ID":268,"Name":"duration","Value":"34","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":269,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":272,"Name":"internal.metrics.executorDeserializeTime","Value":45,"Internal":true,"Count Failed Values":true},{"ID":273,"Name":"internal.metrics.executorDeserializeCpuTime","Value":13097238,"Internal":true,"Count Failed Values":true},{"ID":274,"Name":"internal.metrics.executorRunTime","Value":40,"Internal":true,"Count Failed Values":true},{"ID":275,"Name":"internal.metrics.executorCpuTime","Value":30122809,"Internal":true,"Count Failed Values":true},{"ID":276,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":294,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1669336708750,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":19,"time":1669336708750}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":18,"time":1669336708750}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:28.554Z","batchId":6,"batchDuration":221,"durationMs":{"triggerExecution":221,"queryPlanning":14,"getBatch":0,"latestOffset":1,"addBatch":149,"walCommit":30},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":59}}","endOffset":"{\"12003800_test\":{\"0\":62}}","latestOffset":"{\"12003800_test\":{\"0\":62}}","numInputRows":3,"inputRowsPerSecond":15.789473684210526,"processedRowsPerSecond":13.574660633484163,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":20,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5c4c9c5a, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@e9bd4f0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@70d38a65, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@cc6cb92","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":298,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":299,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":300,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":297,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708833,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":21,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 7","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@755f63b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@15eadb5\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@70d38a65, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@cc6cb92","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":298,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":299,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":300,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":297,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336708841,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1669336708850,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"73\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"DataSourceRDD","Scope":"{\"id\":\"76\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[10],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"21","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"73\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"DataSourceRDD","Scope":"{\"id\":\"76\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708853,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 7","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"7","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"21","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708862,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336708862,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336709006,"Failed":false,"Killed":false,"Accumulables":[{"ID":297,"Name":"duration","Update":"106","Value":"106","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":298,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":301,"Name":"internal.metrics.executorDeserializeTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":302,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10706336,"Value":10706336,"Internal":true,"Count Failed Values":true},{"ID":303,"Name":"internal.metrics.executorRunTime","Update":116,"Value":116,"Internal":true,"Count Failed Values":true},{"ID":304,"Name":"internal.metrics.executorCpuTime","Update":30910385,"Value":30910385,"Internal":true,"Count Failed Values":true},{"ID":305,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":323,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":18,"Executor Deserialize CPU Time":10706336,"Executor Run Time":116,"Executor CPU Time":30910385,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"73\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"76\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[38],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"DataSourceRDD","Scope":"{\"id\":\"76\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336708853,"Completion Time":1669336709007,"Accumulables":[{"ID":297,"Name":"duration","Value":"106","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":298,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":301,"Name":"internal.metrics.executorDeserializeTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":302,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10706336,"Internal":true,"Count Failed Values":true},{"ID":303,"Name":"internal.metrics.executorRunTime","Value":116,"Internal":true,"Count Failed Values":true},{"ID":304,"Name":"internal.metrics.executorCpuTime","Value":30910385,"Internal":true,"Count Failed Values":true},{"ID":305,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":323,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1669336709007,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":21,"time":1669336709009}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":20,"time":1669336709010}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:28.777Z","batchId":7,"batchDuration":260,"durationMs":{"triggerExecution":260,"queryPlanning":12,"getBatch":0,"latestOffset":1,"addBatch":185,"walCommit":34},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":62}}","endOffset":"{\"12003800_test\":{\"0\":66}}","latestOffset":"{\"12003800_test\":{\"0\":66}}","numInputRows":4,"inputRowsPerSecond":17.937219730941703,"processedRowsPerSecond":15.384615384615383,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":4},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":22,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@a302222, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@5b072855\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@542489dc, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@23a602bc","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":327,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":328,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":329,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":326,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709118,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":23,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 8","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@61fbebdb, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@756cc1cd\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@542489dc, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@23a602bc","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":327,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":328,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":329,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":326,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709126,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1669336709135,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[11],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"23","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709138,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 8","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"8","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"23","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709144,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709144,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336709259,"Failed":false,"Killed":false,"Accumulables":[{"ID":326,"Name":"duration","Update":"60","Value":"60","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":327,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":330,"Name":"internal.metrics.executorDeserializeTime","Update":41,"Value":41,"Internal":true,"Count Failed Values":true},{"ID":331,"Name":"internal.metrics.executorDeserializeCpuTime","Update":12431710,"Value":12431710,"Internal":true,"Count Failed Values":true},{"ID":332,"Name":"internal.metrics.executorRunTime","Update":66,"Value":66,"Internal":true,"Count Failed Values":true},{"ID":333,"Name":"internal.metrics.executorCpuTime","Update":30603322,"Value":30603322,"Internal":true,"Count Failed Values":true},{"ID":334,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":352,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":41,"Executor Deserialize CPU Time":12431710,"Executor Run Time":66,"Executor CPU Time":30603322,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"80\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[41],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"DataSourceRDD","Scope":"{\"id\":\"83\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709138,"Completion Time":1669336709260,"Accumulables":[{"ID":326,"Name":"duration","Value":"60","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":327,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":330,"Name":"internal.metrics.executorDeserializeTime","Value":41,"Internal":true,"Count Failed Values":true},{"ID":331,"Name":"internal.metrics.executorDeserializeCpuTime","Value":12431710,"Internal":true,"Count Failed Values":true},{"ID":332,"Name":"internal.metrics.executorRunTime","Value":66,"Internal":true,"Count Failed Values":true},{"ID":333,"Name":"internal.metrics.executorCpuTime","Value":30603322,"Internal":true,"Count Failed Values":true},{"ID":334,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":352,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1669336709260,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":23,"time":1669336709261}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":22,"time":1669336709261}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:29.038Z","batchId":8,"batchDuration":248,"durationMs":{"triggerExecution":248,"queryPlanning":10,"getBatch":0,"latestOffset":4,"addBatch":158,"walCommit":48},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":66}}","endOffset":"{\"12003800_test\":{\"0\":69}}","latestOffset":"{\"12003800_test\":{\"0\":69}}","numInputRows":3,"inputRowsPerSecond":11.494252873563218,"processedRowsPerSecond":12.096774193548388,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":24,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6d684ab3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@70eba84d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1703ab02, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@42dbc27f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":356,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":357,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":358,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":355,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709343,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":25,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 9","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@728f2656, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@586337bf\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1703ab02, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@42dbc27f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":356,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":357,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":358,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":355,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709353,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1669336709366,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"87\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"90\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[12],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"25","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"87\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"90\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709370,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 9","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"9","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"25","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709378,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709378,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336709462,"Failed":false,"Killed":false,"Accumulables":[{"ID":355,"Name":"duration","Update":"48","Value":"48","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":356,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":359,"Name":"internal.metrics.executorDeserializeTime","Update":23,"Value":23,"Internal":true,"Count Failed Values":true},{"ID":360,"Name":"internal.metrics.executorDeserializeCpuTime","Update":13377660,"Value":13377660,"Internal":true,"Count Failed Values":true},{"ID":361,"Name":"internal.metrics.executorRunTime","Update":52,"Value":52,"Internal":true,"Count Failed Values":true},{"ID":362,"Name":"internal.metrics.executorCpuTime","Update":25127534,"Value":25127534,"Internal":true,"Count Failed Values":true},{"ID":363,"Name":"internal.metrics.resultSize","Update":1801,"Value":1801,"Internal":true,"Count Failed Values":true},{"ID":364,"Name":"internal.metrics.jvmGCTime","Update":12,"Value":12,"Internal":true,"Count Failed Values":true},{"ID":381,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":23,"Executor Deserialize CPU Time":13377660,"Executor Run Time":52,"Executor CPU Time":25127534,"Peak Execution Memory":0,"Result Size":1801,"JVM GC Time":12,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"87\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"90\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[44],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"DataSourceRDD","Scope":"{\"id\":\"90\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709370,"Completion Time":1669336709464,"Accumulables":[{"ID":355,"Name":"duration","Value":"48","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":356,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":359,"Name":"internal.metrics.executorDeserializeTime","Value":23,"Internal":true,"Count Failed Values":true},{"ID":360,"Name":"internal.metrics.executorDeserializeCpuTime","Value":13377660,"Internal":true,"Count Failed Values":true},{"ID":361,"Name":"internal.metrics.executorRunTime","Value":52,"Internal":true,"Count Failed Values":true},{"ID":362,"Name":"internal.metrics.executorCpuTime","Value":25127534,"Internal":true,"Count Failed Values":true},{"ID":363,"Name":"internal.metrics.resultSize","Value":1801,"Internal":true,"Count Failed Values":true},{"ID":364,"Name":"internal.metrics.jvmGCTime","Value":12,"Internal":true,"Count Failed Values":true},{"ID":381,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1669336709465,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":25,"time":1669336709465}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":24,"time":1669336709465}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:29.287Z","batchId":9,"batchDuration":211,"durationMs":{"triggerExecution":211,"queryPlanning":13,"getBatch":0,"latestOffset":1,"addBatch":130,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":69}}","endOffset":"{\"12003800_test\":{\"0\":73}}","latestOffset":"{\"12003800_test\":{\"0\":73}}","numInputRows":4,"inputRowsPerSecond":16.06425702811245,"processedRowsPerSecond":18.95734597156398,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":4},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":26,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5fc79fd5, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@30d58f4d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4cbf320b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@604e9312","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":385,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":386,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":387,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":384,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709549,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":27,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 10","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@19439a9d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@380c36d5\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4cbf320b, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@604e9312","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":385,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":386,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":387,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":384,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709561,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1669336709569,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[13],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"27","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709570,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 10","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"10","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"27","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709609,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709609,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336709714,"Failed":false,"Killed":false,"Accumulables":[{"ID":384,"Name":"duration","Update":"63","Value":"63","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":385,"Name":"number of output rows","Update":"2","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":388,"Name":"internal.metrics.executorDeserializeTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":389,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8348082,"Value":8348082,"Internal":true,"Count Failed Values":true},{"ID":390,"Name":"internal.metrics.executorRunTime","Update":69,"Value":69,"Internal":true,"Count Failed Values":true},{"ID":391,"Name":"internal.metrics.executorCpuTime","Update":21796666,"Value":21796666,"Internal":true,"Count Failed Values":true},{"ID":392,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":410,"Name":"internal.metrics.input.recordsRead","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":25,"Executor Deserialize CPU Time":8348082,"Executor Run Time":69,"Executor CPU Time":21796666,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":2},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"94\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"DataSourceRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"97\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709570,"Completion Time":1669336709714,"Accumulables":[{"ID":384,"Name":"duration","Value":"63","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":385,"Name":"number of output rows","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":388,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":389,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8348082,"Internal":true,"Count Failed Values":true},{"ID":390,"Name":"internal.metrics.executorRunTime","Value":69,"Internal":true,"Count Failed Values":true},{"ID":391,"Name":"internal.metrics.executorCpuTime","Value":21796666,"Internal":true,"Count Failed Values":true},{"ID":392,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":410,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1669336709714,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":27,"time":1669336709715}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":26,"time":1669336709715}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:29.500Z","batchId":10,"batchDuration":241,"durationMs":{"triggerExecution":241,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":173,"walCommit":32},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":73}}","endOffset":"{\"12003800_test\":{\"0\":75}}","latestOffset":"{\"12003800_test\":{\"0\":75}}","numInputRows":2,"inputRowsPerSecond":9.389671361502348,"processedRowsPerSecond":8.298755186721992,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":2},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":28,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@26720f31, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@281d845a\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3180ec8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@30820ba4","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":414,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":415,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":416,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":413,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709786,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":29,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 11","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5b5b8416, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@3e2c3f14\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3180ec8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@30820ba4","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":414,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":415,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":416,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":413,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709793,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1669336709804,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"DataSourceRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[14],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"29","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"DataSourceRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709805,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 11","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"11","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"29","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709810,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709810,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336709863,"Failed":false,"Killed":false,"Accumulables":[{"ID":413,"Name":"duration","Update":"19","Value":"19","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":414,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":417,"Name":"internal.metrics.executorDeserializeTime","Update":19,"Value":19,"Internal":true,"Count Failed Values":true},{"ID":418,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8125923,"Value":8125923,"Internal":true,"Count Failed Values":true},{"ID":419,"Name":"internal.metrics.executorRunTime","Update":26,"Value":26,"Internal":true,"Count Failed Values":true},{"ID":420,"Name":"internal.metrics.executorCpuTime","Update":17930099,"Value":17930099,"Internal":true,"Count Failed Values":true},{"ID":421,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":439,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":19,"Executor Deserialize CPU Time":8125923,"Executor Run Time":26,"Executor CPU Time":17930099,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"101\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"DataSourceRDD","Scope":"{\"id\":\"104\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709805,"Completion Time":1669336709865,"Accumulables":[{"ID":413,"Name":"duration","Value":"19","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":414,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":417,"Name":"internal.metrics.executorDeserializeTime","Value":19,"Internal":true,"Count Failed Values":true},{"ID":418,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8125923,"Internal":true,"Count Failed Values":true},{"ID":419,"Name":"internal.metrics.executorRunTime","Value":26,"Internal":true,"Count Failed Values":true},{"ID":420,"Name":"internal.metrics.executorCpuTime","Value":17930099,"Internal":true,"Count Failed Values":true},{"ID":421,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":439,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1669336709865,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":29,"time":1669336709866}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":28,"time":1669336709867}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:29.743Z","batchId":11,"batchDuration":174,"durationMs":{"triggerExecution":174,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":91,"walCommit":21},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":75}}","endOffset":"{\"12003800_test\":{\"0\":79}}","latestOffset":"{\"12003800_test\":{\"0\":79}}","numInputRows":4,"inputRowsPerSecond":16.46090534979424,"processedRowsPerSecond":22.98850574712644,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":4},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336706321,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336709951,"Failed":false,"Killed":false,"Accumulables":[{"ID":121,"Name":"duration","Update":"3278","Value":"3278","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":122,"Name":"number of output rows","Update":"29","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":125,"Name":"duration","Update":"3265","Value":"3265","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Update":"29","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":127,"Name":"internal.metrics.executorDeserializeTime","Update":228,"Value":228,"Internal":true,"Count Failed Values":true},{"ID":128,"Name":"internal.metrics.executorDeserializeCpuTime","Update":147745987,"Value":147745987,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.executorRunTime","Update":3366,"Value":3366,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorCpuTime","Update":2317749345,"Value":2317749345,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.resultSize","Update":1959,"Value":1959,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.jvmGCTime","Update":31,"Value":31,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSerializationTime","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":149,"Name":"internal.metrics.input.recordsRead","Update":29,"Value":29,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":228,"Executor Deserialize CPU Time":147745987,"Executor Run Time":3366,"Executor CPU Time":2317749345,"Peak Execution Memory":0,"Result Size":1959,"JVM GC Time":31,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":29},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"29\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"DataSourceRDD","Scope":"{\"id\":\"32\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"32\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336706300,"Completion Time":1669336709952,"Accumulables":[{"ID":121,"Name":"duration","Value":"3278","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":122,"Name":"number of output rows","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":125,"Name":"duration","Value":"3265","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":126,"Name":"number of output rows","Value":"29","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":127,"Name":"internal.metrics.executorDeserializeTime","Value":228,"Internal":true,"Count Failed Values":true},{"ID":128,"Name":"internal.metrics.executorDeserializeCpuTime","Value":147745987,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.executorRunTime","Value":3366,"Internal":true,"Count Failed Values":true},{"ID":130,"Name":"internal.metrics.executorCpuTime","Value":2317749345,"Internal":true,"Count Failed Values":true},{"ID":131,"Name":"internal.metrics.resultSize","Value":1959,"Internal":true,"Count Failed Values":true},{"ID":132,"Name":"internal.metrics.jvmGCTime","Value":31,"Internal":true,"Count Failed Values":true},{"ID":133,"Name":"internal.metrics.resultSerializationTime","Value":1,"Internal":true,"Count Failed Values":true},{"ID":149,"Name":"internal.metrics.input.recordsRead","Value":29,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1669336709952,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":9,"time":1669336709952}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":8,"time":1669336709953}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":30,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@31557e71, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@74e8257c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5617a0ab, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@126d0d8f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":443,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":444,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":445,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":442,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709973,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":31,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 12","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2e0c8286, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@29eb8fc9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5617a0ab, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@126d0d8f","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":443,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":444,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":445,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":442,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336709980,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:26.043Z","batchId":2,"batchDuration":3936,"durationMs":{"triggerExecution":3936,"queryPlanning":25,"getBatch":0,"latestOffset":1,"addBatch":3845,"walCommit":35},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":1}}","endOffset":"{\"12003800_test\":{\"0\":30}}","latestOffset":"{\"12003800_test\":{\"0\":30}}","numInputRows":29,"inputRowsPerSecond":14.02321083172147,"processedRowsPerSecond":7.367886178861789,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1669336709991,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"113\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"DataSourceRDD","Scope":"{\"id\":\"116\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[15],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"31","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"113\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"DataSourceRDD","Scope":"{\"id\":\"116\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709992,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 12","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"12","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"31","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709998,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":32,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:29.983 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:29.983 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":472,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":473,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":474,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":471,"metricType":"timing"}]},"time":1669336710042,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336709998,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336710133,"Failed":false,"Killed":false,"Accumulables":[{"ID":442,"Name":"duration","Update":"90","Value":"90","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":443,"Name":"number of output rows","Update":"3","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":446,"Name":"internal.metrics.executorDeserializeTime","Update":18,"Value":18,"Internal":true,"Count Failed Values":true},{"ID":447,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10639461,"Value":10639461,"Internal":true,"Count Failed Values":true},{"ID":448,"Name":"internal.metrics.executorRunTime","Update":101,"Value":101,"Internal":true,"Count Failed Values":true},{"ID":449,"Name":"internal.metrics.executorCpuTime","Update":23965907,"Value":23965907,"Internal":true,"Count Failed Values":true},{"ID":450,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":468,"Name":"internal.metrics.input.recordsRead","Update":3,"Value":3,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":18,"Executor Deserialize CPU Time":10639461,"Executor Run Time":101,"Executor CPU Time":23965907,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":3},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"113\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"DataSourceRDD","Scope":"{\"id\":\"116\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"116\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336709992,"Completion Time":1669336710133,"Accumulables":[{"ID":442,"Name":"duration","Value":"90","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":443,"Name":"number of output rows","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":446,"Name":"internal.metrics.executorDeserializeTime","Value":18,"Internal":true,"Count Failed Values":true},{"ID":447,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10639461,"Internal":true,"Count Failed Values":true},{"ID":448,"Name":"internal.metrics.executorRunTime","Value":101,"Internal":true,"Count Failed Values":true},{"ID":449,"Name":"internal.metrics.executorCpuTime","Value":23965907,"Internal":true,"Count Failed Values":true},{"ID":450,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":468,"Name":"internal.metrics.input.recordsRead","Value":3,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1669336710133,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":31,"time":1669336710134}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":30,"time":1669336710134}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":33,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 3","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#214, value#215, timestamp#216, current_timestamp#217]\nArguments: [topic#214, value#215, timestamp#216, current_timestamp#217], SQLExecutionRDD[59] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#214, value#215, timestamp#216, current_timestamp#217]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@bf31b6, org.apache.spark.sql.connector.write.WriteBuilder$1@e390907\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@bf31b6, org.apache.spark.sql.connector.write.WriteBuilder$1@e390907","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#214,value#215,timestamp#216,current_timestamp#217]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":476,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":475,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336710173,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1669336710179,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":60,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"124\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[59],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":59,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"DataSourceRDD","Scope":"{\"id\":\"120\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"120\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"117\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[16],"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"33","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":60,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"124\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[59],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":59,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"DataSourceRDD","Scope":"{\"id\":\"120\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"120\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"117\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710180,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 3","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"3","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"33","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710188,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:29.917Z","batchId":12,"batchDuration":284,"durationMs":{"triggerExecution":284,"queryPlanning":11,"getBatch":0,"latestOffset":1,"addBatch":171,"walCommit":33},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":79}}","endOffset":"{\"12003800_test\":{\"0\":82}}","latestOffset":"{\"12003800_test\":{\"0\":82}}","numInputRows":3,"inputRowsPerSecond":17.24137931034483,"processedRowsPerSecond":10.563380281690142,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":3},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":34,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1ac2a718, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@771ae15\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7413b0e8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@5bca77ff","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":503,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":504,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":505,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":502,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336710261,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":35,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 13","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@14afe11c, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@6d81b0e0\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7413b0e8, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@5bca77ff","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":503,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":504,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":505,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":502,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336710279,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1669336710292,"Stage Infos":[{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"DataSourceRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[17],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"35","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"DataSourceRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710293,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 13","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"13","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"35","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710299,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710299,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336710512,"Failed":false,"Killed":false,"Accumulables":[{"ID":502,"Name":"duration","Update":"82","Value":"82","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":503,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":506,"Name":"internal.metrics.executorDeserializeTime","Update":20,"Value":20,"Internal":true,"Count Failed Values":true},{"ID":507,"Name":"internal.metrics.executorDeserializeCpuTime","Update":11421975,"Value":11421975,"Internal":true,"Count Failed Values":true},{"ID":508,"Name":"internal.metrics.executorRunTime","Update":92,"Value":92,"Internal":true,"Count Failed Values":true},{"ID":509,"Name":"internal.metrics.executorCpuTime","Update":23630773,"Value":23630773,"Internal":true,"Count Failed Values":true},{"ID":510,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":528,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":34635856,"JVMOffHeapMemory":124027656,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":124305,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":124305,"OffHeapUnifiedMemory":0,"DirectPoolMemory":29596,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":8,"MinorGCTime":158,"MajorGCCount":4,"MajorGCTime":330,"TotalGCTime":488},"Task Metrics":{"Executor Deserialize Time":20,"Executor Deserialize CPU Time":11421975,"Executor Run Time":92,"Executor CPU Time":23630773,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":63,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"126\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"DataSourceRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"129\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710293,"Completion Time":1669336710514,"Accumulables":[{"ID":502,"Name":"duration","Value":"82","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":503,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":506,"Name":"internal.metrics.executorDeserializeTime","Value":20,"Internal":true,"Count Failed Values":true},{"ID":507,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11421975,"Internal":true,"Count Failed Values":true},{"ID":508,"Name":"internal.metrics.executorRunTime","Value":92,"Internal":true,"Count Failed Values":true},{"ID":509,"Name":"internal.metrics.executorCpuTime","Value":23630773,"Internal":true,"Count Failed Values":true},{"ID":510,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":528,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1669336710514,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":35,"time":1669336710515}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":34,"time":1669336710515}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710188,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336710522,"Failed":false,"Killed":false,"Accumulables":[{"ID":471,"Name":"duration","Update":"276","Value":"276","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":472,"Name":"number of output rows","Update":"53","Value":"53","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":475,"Name":"duration","Update":"276","Value":"276","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":476,"Name":"number of output rows","Update":"53","Value":"53","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":477,"Name":"internal.metrics.executorDeserializeTime","Update":19,"Value":19,"Internal":true,"Count Failed Values":true},{"ID":478,"Name":"internal.metrics.executorDeserializeCpuTime","Update":11192244,"Value":11192244,"Internal":true,"Count Failed Values":true},{"ID":479,"Name":"internal.metrics.executorRunTime","Update":305,"Value":305,"Internal":true,"Count Failed Values":true},{"ID":480,"Name":"internal.metrics.executorCpuTime","Update":81742183,"Value":81742183,"Internal":true,"Count Failed Values":true},{"ID":481,"Name":"internal.metrics.resultSize","Update":1916,"Value":1916,"Internal":true,"Count Failed Values":true},{"ID":482,"Name":"internal.metrics.jvmGCTime","Update":114,"Value":114,"Internal":true,"Count Failed Values":true},{"ID":499,"Name":"internal.metrics.input.recordsRead","Update":53,"Value":53,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":34635856,"JVMOffHeapMemory":124027656,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":124305,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":124305,"OffHeapUnifiedMemory":0,"DirectPoolMemory":29596,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":8,"MinorGCTime":158,"MajorGCCount":4,"MajorGCTime":330,"TotalGCTime":488},"Task Metrics":{"Executor Deserialize Time":19,"Executor Deserialize CPU Time":11192244,"Executor Run Time":305,"Executor CPU Time":81742183,"Peak Execution Memory":0,"Result Size":1916,"JVM GC Time":114,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":53},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":60,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"124\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[59],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":59,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"DataSourceRDD","Scope":"{\"id\":\"120\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"120\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"117\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710180,"Completion Time":1669336710522,"Accumulables":[{"ID":471,"Name":"duration","Value":"276","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":472,"Name":"number of output rows","Value":"53","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":475,"Name":"duration","Value":"276","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":476,"Name":"number of output rows","Value":"53","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":477,"Name":"internal.metrics.executorDeserializeTime","Value":19,"Internal":true,"Count Failed Values":true},{"ID":478,"Name":"internal.metrics.executorDeserializeCpuTime","Value":11192244,"Internal":true,"Count Failed Values":true},{"ID":479,"Name":"internal.metrics.executorRunTime","Value":305,"Internal":true,"Count Failed Values":true},{"ID":480,"Name":"internal.metrics.executorCpuTime","Value":81742183,"Internal":true,"Count Failed Values":true},{"ID":481,"Name":"internal.metrics.resultSize","Value":1916,"Internal":true,"Count Failed Values":true},{"ID":482,"Name":"internal.metrics.jvmGCTime","Value":114,"Internal":true,"Count Failed Values":true},{"ID":499,"Name":"internal.metrics.input.recordsRead","Value":53,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1669336710523,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":33,"time":1669336710523}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":32,"time":1669336710523}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:30.202Z","batchId":13,"batchDuration":340,"durationMs":{"triggerExecution":340,"queryPlanning":11,"getBatch":0,"latestOffset":2,"addBatch":264,"walCommit":34},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":82}}","endOffset":"{\"12003800_test\":{\"0\":86}}","latestOffset":"{\"12003800_test\":{\"0\":86}}","numInputRows":4,"inputRowsPerSecond":14.035087719298247,"processedRowsPerSecond":11.76470588235294,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":4},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:29.981Z","batchId":3,"batchDuration":568,"durationMs":{"triggerExecution":568,"queryPlanning":12,"getBatch":0,"latestOffset":1,"addBatch":492,"walCommit":33},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":30}}","endOffset":"{\"12003800_test\":{\"0\":83}}","latestOffset":"{\"12003800_test\":{\"0\":83}}","numInputRows":53,"inputRowsPerSecond":13.458608430675469,"processedRowsPerSecond":93.30985915492958,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":36,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1dd6513d, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@745c5c52\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@274636ad, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@3de81301","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":532,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":533,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":534,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":531,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336710596,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":37,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:30.55 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:30.55 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":536,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":537,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":538,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":535,"metricType":"timing"}]},"time":1669336710602,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":38,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 14","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3a84e021, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@3aa3ea2e\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@274636ad, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@3de81301","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":532,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":533,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":534,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":531,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336710606,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1669336710614,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[18],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"38","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710615,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 14","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"14","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"38","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710619,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":39,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 4","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#248, value#249, timestamp#250, current_timestamp#251]\nArguments: [topic#248, value#249, timestamp#250, current_timestamp#251], SQLExecutionRDD[70] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#248, value#249, timestamp#250, current_timestamp#251]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@7d451b5a, org.apache.spark.sql.connector.write.WriteBuilder$1@58a87119\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@7d451b5a, org.apache.spark.sql.connector.write.WriteBuilder$1@58a87119","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#248,value#249,timestamp#250,current_timestamp#251]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":565,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":564,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336710710,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1669336710719,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"146\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"145\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"138\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[19],"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"39","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"146\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"145\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"138\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710720,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 4","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"4","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"39","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710727,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710619,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336710984,"Failed":false,"Killed":false,"Accumulables":[{"ID":531,"Name":"duration","Update":"157","Value":"157","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":532,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":539,"Name":"internal.metrics.executorDeserializeTime","Update":187,"Value":187,"Internal":true,"Count Failed Values":true},{"ID":540,"Name":"internal.metrics.executorDeserializeCpuTime","Update":9203162,"Value":9203162,"Internal":true,"Count Failed Values":true},{"ID":541,"Name":"internal.metrics.executorRunTime","Update":169,"Value":169,"Internal":true,"Count Failed Values":true},{"ID":542,"Name":"internal.metrics.executorCpuTime","Update":22455125,"Value":22455125,"Internal":true,"Count Failed Values":true},{"ID":543,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":561,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":187,"Executor Deserialize CPU Time":9203162,"Executor Run Time":169,"Executor CPU Time":22455125,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":66,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"141\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[65],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":64,"Name":"DataSourceRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"144\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710615,"Completion Time":1669336710986,"Accumulables":[{"ID":531,"Name":"duration","Value":"157","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":532,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":539,"Name":"internal.metrics.executorDeserializeTime","Value":187,"Internal":true,"Count Failed Values":true},{"ID":540,"Name":"internal.metrics.executorDeserializeCpuTime","Value":9203162,"Internal":true,"Count Failed Values":true},{"ID":541,"Name":"internal.metrics.executorRunTime","Value":169,"Internal":true,"Count Failed Values":true},{"ID":542,"Name":"internal.metrics.executorCpuTime","Value":22455125,"Internal":true,"Count Failed Values":true},{"ID":543,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":561,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1669336710987,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":38,"time":1669336710988}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":36,"time":1669336710988}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336710727,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336711009,"Failed":false,"Killed":false,"Accumulables":[{"ID":535,"Name":"duration","Update":"93","Value":"93","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":536,"Name":"number of output rows","Update":"7","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":564,"Name":"duration","Update":"93","Value":"93","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":565,"Name":"number of output rows","Update":"7","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":566,"Name":"internal.metrics.executorDeserializeTime","Update":44,"Value":44,"Internal":true,"Count Failed Values":true},{"ID":567,"Name":"internal.metrics.executorDeserializeCpuTime","Update":10370977,"Value":10370977,"Internal":true,"Count Failed Values":true},{"ID":568,"Name":"internal.metrics.executorRunTime","Update":170,"Value":170,"Internal":true,"Count Failed Values":true},{"ID":569,"Name":"internal.metrics.executorCpuTime","Update":63562403,"Value":63562403,"Internal":true,"Count Failed Values":true},{"ID":570,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":588,"Name":"internal.metrics.input.recordsRead","Update":7,"Value":7,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":44,"Executor Deserialize CPU Time":10370977,"Executor Run Time":170,"Executor CPU Time":63562403,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":7},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":71,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"146\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[70],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":67,"Name":"DataSourceRDD","Scope":"{\"id\":\"145\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"145\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":69,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"138\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[68],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":70,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[69],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336710720,"Completion Time":1669336711010,"Accumulables":[{"ID":535,"Name":"duration","Value":"93","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":536,"Name":"number of output rows","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":564,"Name":"duration","Value":"93","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":565,"Name":"number of output rows","Value":"7","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":566,"Name":"internal.metrics.executorDeserializeTime","Value":44,"Internal":true,"Count Failed Values":true},{"ID":567,"Name":"internal.metrics.executorDeserializeCpuTime","Value":10370977,"Internal":true,"Count Failed Values":true},{"ID":568,"Name":"internal.metrics.executorRunTime","Value":170,"Internal":true,"Count Failed Values":true},{"ID":569,"Name":"internal.metrics.executorCpuTime","Value":63562403,"Internal":true,"Count Failed Values":true},{"ID":570,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":588,"Name":"internal.metrics.input.recordsRead","Value":7,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1669336711010,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":39,"time":1669336711017}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":37,"time":1669336711018}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:30.543Z","batchId":14,"batchDuration":483,"durationMs":{"triggerExecution":483,"queryPlanning":12,"getBatch":0,"latestOffset":1,"addBatch":404,"walCommit":28},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":86}}","endOffset":"{\"12003800_test\":{\"0\":90}}","latestOffset":"{\"12003800_test\":{\"0\":90}}","numInputRows":4,"inputRowsPerSecond":11.730205278592374,"processedRowsPerSecond":8.281573498964804,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":4},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:30.549Z","batchId":4,"batchDuration":502,"durationMs":{"triggerExecution":502,"queryPlanning":9,"getBatch":0,"latestOffset":1,"addBatch":430,"walCommit":26},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":83}}","endOffset":"{\"12003800_test\":{\"0\":90}}","latestOffset":"{\"12003800_test\":{\"0\":90}}","numInputRows":7,"inputRowsPerSecond":12.323943661971832,"processedRowsPerSecond":13.944223107569721,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":40,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 15","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e95e2c2, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@1128979f\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5de499d3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@6e1f31e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":592,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":593,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":594,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":591,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336711096,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":41,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 15","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@39ce65ab, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@58c222d5\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5de499d3, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@6e1f31e","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":592,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":593,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":594,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":591,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336711106,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1669336711118,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"156\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"159\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"DataSourceRDD","Scope":"{\"id\":\"159\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[20],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 15","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"15","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"41","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"156\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"159\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"DataSourceRDD","Scope":"{\"id\":\"159\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711119,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 15","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"15","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"41","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711134,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":42,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:31.053 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:31.053 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":621,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":622,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":623,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":620,"metricType":"timing"}]},"time":1669336711138,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711134,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336711215,"Failed":false,"Killed":false,"Accumulables":[{"ID":591,"Name":"duration","Update":"27","Value":"27","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":592,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":595,"Name":"internal.metrics.executorDeserializeTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":596,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8188884,"Value":8188884,"Internal":true,"Count Failed Values":true},{"ID":597,"Name":"internal.metrics.executorRunTime","Update":43,"Value":43,"Internal":true,"Count Failed Values":true},{"ID":598,"Name":"internal.metrics.executorCpuTime","Update":24994575,"Value":24994575,"Internal":true,"Count Failed Values":true},{"ID":599,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":617,"Name":"internal.metrics.input.recordsRead","Update":6,"Value":6,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":25,"Executor Deserialize CPU Time":8188884,"Executor Run Time":43,"Executor CPU Time":24994575,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":6},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":74,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"156\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[73],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":73,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"159\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[72],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":72,"Name":"DataSourceRDD","Scope":"{\"id\":\"159\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711119,"Completion Time":1669336711216,"Accumulables":[{"ID":591,"Name":"duration","Value":"27","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":592,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":595,"Name":"internal.metrics.executorDeserializeTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":596,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8188884,"Internal":true,"Count Failed Values":true},{"ID":597,"Name":"internal.metrics.executorRunTime","Value":43,"Internal":true,"Count Failed Values":true},{"ID":598,"Name":"internal.metrics.executorCpuTime","Value":24994575,"Internal":true,"Count Failed Values":true},{"ID":599,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":617,"Name":"internal.metrics.input.recordsRead","Value":6,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1669336711216,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":41,"time":1669336711222}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":40,"time":1669336711222}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":43,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 5","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#275, value#276, timestamp#277, current_timestamp#278]\nArguments: [topic#275, value#276, timestamp#277, current_timestamp#278], SQLExecutionRDD[78] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#275, value#276, timestamp#277, current_timestamp#278]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@53091894, org.apache.spark.sql.connector.write.WriteBuilder$1@2f2190d6\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@53091894, org.apache.spark.sql.connector.write.WriteBuilder$1@2f2190d6","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#275,value#276,timestamp#277,current_timestamp#278]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":625,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":624,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336711234,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1669336711241,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"167\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[78],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"DataSourceRDD","Scope":"{\"id\":\"163\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"163\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":78,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"160\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[21],"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"43","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"167\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[78],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"DataSourceRDD","Scope":"{\"id\":\"163\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"163\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":78,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"160\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711241,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 5","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"5","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"43","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711246,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:31.027Z","batchId":15,"batchDuration":224,"durationMs":{"triggerExecution":224,"queryPlanning":11,"getBatch":0,"latestOffset":1,"addBatch":145,"walCommit":37},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":90}}","endOffset":"{\"12003800_test\":{\"0\":96}}","latestOffset":"{\"12003800_test\":{\"0\":96}}","numInputRows":6,"inputRowsPerSecond":12.396694214876034,"processedRowsPerSecond":26.785714285714285,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":6},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":44,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 16","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@3a444245, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@1540452c\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1ee2d243, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@2256c96","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":652,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":653,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":654,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":651,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336711311,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":45,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 16","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6c29e8b0, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@49e44adb\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1ee2d243, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@2256c96","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":652,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":653,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":654,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":651,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336711321,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":22,"Submission Time":1669336711333,"Stage Infos":[{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"172\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"172\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[22],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 16","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"16","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"45","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"172\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"172\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711333,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 16","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"16","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"45","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":22,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711340,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":22,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711340,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336711388,"Failed":false,"Killed":false,"Accumulables":[{"ID":651,"Name":"duration","Update":"19","Value":"19","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":652,"Name":"number of output rows","Update":"2","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":655,"Name":"internal.metrics.executorDeserializeTime","Update":14,"Value":14,"Internal":true,"Count Failed Values":true},{"ID":656,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8457699,"Value":8457699,"Internal":true,"Count Failed Values":true},{"ID":657,"Name":"internal.metrics.executorRunTime","Update":24,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":658,"Name":"internal.metrics.executorCpuTime","Update":16556352,"Value":16556352,"Internal":true,"Count Failed Values":true},{"ID":659,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":677,"Name":"internal.metrics.input.recordsRead","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":14,"Executor Deserialize CPU Time":8457699,"Executor Run Time":24,"Executor CPU Time":16556352,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":2},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":82,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"169\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[81],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":80,"Name":"DataSourceRDD","Scope":"{\"id\":\"172\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":81,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"172\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[80],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711333,"Completion Time":1669336711389,"Accumulables":[{"ID":651,"Name":"duration","Value":"19","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":652,"Name":"number of output rows","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":655,"Name":"internal.metrics.executorDeserializeTime","Value":14,"Internal":true,"Count Failed Values":true},{"ID":656,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8457699,"Internal":true,"Count Failed Values":true},{"ID":657,"Name":"internal.metrics.executorRunTime","Value":24,"Internal":true,"Count Failed Values":true},{"ID":658,"Name":"internal.metrics.executorCpuTime","Value":16556352,"Internal":true,"Count Failed Values":true},{"ID":659,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":677,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":22,"Completion Time":1669336711390,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":45,"time":1669336711390}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":44,"time":1669336711391}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:31.252Z","batchId":16,"batchDuration":168,"durationMs":{"triggerExecution":168,"queryPlanning":10,"getBatch":0,"latestOffset":1,"addBatch":90,"walCommit":37},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":96}}","endOffset":"{\"12003800_test\":{\"0\":98}}","latestOffset":"{\"12003800_test\":{\"0\":98}}","numInputRows":2,"inputRowsPerSecond":8.88888888888889,"processedRowsPerSecond":11.904761904761903,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":2},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":46,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 17","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7626e3bb, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@8d12fd9\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@552eaa96, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@205bc395","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":681,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":682,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":683,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":680,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336711462,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":47,"description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 17","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nWriteToDataSourceV2 (3)\n+- * Project (2)\n   +- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [2]: [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n(3) WriteToDataSourceV2\nInput [2]: [key#30, value#31]\nArguments: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@511a6299, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@4d114c1d\n\n","sparkPlanInfo":{"nodeName":"WriteToDataSourceV2","simpleString":"WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@552eaa96, org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$2549/1858777139@205bc395","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [cast(key#7 as string) AS key#30, cast(value#8 as string) AS value#31]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":681,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":682,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":683,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":680,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336711468,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerJobStart","Job ID":23,"Submission Time":1669336711477,"Stage Infos":[{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":85,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"176\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"DataSourceRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[23],"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 17","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"17","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"47","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":85,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"176\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"DataSourceRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711478,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = ef2fa6b2-1188-48f6-8dd4-20272bc8c887\nrunId = af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c\nbatch = 17","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"17","spark.jobGroup.id":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"47","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":23,"Stage Attempt ID":0,"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711482,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711246,"Executor ID":"1","Host":"172.22.0.9","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336711870,"Failed":false,"Killed":false,"Accumulables":[{"ID":620,"Name":"duration","Update":"565","Value":"565","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":621,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":624,"Name":"duration","Update":"565","Value":"565","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":625,"Name":"number of output rows","Update":"6","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":626,"Name":"internal.metrics.executorDeserializeTime","Update":24,"Value":24,"Internal":true,"Count Failed Values":true},{"ID":627,"Name":"internal.metrics.executorDeserializeCpuTime","Update":17032625,"Value":17032625,"Internal":true,"Count Failed Values":true},{"ID":628,"Name":"internal.metrics.executorRunTime","Update":593,"Value":593,"Internal":true,"Count Failed Values":true},{"ID":629,"Name":"internal.metrics.executorCpuTime","Update":49779382,"Value":49779382,"Internal":true,"Count Failed Values":true},{"ID":630,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":648,"Name":"internal.metrics.input.recordsRead","Update":6,"Value":6,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":24,"Executor Deserialize CPU Time":17032625,"Executor Run Time":593,"Executor CPU Time":49779382,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":6},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":79,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"167\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[78],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":75,"Name":"DataSourceRDD","Scope":"{\"id\":\"163\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":76,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"163\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[75],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":78,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[77],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":77,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"160\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[76],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711241,"Completion Time":1669336711871,"Accumulables":[{"ID":620,"Name":"duration","Value":"565","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":621,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":624,"Name":"duration","Value":"565","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":625,"Name":"number of output rows","Value":"6","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":626,"Name":"internal.metrics.executorDeserializeTime","Value":24,"Internal":true,"Count Failed Values":true},{"ID":627,"Name":"internal.metrics.executorDeserializeCpuTime","Value":17032625,"Internal":true,"Count Failed Values":true},{"ID":628,"Name":"internal.metrics.executorRunTime","Value":593,"Internal":true,"Count Failed Values":true},{"ID":629,"Name":"internal.metrics.executorCpuTime","Value":49779382,"Internal":true,"Count Failed Values":true},{"ID":630,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":648,"Name":"internal.metrics.input.recordsRead","Value":6,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1669336711871,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":43,"time":1669336711871}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":42,"time":1669336711872}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:31.051Z","batchId":5,"batchDuration":851,"durationMs":{"triggerExecution":851,"queryPlanning":20,"getBatch":0,"latestOffset":2,"addBatch":753,"walCommit":44},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":90}}","endOffset":"{\"12003800_test\":{\"0\":96}}","latestOffset":"{\"12003800_test\":{\"0\":96}}","numInputRows":6,"inputRowsPerSecond":11.952191235059761,"processedRowsPerSecond":7.050528789659225,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":48,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\n* Project (2)\n+- MicroBatchScan (1)\n\n\n(1) MicroBatchScan\nOutput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\nclass org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan\n\n(2) Project [codegen id : 1]\nOutput [4]: [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:31.904 AS current_timestamp#21]\nInput [7]: [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]\n\n","sparkPlanInfo":{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [topic#9, cast(cast(value#8 as string) as int) AS value#50, timestamp#12, 2022-11-25 01:38:31.904 AS current_timestamp#21]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"MicroBatchScan","simpleString":"MicroBatchScan[key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13] class org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":710,"metricType":"sum"},{"name":"estimated number of fetched offsets out of range","accumulatorId":711,"metricType":"v2Custom_org.apache.spark.sql.kafka010.OffsetOutOfRangeMetric"},{"name":"number of data loss error","accumulatorId":712,"metricType":"v2Custom_org.apache.spark.sql.kafka010.DataLossMetric"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":709,"metricType":"timing"}]},"time":1669336711950,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":49,"description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 6","details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","physicalPlanDescription":"== Physical Plan ==\nAppendData (2)\n+- * Scan ExistingRDD (1)\n\n\n(1) Scan ExistingRDD [codegen id : 1]\nOutput [4]: [topic#309, value#310, timestamp#311, current_timestamp#312]\nArguments: [topic#309, value#310, timestamp#311, current_timestamp#312], SQLExecutionRDD[89] at start at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n\n(2) AppendData\nInput [4]: [topic#309, value#310, timestamp#311, current_timestamp#312]\nArguments: org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@fb5de5b, org.apache.spark.sql.connector.write.WriteBuilder$1@13a6713b\n\n","sparkPlanInfo":{"nodeName":"AppendData","simpleString":"AppendData org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy$$Lambda$3931/392299740@fb5de5b, org.apache.spark.sql.connector.write.WriteBuilder$1@13a6713b","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Scan ExistingRDD","simpleString":"Scan ExistingRDD[topic#309,value#310,timestamp#311,current_timestamp#312]","children":[],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":714,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":713,"metricType":"timing"}]}],"metadata":{},"metrics":[]},"time":1669336712021,"modifiedConfigs":{"spark.sql.adaptive.enabled":"false","spark.sql.requireAllClusterKeysForDistribution":"false","spark.sql.cbo.enabled":"false"}}
{"Event":"SparkListenerTaskEnd","Stage ID":23,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":23,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336711482,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336712025,"Failed":false,"Killed":false,"Accumulables":[{"ID":680,"Name":"duration","Update":"517","Value":"517","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":681,"Name":"number of output rows","Update":"2","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":684,"Name":"internal.metrics.executorDeserializeTime","Update":15,"Value":15,"Internal":true,"Count Failed Values":true},{"ID":685,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8239801,"Value":8239801,"Internal":true,"Count Failed Values":true},{"ID":686,"Name":"internal.metrics.executorRunTime","Update":521,"Value":521,"Internal":true,"Count Failed Values":true},{"ID":687,"Name":"internal.metrics.executorCpuTime","Update":17479932,"Value":17479932,"Internal":true,"Count Failed Values":true},{"ID":688,"Name":"internal.metrics.resultSize","Update":1758,"Value":1758,"Internal":true,"Count Failed Values":true},{"ID":706,"Name":"internal.metrics.input.recordsRead","Update":2,"Value":2,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":15,"Executor Deserialize CPU Time":8239801,"Executor Run Time":521,"Executor CPU Time":17479932,"Peak Execution Memory":0,"Result Size":1758,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":2},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":23,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":85,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"176\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[84],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":84,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[83],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":83,"Name":"DataSourceRDD","Scope":"{\"id\":\"179\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336711478,"Completion Time":1669336712026,"Accumulables":[{"ID":680,"Name":"duration","Value":"517","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":681,"Name":"number of output rows","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":684,"Name":"internal.metrics.executorDeserializeTime","Value":15,"Internal":true,"Count Failed Values":true},{"ID":685,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8239801,"Internal":true,"Count Failed Values":true},{"ID":686,"Name":"internal.metrics.executorRunTime","Value":521,"Internal":true,"Count Failed Values":true},{"ID":687,"Name":"internal.metrics.executorCpuTime","Value":17479932,"Internal":true,"Count Failed Values":true},{"ID":688,"Name":"internal.metrics.resultSize","Value":1758,"Internal":true,"Count Failed Values":true},{"ID":706,"Name":"internal.metrics.input.recordsRead","Value":2,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":23,"Completion Time":1669336712026,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":47,"time":1669336712026}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":46,"time":1669336712026}
{"Event":"SparkListenerJobStart","Job ID":24,"Submission Time":1669336712028,"Stage Infos":[{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"189\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"DataSourceRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Accumulables":[],"Resource Profile Id":0}],"Stage IDs":[24],"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"49","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"189\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"DataSourceRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336712029,"Accumulables":[],"Resource Profile Id":0},"Properties":{"sql.streaming.queryId":"253bd82c-7a01-42b4-9508-9872a09c9339","spark.sql.warehouse.dir":"file:/scripts/spark-warehouse","spark.executor.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.driver.host":"afe89519116f","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///spark-events","spark.eventLog.enabled":"true","spark.sql.adaptive.enabled":"false","spark.job.interruptOnCancel":"true","spark.driver.port":"36889","spark.rdd.compress":"True","spark.jars":"*********(redacted)","__is_continuous_processing":"false","spark.app.name":"Testing the Stream with Kafka","callSite.long":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","callSite.short":"start at NativeMethodAccessorImpl.java:0","spark.sql.requireAllClusterKeysForDistribution":"false","spark.app.initial.file.urls":"*********(redacted)","spark.submit.pyFiles":"*********(redacted)","spark.ui.showConsoleProgress":"true","spark.app.submitTime":"1669336523875","spark.jars.packages":"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,com.datastax.spark:spark-cassandra-connector_2.12:3.0.0,ch.cern.sparkmeasure:spark-measure_2.12:0.19","spark.job.description":"\nid = 253bd82c-7a01-42b4-9508-9872a09c9339\nrunId = 52826664-be14-4496-8d60-8f5b72cbff1c\nbatch = 6","spark.cassandra.auth.username":"cassandra","spark.files":"*********(redacted)","spark.app.startTime":"1669336524050","spark.executor.id":"driver","spark.sql.cbo.enabled":"false","spark.cassandra.connection.port":"9042","streaming.sql.batchId":"6","spark.jobGroup.id":"52826664-be14-4496-8d60-8f5b72cbff1c","spark.driver.extraJavaOptions":"-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED","spark.app.initial.jar.urls":"*********(redacted)","spark.submit.deployMode":"client","spark.cassandra.auth.password":"*********(redacted)","spark.master":"spark://spark-master:7077","spark.eventLog.dir":"file:///spark-events","spark.sql.execution.id":"49","spark.repl.local.jars":"*********(redacted)","spark.app.id":"app-20221125013525-0000","spark.cassandra.connection.host":"cassandra"}}
{"Event":"SparkListenerTaskStart","Stage ID":24,"Stage Attempt ID":0,"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336712034,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:31.421Z","batchId":17,"batchDuration":661,"durationMs":{"triggerExecution":661,"queryPlanning":8,"getBatch":0,"latestOffset":1,"addBatch":571,"walCommit":23},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":98}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":2,"inputRowsPerSecond":11.834319526627219,"processedRowsPerSecond":3.02571860816944,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":2},"observedMetrics":{}}}
{"Event":"SparkListenerTaskEnd","Stage ID":24,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":24,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1669336712034,"Executor ID":"0","Host":"172.22.0.10","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1669336712650,"Failed":false,"Killed":false,"Accumulables":[{"ID":709,"Name":"duration","Update":"551","Value":"551","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":710,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":713,"Name":"duration","Update":"551","Value":"551","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":714,"Name":"number of output rows","Update":"4","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":715,"Name":"internal.metrics.executorDeserializeTime","Update":13,"Value":13,"Internal":true,"Count Failed Values":true},{"ID":716,"Name":"internal.metrics.executorDeserializeCpuTime","Update":8595066,"Value":8595066,"Internal":true,"Count Failed Values":true},{"ID":717,"Name":"internal.metrics.executorRunTime","Update":595,"Value":595,"Internal":true,"Count Failed Values":true},{"ID":718,"Name":"internal.metrics.executorCpuTime","Update":40407154,"Value":40407154,"Internal":true,"Count Failed Values":true},{"ID":719,"Name":"internal.metrics.resultSize","Update":1873,"Value":1873,"Internal":true,"Count Failed Values":true},{"ID":737,"Name":"internal.metrics.input.recordsRead","Update":4,"Value":4,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":13,"Executor Deserialize CPU Time":8595066,"Executor Run Time":595,"Executor CPU Time":40407154,"Peak Execution Memory":0,"Result Size":1873,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":4},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":24,"Stage Attempt ID":0,"Stage Name":"start at NativeMethodAccessorImpl.java:0","Number of Tasks":1,"RDD Info":[{"RDD ID":90,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"189\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[89],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":86,"Name":"DataSourceRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":88,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"185\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[87],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":87,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"188\",\"name\":\"MicroBatchScan\"}","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[86],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":89,"Name":"SQLExecutionRDD","Callsite":"start at NativeMethodAccessorImpl.java:0","Parent IDs":[88],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:249)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)","Submission Time":1669336712029,"Completion Time":1669336712651,"Accumulables":[{"ID":709,"Name":"duration","Value":"551","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":710,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":713,"Name":"duration","Value":"551","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":714,"Name":"number of output rows","Value":"4","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":715,"Name":"internal.metrics.executorDeserializeTime","Value":13,"Internal":true,"Count Failed Values":true},{"ID":716,"Name":"internal.metrics.executorDeserializeCpuTime","Value":8595066,"Internal":true,"Count Failed Values":true},{"ID":717,"Name":"internal.metrics.executorRunTime","Value":595,"Internal":true,"Count Failed Values":true},{"ID":718,"Name":"internal.metrics.executorCpuTime","Value":40407154,"Internal":true,"Count Failed Values":true},{"ID":719,"Name":"internal.metrics.resultSize","Value":1873,"Internal":true,"Count Failed Values":true},{"ID":737,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0}}
{"Event":"SparkListenerJobEnd","Job ID":24,"Completion Time":1669336712651,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":49,"time":1669336712652}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":48,"time":1669336712652}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:31.903Z","batchId":6,"batchDuration":771,"durationMs":{"triggerExecution":771,"queryPlanning":7,"getBatch":0,"latestOffset":1,"addBatch":709,"walCommit":29},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":96}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":4,"inputRowsPerSecond":4.694835680751174,"processedRowsPerSecond":5.188067444876784,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"ef2fa6b2-1188-48f6-8dd4-20272bc8c887","runId":"af8be6b0-0ff2-4b94-89c5-ad4de7f0d68c","name":null,"timestamp":"2022-11-25T00:38:42.085Z","batchId":18,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@13a539f1","numOutputRows":0},"observedMetrics":{}}}
{"Event":"org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent","progress":{"id":"253bd82c-7a01-42b4-9508-9872a09c9339","runId":"52826664-be14-4496-8d60-8f5b72cbff1c","name":null,"timestamp":"2022-11-25T00:38:42.681Z","batchId":7,"batchDuration":1,"durationMs":{"triggerExecution":1,"latestOffset":1},"eventTime":{},"stateOperators":[],"sources":[{"description":"KafkaV2[Subscribe[12003800_test]]","startOffset":"{\"12003800_test\":{\"0\":100}}","endOffset":"{\"12003800_test\":{\"0\":100}}","latestOffset":"{\"12003800_test\":{\"0\":100}}","numInputRows":0,"inputRowsPerSecond":0.0,"processedRowsPerSecond":0.0,"metrics":{"minOffsetsBehindLatest":"0","maxOffsetsBehindLatest":"0","avgOffsetsBehindLatest":"0.0"}}],"sink":{"description":"ForeachBatchSink","numOutputRows":-1},"observedMetrics":{}}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1669336727943}
